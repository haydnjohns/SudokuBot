local_system:
  attached_files:
    - digit_classifier.py
    - digit_extractor.py
    - sudoku_recogniser.py
    - sudoku_renderer.py
  conversation_file:
  compile_command:
  initial_file_contents:
    digit_classifier.py: |
      """
      SudokuBot – Digit Classifier (Full Grid Prediction)
      Version 2025-04-22

      Major Changes:
      - Model predicts all 81 cells from the rectified grid image at once.
      - Uses a Fully Convolutional Network (FCN) based on ResNet blocks.
      - Data generator yields full grid images and corresponding label grids.
      - Training data uses puzzles derived from valid, solvable Sudoku solutions.
      - Preprocessing and augmentation apply to the full grid image.
      """

      # ------------------------------------------------------------------ #
      # 1.  choose backend BEFORE importing keras
      # ------------------------------------------------------------------ #
      import os
      os.environ["KERAS_BACKEND"] = "torch"  # must be first – do NOT move

      # ------------------------------------------------------------------ #
      # 2.  std‑lib & 3rd‑party imports
      # ------------------------------------------------------------------ #
      import gc
      import random
      from pathlib import Path
      from typing import Callable, Generator, Optional, Tuple

      import cv2
      import numpy as np
      import torch
      import keras
      from keras import callbacks, layers, models, activations, regularizers

      # ------------------------------------------------------------------ #
      # 3.  project‑local imports
      # ------------------------------------------------------------------ #
      try:
          # Use the updated renderer and extractor
          from sudoku_renderer import SudokuRenderer, generate_and_save_test_example
          from digit_extractor import (
              GRID_SIZE,
              DEFAULT_RECTIFIED_SIZE, # Use the size defined in extractor
              extract_cells_from_image,
              rectify_grid,
              # split_into_cells is not directly needed by the classifier anymore
          )
          import sudoku_recogniser # Needed for printing grids in callback
      except ImportError as e:
          print(f"Error importing local modules: {e}")
          print("Please ensure sudoku_renderer.py, digit_extractor.py, and sudoku_recogniser.py are available.")
          # Provide dummy implementations or raise error if essential
          GRID_SIZE = 9
          DEFAULT_RECTIFIED_SIZE = 252
          class SudokuRenderer:
              def render_sudoku(self, allow_empty=True, grid_spec=None): return None, None, None
          def generate_and_save_test_example(force=False): return Path("dummy_test.png"), np.zeros((9,9), dtype=int)
          def extract_cells_from_image(path, size=252, debug=False): return [], np.zeros((size,size), dtype=np.uint8), None
          class sudoku_recogniser:
              FINAL_CONFIDENCE_THRESHOLD = 0.8
              @staticmethod
              def print_sudoku_grid(grid, confs=None, threshold=0.0): pass


      # ------------------------------------------------------------------ #
      # 4.  constants
      # ------------------------------------------------------------------ #
      MODEL_FILENAME = "sudoku_full_grid_classifier_fcn.keras" # New filename for the new model type
      # Input shape based on the rectified grid size from digit_extractor
      MODEL_INPUT_SHAPE = (DEFAULT_RECTIFIED_SIZE, DEFAULT_RECTIFIED_SIZE, 1) # Grayscale input
      NUM_CLASSES = 11  # digits 0-9 + "empty"
      EMPTY_LABEL = 10  # Label used for empty cells in the target data (y)

      # Training parameters
      EPOCHS = 25 # Might need more epochs for a larger model/task
      STEPS_PER_EPOCH = 100 # Adjust based on data generation speed and dataset size
      BATCH_SIZE = 16 # Reduced batch size due to larger input images
      VALIDATION_STEPS = 30

      # Type alias for data batches
      DataBatch = Tuple[np.ndarray, np.ndarray] # (batch_of_grids, batch_of_labels)

      # ------------------------------------------------------------------ #
      # 5.  data generator (simplified for full grids)
      # ------------------------------------------------------------------ #
      def sudoku_data_generator(
          renderer: SudokuRenderer,
          batch_size: int,
          preprocess_func: Callable[[np.ndarray], Optional[np.ndarray]],
          augment_func: Optional[Callable[[np.ndarray], np.ndarray]], # Optional augmentation
          input_shape: Tuple[int, int, int], # e.g., (252, 252, 1)
      ) -> Generator[DataBatch, None, None]:
          """
          Yields batches of (preprocessed_grid_image, target_label_grid).
          Generates valid Sudoku puzzles on the fly.
          """
          target_h, target_w, target_c = input_shape
          is_grayscale = (target_c == 1)

          batch_counter = 0
          while True:
              batch_x = np.zeros((batch_size, target_h, target_w, target_c), dtype="float32")
              batch_y = np.zeros((batch_size, GRID_SIZE, GRID_SIZE), dtype="int64")
              
              items_in_batch = 0
              while items_in_batch < batch_size:
                  # Generate a rendered Sudoku image and its ground truth puzzle grid (0 for empty)
                  img, gt_puzzle_grid, corners = renderer.render_sudoku(allow_empty=True) # Let renderer handle difficulty

                  if img is None or gt_puzzle_grid is None or corners is None:
                      # print("[Generator] Renderer failed, skipping.")
                      time.sleep(0.1) # Avoid busy-looping if renderer fails consistently
                      continue

                  # Rectify the grid using the known corners
                  # Use the target input size for rectification directly
                  rectified = rectify_grid(img, corners, size=target_h) # Assuming target_h == target_w
                  if rectified is None:
                      # print("[Generator] Rectification failed, skipping.")
                      continue

                  # Preprocess the entire rectified grid image
                  processed_grid = preprocess_func(rectified)
                  if processed_grid is None:
                      # print("[Generator] Preprocessing failed, skipping.")
                      continue

                  # Apply augmentation if provided (usually only for training)
                  if augment_func:
                      processed_grid = augment_func(processed_grid)

                  # Ensure the processed grid has the correct shape (H, W, C)
                  if processed_grid.shape != (target_h, target_w, target_c):
                       print(f"[Generator Warning] Processed grid shape mismatch: expected {(target_h, target_w, target_c)}, got {processed_grid.shape}. Skipping.")
                       continue


                  # Convert the ground truth puzzle grid (0 for empty) to the target format
                  # where empty cells are represented by EMPTY_LABEL (10)
                  target_labels = gt_puzzle_grid.copy()
                  target_labels[target_labels == 0] = EMPTY_LABEL

                  # Add to batch
                  batch_x[items_in_batch] = processed_grid
                  batch_y[items_in_batch] = target_labels
                  items_in_batch += 1

              # Yield the complete batch
              batch_counter += 1
              # Optional debug print
              # if batch_counter % 10 == 0:
              #     print(f"[Generator] Yielding batch {batch_counter}. Example label counts: {np.bincount(batch_y[0].flatten(), minlength=NUM_CLASSES)}")

              yield batch_x, batch_y
              # No need for explicit gc.collect() here usually, Python handles it.


      # ------------------------------------------------------------------ #
      # 6.  classifier object (handles full grid model)
      # ------------------------------------------------------------------ #
      class DigitClassifier:
          """
          Handles loading, training and inference of the FCN Sudoku grid classifier.
          """

          # -------------------------------------------------------------- #
          # constructor
          # -------------------------------------------------------------- #
          def __init__(
              self,
              model_path: Optional[str | Path] = None,
              training_required: bool = False,
          ) -> None:
              self.model_path = Path(model_path) if model_path else Path(MODEL_FILENAME)
              self.model: Optional[keras.Model] = None
              self._model_input_shape = MODEL_INPUT_SHAPE # e.g., (252, 252, 1)

              if not training_required and self.model_path.exists():
                  print(f"Attempting to load model from {self.model_path}...")
                  try:
                      self.model = keras.models.load_model(self.model_path)
                      # Check if loaded model's input shape matches config
                      # Keras models sometimes store input shape as (None, H, W, C)
                      loaded_shape = self.model.input_shape[1:]
                      if loaded_shape != self._model_input_shape:
                          print(f"[Warning] Loaded model input shape {loaded_shape} "
                                f"differs from expected {self._model_input_shape}. Mismatch may cause errors.")
                      print(f"Full-grid classifier model loaded successfully.")
                  except Exception as e:
                      print(f"[Error] Failed to load model from {self.model_path}: {e}")
                      print("Will build and train a new model if training is enabled.")
                      self.model = None # Ensure model is None if loading failed

              # Handle training_required flag
              if training_required and self.model is not None:
                   print("Training required: Ignoring previously loaded model and building a new one.")
                   self.model = None
              elif training_required and self.model is None:
                   print("Training required: Model will be built.")
              elif not training_required and self.model is None:
                   print("Model not found or failed to load, and training not required. Classifier is inactive.")


          # -------------------------------------------------------------- #
          # ResNet-style building block (same as before)
          # -------------------------------------------------------------- #
          def _residual_block(self, x, filters, strides=1, activation="relu"):
              """Basic residual block."""
              shortcut = x
              # Downsample shortcut if needed
              if strides > 1 or shortcut.shape[-1] != filters:
                  shortcut = layers.Conv2D(
                      filters, 1, strides=strides, use_bias=False, kernel_initializer="he_normal",
                      kernel_regularizer=regularizers.l2(1e-5) # Added slight L2 regularization
                  )(shortcut)
                  shortcut = layers.BatchNormalization()(shortcut)

              # First convolution
              y = layers.Conv2D(
                  filters, 3, strides=strides, padding="same", use_bias=False, kernel_initializer="he_normal",
                  kernel_regularizer=regularizers.l2(1e-5)
              )(x)
              y = layers.BatchNormalization()(y)
              y = layers.Activation(activation)(y)

              # Second convolution
              y = layers.Conv2D(
                  filters, 3, padding="same", use_bias=False, kernel_initializer="he_normal",
                  kernel_regularizer=regularizers.l2(1e-5)
              )(y)
              y = layers.BatchNormalization()(y)

              # Add shortcut
              y = layers.Add()([shortcut, y])
              y = layers.Activation(activation)(y)
              return y

          # -------------------------------------------------------------- #
          # backbone (FCN for full grid prediction)
          # -------------------------------------------------------------- #
          def _build_cnn_model(self) -> keras.Model:
              """Builds a Fully Convolutional Network (FCN) for grid prediction."""
              activation_func = "relu" # Or 'gelu'

              x_in = keras.Input(shape=self._model_input_shape) # e.g., (252, 252, 1)

              # --- Encoder Path (Downsampling) ---
              # Initial Conv Layer (Stem)
              # Use stride 3 to quickly reduce dimensions: 252 -> 84
              filters = 32
              x = layers.Conv2D(filters, 7, strides=3, padding="same", use_bias=False, kernel_initializer="he_normal")(x_in)
              x = layers.BatchNormalization()(x)
              x = layers.Activation(activation_func)(x)
              # x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # Optional extra pooling

              # Residual Blocks with increasing filters and downsampling
              # Block 1: 84x84 -> 84x84 (filters=32)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 2: 84x84 -> 28x28 (filters=64, stride=3)
              filters *= 2 # 64
              x = self._residual_block(x, filters, strides=3, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 3: 28x28 -> 28x28 (filters=128) - Stride 1 here
              filters *= 2 # 128
              x = self._residual_block(x, filters, strides=1, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 4: 28x28 -> 14x14 (filters=256, stride=2) - Aiming for spatial dim > 9
              filters *= 2 # 256
              x = self._residual_block(x, filters, strides=2, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # --- Prediction Head ---
              # At this point, spatial dimension is 14x14. We need 9x9 output.
              # Option 1: Use a Conv layer with stride to reduce size (might lose info)
              # Option 2: Use Adaptive Pooling (if available/easy in Keras backend)
              # Option 3: Use Conv + Upsampling (more complex)
              # Option 4: Use a final Conv layer that implicitly handles the size reduction (less common)

              # Let's try a Conv2D layer designed to output the correct spatial dimensions.
              # We need to get closer to 9x9. Add another block?
              # Block 5: 14x14 -> 7x7 (filters=512, stride=2)
              # filters *= 2 # 512
              # x = self._residual_block(x, filters, strides=2, activation=activation_func)
              # x = self._residual_block(x, filters, strides=1, activation=activation_func)
              # Now spatial dim is 7x7. This is too small.

              # Backtrack: Let's stop at 14x14 (Block 4 output).
              # How to get to (9, 9, NUM_CLASSES)?
              # Use a 1x1 Conv to reduce filters, then maybe resize/crop or use specific conv?

              # Try a final Conv layer with appropriate kernel/padding to target 9x9.
              # Input to this layer is (None, 14, 14, 256)
              # Output needed is (None, 9, 9, NUM_CLASSES)

              # Use a 1x1 convolution to adjust the number of channels first
              x = layers.Conv2D(128, 1, padding='same', activation=activation_func, kernel_initializer='he_normal')(x)
              x = layers.BatchNormalization()(x)
              # Now (None, 14, 14, 128)

              # Use a final Conv2D layer to produce the output map.
              # A kernel size of 6 with valid padding on a 14x14 input gives (14-6+1) = 9x9 output.
              # Stride 1 is implicit.
              x = layers.Conv2D(
                  filters=NUM_CLASSES,
                  kernel_size=6, # Kernel size chosen to map 14x14 -> 9x9 with 'valid' padding
                  padding="valid", # 'valid' means no padding
                  activation=None, # Apply softmax separately across the class dimension
                  kernel_initializer='he_normal',
                  name="final_conv_logits"
              )(x)
              # Output shape should now be (None, 9, 9, NUM_CLASSES)

              # Apply Softmax activation across the last axis (classes)
              y_out = layers.Activation("softmax", name="output_softmax")(x)

              # Create the model
              model = models.Model(x_in, y_out, name="fcn_sudoku_grid")

              # Compile the model
              optimizer = keras.optimizers.Adam(learning_rate=5e-4) # Slightly higher LR?
              # Loss function suitable for integer targets and probability outputs
              loss = "sparse_categorical_crossentropy"
              # Metrics: Accuracy calculated per cell prediction
              metrics = ["accuracy"]

              model.compile(
                  optimizer=optimizer,
                  loss=loss,
                  metrics=metrics,
              )
              model.summary(line_length=120)
              return model

          # -------------------------------------------------------------- #
          # preprocessing (for full grid image)
          # -------------------------------------------------------------- #
          def _preprocess_grid_for_model(self, rectified_img: np.ndarray) -> Optional[np.ndarray]:
              """
              Prepares the rectified grid image for the FCN model.
              Resizes, converts to grayscale, normalizes to [0, 1], adds channel dim.
              """
              if rectified_img is None or rectified_img.size == 0:
                  return None

              target_h, target_w, target_c = self._model_input_shape
              is_grayscale = (target_c == 1)

              # Resize to target input size
              # Use INTER_AREA for shrinking, INTER_LINEAR for enlarging
              current_h, current_w = rectified_img.shape[:2]
              if current_h * current_w > target_h * target_w:
                  interp = cv2.INTER_AREA
              else:
                  interp = cv2.INTER_LINEAR
              resized = cv2.resize(rectified_img, (target_w, target_h), interpolation=interp)

              # Ensure correct number of channels (grayscale)
              if is_grayscale:
                  if resized.ndim == 3 and resized.shape[2] == 3:
                      processed = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)
                  elif resized.ndim == 3 and resized.shape[2] == 4:
                      processed = cv2.cvtColor(resized, cv2.COLOR_BGRA2GRAY)
                  elif resized.ndim == 2:
                      processed = resized
                  else:
                      print(f"[Preprocess Error] Unexpected image shape: {resized.shape}")
                      return None
                  # Add channel dimension: (H, W) -> (H, W, 1)
                  processed = processed[..., np.newaxis]
              else: # If model expected color input (target_c == 3)
                  if resized.ndim == 2: # Convert grayscale to BGR
                      processed = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)
                  elif resized.ndim == 3 and resized.shape[2] == 4: # Convert BGRA to BGR
                       processed = cv2.cvtColor(resized, cv2.COLOR_BGRA2BGR)
                  elif resized.ndim == 3 and resized.shape[2] == 3:
                       processed = resized # Already BGR
                  else:
                      print(f"[Preprocess Error] Unexpected image shape for color: {resized.shape}")
                      return None

              # Normalize to [0, 1] float32
              processed = processed.astype("float32") / 255.0

              return processed


          # ------------------------------------------------------------------ #
          # 7.1  augmentation (for full grid image)
          # ------------------------------------------------------------------ #
          def _augment_grid(self, grid_img: np.ndarray) -> np.ndarray:
              """Apply augmentations to the full grid image."""
              h, w = grid_img.shape[:2]
              augmented = grid_img.copy()

              # 1. Small Rotation
              if random.random() < 0.5:
                  angle = random.uniform(-8, 8) # Reduced angle for full grid
                  M_rot = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1.0)
                  augmented = cv2.warpAffine(augmented, M_rot, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0) # Black border

              # 2. Small Translation
              if random.random() < 0.5:
                  tx = random.uniform(-w * 0.03, w * 0.03) # Max 3% translation
                  ty = random.uniform(-h * 0.03, h * 0.03)
                  M_trans = np.float32([[1, 0, tx], [0, 1, ty]])
                  augmented = cv2.warpAffine(augmented, M_trans, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0)

              # 3. Brightness/Contrast Jitter
              if random.random() < 0.6:
                  alpha = random.uniform(0.85, 1.15) # Contrast
                  beta = random.uniform(-0.1, 0.1)   # Brightness
                  augmented = np.clip(augmented * alpha + beta, 0.0, 1.0)

              # 4. Gaussian Noise
              if random.random() < 0.3:
                  noise = np.random.normal(0, random.uniform(0.01, 0.05), augmented.shape)
                  augmented = np.clip(augmented + noise, 0.0, 1.0)

              # Ensure output is float32
              return augmented.astype("float32")


          # -------------------------------------------------------------- #
          # training
          # -------------------------------------------------------------- #
          def train(
              self,
              epochs: int = EPOCHS,
              steps_per_epoch: int = STEPS_PER_EPOCH,
              batch_size: int = BATCH_SIZE,
              validation_steps: int = VALIDATION_STEPS,
          ) -> None:
              """Trains the full-grid FCN model."""
              print(f"\n--- Training Full Grid Classifier ---")
              print(f"Epochs: {epochs}, Steps/Epoch: {steps_per_epoch}, Batch Size: {batch_size}")
              print(f"Input Shape: {self._model_input_shape}, Output: (9, 9, {NUM_CLASSES})")

              if self.model is None:
                  self.model = self._build_cnn_model()
              elif not isinstance(self.model, keras.Model):
                   print("[Error] self.model is not a valid Keras model. Cannot train.")
                   return

              # Prepare test example for callback
              try:
                  test_img_path, test_gt_grid = generate_and_save_test_example()
                  if test_img_path is None or test_gt_grid is None:
                       raise ValueError("Failed to generate/load test example.")
                  # Pass the classifier instance and the ground truth grid (0 for empty)
                  epoch_cb = EpochTestCallback(test_img_path, test_gt_grid, self)
              except Exception as e:
                  print(f"[Warning] Failed to set up EpochTestCallback: {e}. Callback disabled.")
                  epoch_cb = None

              # Create data generators
              # Training generator uses augmentation
              train_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  self._augment_grid, # Apply augmentation
                  self._model_input_shape,
              )
              # Validation generator does not use augmentation
              val_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  None, # No augmentation for validation
                  self._model_input_shape,
              )

              # Dump a batch of augmented training samples for visualization
              dump_dir = Path("dumped_training_grids")
              dump_dir.mkdir(exist_ok=True)
              try:
                  x_vis, y_vis = next(train_gen) # Get one batch from training gen
                  n_dump = min(4, x_vis.shape[0]) # Dump fewer, larger images
                  for i in range(n_dump):
                      # Convert float32 [0,1] -> uint8 [0,255]
                      img = (x_vis[i] * 255).astype(np.uint8)
                      # Maybe add label info to filename if needed, but grid is complex
                      cv2.imwrite(str(dump_dir / f"sample_grid_{i}.png"), img)
                  print(f"[Info] Dumped {n_dump} augmented training grid samples to {dump_dir}")
              except Exception as e:
                  print(f"[Warning] Could not dump training samples: {e}")


              # Callbacks
              cbs: list[callbacks.Callback] = [
                  callbacks.EarlyStopping(
                      monitor="val_accuracy", # Monitor validation accuracy (per-cell)
                      patience=10,          # Increased patience for larger model
                      restore_best_weights=True,
                      verbose=1,
                      mode='max'
                  ),
                  callbacks.ModelCheckpoint(
                      filepath=str(self.model_path), # Ensure path is string
                      monitor="val_accuracy",
                      save_best_only=True,
                      verbose=1,
                      mode='max'
                  ),
                  callbacks.ReduceLROnPlateau(
                      monitor="val_loss", # Reduce LR based on validation loss
                      factor=0.2,
                      patience=4,
                      min_lr=1e-7,
                      verbose=1,
                      mode='min' # Reduce LR when loss plateaus
                  ),
                  # Optional: TensorBoard
                  # callbacks.TensorBoard(log_dir='./logs_fcn', histogram_freq=1)
              ]
              if epoch_cb:
                  cbs.append(epoch_cb)

              # Start Training
              print("\nStarting model training...")
              history = self.model.fit(
                  train_gen,
                  epochs=epochs,
                  steps_per_epoch=steps_per_epoch,
                  validation_data=val_gen,
                  validation_steps=validation_steps,
                  callbacks=cbs,
                  verbose=1, # Use 1 for progress bar, 2 for one line per epoch
              )

              # Ensure the best model is loaded (EarlyStopping might restore, Checkpoint saves)
              if self.model_path.exists():
                   print(f"Reloading best weights from {self.model_path}...")
                   try:
                       # Use load_model if the whole architecture might change,
                       # or load_weights if only weights are saved/needed.
                       # ModelCheckpoint saves the whole model by default.
                       self.model = keras.models.load_model(self.model_path)
                       print("Best model reloaded.")
                   except Exception as e:
                       print(f"[Error] Failed to reload best model after training: {e}")
                       # The model instance might still hold the best weights if EarlyStopping restored them.

              print("\n--- Final Evaluation (using best weights) ---")
              # Use a fresh validation generator for final evaluation
              final_eval_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  None, # No augmentation
                  self._model_input_shape,
              )
              loss, acc = self.model.evaluate(
                  final_eval_gen,
                  steps=validation_steps * 2, # Evaluate on more validation steps
                  verbose=1,
              )
              print(f"Final Validation Loss: {loss:.5f}")
              print(f"Final Validation Accuracy (per cell): {acc:.5f}")

              # Explicitly save the final best model again (belt-and-suspenders)
              try:
                  print(f"Saving final best model to {self.model_path}")
                  self.model.save(self.model_path)
              except Exception as e:
                  print(f"[Error] Failed to save final model: {e}")

              del train_gen, val_gen, final_eval_gen, history
              gc.collect()
              print("--- Training Finished ---")


          # -------------------------------------------------------------- #
          # inference (for full grid)
          # -------------------------------------------------------------- #
          @torch.no_grad() # Keep decorator if using torch backend
          def recognise_grid(
              self,
              rectified_img: np.ndarray,
              confidence_threshold: float = 0.80, # Default threshold for accepting a digit
          ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
              """
              Recognises digits in a rectified Sudoku grid image using the FCN model.

              Args:
                  rectified_img: The (e.g., 252x252) rectified grid image (uint8 or float).
                  confidence_threshold: Minimum confidence to accept a digit prediction (1-9).

              Returns:
                  A tuple (predicted_grid, confidence_grid):
                  - predicted_grid: (9, 9) numpy array with recognised digits (1-9) or 0 for empty/uncertain.
                  - confidence_grid: (9, 9) numpy array with confidence scores for the predicted class in each cell.
                  Returns (None, None) if inference fails.
              """
              if self.model is None:
                  print("[Error] Recognise_grid called but model is not loaded.")
                  return None, None

              # 1. Preprocess the input grid image
              proc_grid = self._preprocess_grid_for_model(rectified_img)
              if proc_grid is None:
                  print("[Error] Preprocessing failed during recognition.")
                  return None, None # Indicate failure

              # 2. Add batch dimension: (H, W, C) -> (1, H, W, C)
              x = proc_grid[np.newaxis, ...]

              # 3. Predict using the Keras model
              try:
                  # Use training=False for inference (important for layers like BatchNorm, Dropout)
                  raw_output = self.model(x, training=False) # Shape: (1, 9, 9, NUM_CLASSES)
              except Exception as e:
                  print(f"[Error] Model prediction failed: {e}")
                  return None, None

              # 4. Convert to NumPy and remove batch dimension
              # Keras with torch backend might return torch tensors
              if hasattr(raw_output, 'cpu') and hasattr(raw_output, 'numpy'): # Check if it's a tensor with cpu/numpy methods
                   probs = raw_output.cpu().numpy()
              elif isinstance(raw_output, np.ndarray):
                   probs = raw_output
              else:
                   print(f"[Error] Unexpected model output type: {type(raw_output)}")
                   return None, None

              probs = probs[0] # Shape: (9, 9, NUM_CLASSES)

              # 5. Decode probabilities to predictions and confidences
              predicted_indices = np.argmax(probs, axis=-1) # Shape: (9, 9), contains indices 0-10
              confidences = np.max(probs, axis=-1)       # Shape: (9, 9), contains max probability

              # 6. Create the final output grid
              # Initialize with zeros (representing empty/uncertain)
              final_grid = np.zeros((GRID_SIZE, GRID_SIZE), dtype=int)

              # Iterate through each cell prediction
              for r in range(GRID_SIZE):
                  for c in range(GRID_SIZE):
                      pred_idx = predicted_indices[r, c]
                      conf = confidences[r, c]

                      # Check if the prediction is a digit (1-9), not EMPTY_LABEL (10),
                      # and if the confidence meets the threshold.
                      if pred_idx != EMPTY_LABEL and conf >= confidence_threshold:
                          final_grid[r, c] = pred_idx # Assign the predicted digit (1-9)
                      # Otherwise, leave it as 0 (empty/uncertain)

              return final_grid, confidences


      # ------------------------------------------------------------------ #
      # 8.  epoch‑end callback (adapted for full grid)
      # ------------------------------------------------------------------ #
      class EpochTestCallback(callbacks.Callback):
          def __init__(
              self,
              test_img_path: Path | str,
              gt_puzzle_grid: np.ndarray, # Ground truth puzzle (0 for empty)
              classifier: "DigitClassifier",
              frequency: int = 1,
          ) -> None:
              super().__init__()
              self.frequency = max(1, frequency)
              self.gt_puzzle_grid = gt_puzzle_grid # Shape (9, 9), 0 for empty
              self.classifier = classifier
              self.test_img_path = test_img_path
              self.preprocessed_test_grid = None # To store the single preprocessed grid

          def on_train_begin(self, logs=None):
              """Preprocess the test image once before training starts."""
              print("\n[Callback] Preprocessing test example for epoch-end evaluation...")
              try:
                  # Extract the rectified grid from the test image file
                  # We don't need the individual cells here, just the rectified image
                  _, rectified_test_img, _ = extract_cells_from_image(
                      self.test_img_path,
                      size=self.classifier._model_input_shape[0], # Use model's input size
                      debug=False
                  )

                  if rectified_test_img is None:
                      print("[Callback Error] Failed to extract rectified grid from test image.")
                      self.preprocessed_test_grid = None
                      return

                  # Preprocess the rectified grid using the classifier's method
                  self.preprocessed_test_grid = self.classifier._preprocess_grid_for_model(rectified_test_img)

                  if self.preprocessed_test_grid is None:
                      print("[Callback Error] Preprocessing of the test grid failed.")
                  else:
                      print(f"[Callback] Test grid preprocessed successfully ({self.preprocessed_test_grid.shape}).")

              except Exception as e:
                  print(f"[Callback Error] Failed during test example setup: {e}")
                  self.preprocessed_test_grid = None

          def on_epoch_end(self, epoch, logs=None):
              # Check if preprocessing was successful and if it's the right epoch
              if self.preprocessed_test_grid is None or (epoch + 1) % self.frequency != 0:
                  return

              if not hasattr(self.model, 'predict'):
                   print("[Callback Error] Model object in callback does not have predict method.")
                   return

              print(f"\n--- Epoch {epoch+1} Test Example Evaluation ---")
              try:
                  # Add batch dimension for prediction
                  x_test = self.preprocessed_test_grid[np.newaxis, ...]

                  # Predict using the model being trained
                  raw_output = self.model.predict(x_test, verbose=0) # Shape: (1, 9, 9, NUM_CLASSES)

                  # Decode the output (similar to recognise_grid)
                  probs = raw_output[0] # Remove batch dim -> (9, 9, NUM_CLASSES)
                  pred_indices = np.argmax(probs, axis=-1) # (9, 9) indices 0-10
                  confs = np.max(probs, axis=-1)       # (9, 9) confidences

                  # Apply thresholding for display (use a slightly lower threshold maybe)
                  display_threshold = 0.7 # Threshold for visualization purposes
                  display_grid = np.zeros_like(pred_indices, dtype=int)
                  for r in range(GRID_SIZE):
                      for c in range(GRID_SIZE):
                          idx = pred_indices[r, c]
                          cf = confs[r, c]
                          if idx != EMPTY_LABEL and cf >= display_threshold:
                              display_grid[r, c] = idx

                  print("Ground Truth Puzzle:")
                  # print_sudoku_grid expects 0 for empty
                  sudoku_recogniser.print_sudoku_grid(self.gt_puzzle_grid)

                  print(f"Prediction (Thresholded @ {display_threshold:.2f}):")
                  sudoku_recogniser.print_sudoku_grid(display_grid, confs, threshold=display_threshold)

                  # --- Calculate Accuracy ---
                  # Compare prediction indices directly with the GT grid converted to use EMPTY_LABEL
                  gt_labels = self.gt_puzzle_grid.copy()
                  gt_labels[gt_labels == 0] = EMPTY_LABEL # Convert GT to use 10 for empty

                  correct_cells = (pred_indices == gt_labels).sum()
                  total_cells = GRID_SIZE * GRID_SIZE
                  accuracy = correct_cells / total_cells
                  print(f"Test Example Accuracy (Raw Prediction vs GT Labels): {correct_cells}/{total_cells} = {accuracy:.4f}")
                  print("--- End Epoch Test ---\n")

              except Exception as e:
                  print(f"[Callback Error] Failed during prediction or display: {e}")
                  import traceback
                  traceback.print_exc()


      # ------------------------------------------------------------------ #
      # 9.  CLI helper
      # ------------------------------------------------------------------ #
      if __name__ == "__main__":
          # Set to True to force retraining even if a model file exists
          FORCE_TRAIN = False

          model_file = Path(MODEL_FILENAME)
          train_needed = FORCE_TRAIN or not model_file.exists()

          if FORCE_TRAIN and model_file.exists():
              print(f"FORCE_TRAIN is True. Deleting existing model: {model_file}")
              try:
                  model_file.unlink()
                  train_needed = True
              except OSError as e:
                  print(f"Error deleting existing model: {e}. Proceeding might use old model if loading works.")
                  # Decide whether to exit or continue
                  # exit(1)

          # Instantiate the classifier. It will try to load if train_needed is False.
          clf = DigitClassifier(model_path=model_file, training_required=train_needed)

          # Train if needed
          if train_needed:
              if clf.model is not None:
                   print("[Warning] Model was loaded despite train_needed=True? Retraining anyway.")
                   clf.model = None # Ensure model is rebuilt
              print("Starting training process...")
              clf.train(epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, batch_size=BATCH_SIZE)
              # After training, the best model should be saved and reloaded by the train method.
              if clf.model is None:
                   print("[Error] Training finished, but model is still None. Cannot proceed.")
                   exit(1)
          elif clf.model is None:
               print("[Error] Model loading failed, and training was not requested. Cannot proceed.")
               exit(1)
          else:
               print("Model loaded successfully. Skipping training.")


          # --- Perform Sanity Check using the Test Example ---
          if clf.model:
              print("\n--- Sanity Check: Recognising the Test Example ---")
              test_img_path_str, test_gt_grid = generate_and_save_test_example() # Get path and GT

              if test_img_path_str is None or test_gt_grid is None:
                  print("Failed to load test example for sanity check.")
              else:
                  test_img_path = Path(test_img_path_str)
                  print(f"Loading test image: {test_img_path}")
                  # Extract rectified grid from the test image
                  _, rectified_test, _ = extract_cells_from_image(
                      test_img_path,
                      size=clf._model_input_shape[0], # Use model's input size
                      debug=False
                  )

                  if rectified_test is None:
                      print("Failed to extract rectified grid from test image for sanity check.")
                  else:
                      print("Running recognise_grid on the test image...")
                      # Use a reasonable confidence threshold for the check
                      pred_grid, conf_grid = clf.recognise_grid(rectified_test, confidence_threshold=0.75)

                      if pred_grid is None:
                          print("Recognition failed during sanity check.")
                      else:
                          print("\nGround Truth Puzzle:")
                          sudoku_recogniser.print_sudoku_grid(test_gt_grid)

                          print("Recognised Grid (Thresholded @ 0.75):")
                          sudoku_recogniser.print_sudoku_grid(pred_grid, conf_grid, threshold=0.75)

                          # Calculate accuracy for the sanity check
                          correct_cells = (pred_grid == test_gt_grid).sum()
                          # Account for empty cells being 0 in both GT and prediction (correctly)
                          # Non-empty cells must match exactly
                          correct_non_empty = ((pred_grid == test_gt_grid) & (test_gt_grid != 0)).sum()
                          correct_empty = ((pred_grid == 0) & (test_gt_grid == 0)).sum()
                          total_correct = correct_non_empty + correct_empty

                          total_cells = GRID_SIZE * GRID_SIZE
                          accuracy = total_correct / total_cells
                          print(f"\nSanity Check Accuracy: {total_correct}/{total_cells} = {accuracy:.4f}")
          else:
              print("\nSanity check skipped: No model available.")

          print("\nScript finished.")
    digit_extractor.py: |
      """
      Find and extract Sudoku grid cells from an image.
      """

      import os
      from pathlib import Path
      from typing import List, Tuple, Optional

      import cv2
      import numpy as np

      GRID_SIZE = 9
      # Changed default size to be divisible by common CNN strides (e.g., 2^3=8 or 3^3=27)
      # 252 = 9 * 28 -> divisible by 2, 3, 4, 6, 7, 9, 12, 14, 18, 21, 28...
      DEFAULT_RECTIFIED_SIZE = 252


      def _order_points(pts: np.ndarray) -> np.ndarray:
          """Order four points as top-left, top-right, bottom-right, bottom-left."""
          pts = pts.reshape(4, 2).astype("float32")
          rect = np.zeros((4, 2), dtype="float32")
          s = pts.sum(axis=1)
          rect[0] = pts[np.argmin(s)] # Top-left has smallest sum
          rect[2] = pts[np.argmax(s)] # Bottom-right has largest sum
          diff = np.diff(pts, axis=1) # diff = y - x
          rect[1] = pts[np.argmin(diff)] # Top-right has smallest diff
          rect[3] = pts[np.argmax(diff)] # Bottom-left has largest diff
          return rect


      def find_sudoku_grid_contour(
          img: np.ndarray,
          debug_dir: Optional[Path] = None
      ) -> Optional[np.ndarray]:
          """
          Find the largest 4-point contour approximating the Sudoku grid boundary.
          Returns the contour points (4, 2) or None if not found.
          """
          if img is None or img.size == 0:
              print("[Contour Finder] Invalid input image.")
              return None

          gray = (
              cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
              if img.ndim == 3 and img.shape[2] == 3 else img.copy()
          )
          if gray.ndim == 3: # Handle case like RGBA input
              gray = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)

          if debug_dir:
              debug_dir.mkdir(parents=True, exist_ok=True)
              cv2.imwrite(str(debug_dir / "00_gray.png"), gray)

          # Preprocessing: Blur and Threshold
          # GaussianBlur helps reduce noise before thresholding
          blur = cv2.GaussianBlur(gray, (7, 7), 0)
          if debug_dir: cv2.imwrite(str(debug_dir / "01_blur.png"), blur)

          # Adaptive thresholding is generally robust to lighting changes
          thresh = cv2.adaptiveThreshold(
              blur, 255,
              cv2.ADAPTIVE_THRESH_GAUSSIAN_C, # Method
              cv2.THRESH_BINARY_INV,         # Threshold type (invert to get black lines on white)
              15,                            # Block size (must be odd) - adjust based on image size/line thickness
              4                              # Constant C subtracted from mean
          )
          if debug_dir: cv2.imwrite(str(debug_dir / "02_thresh.png"), thresh)

          # Morphological closing to connect broken lines
          kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
          closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)
          if debug_dir: cv2.imwrite(str(debug_dir / "03_closed.png"), closed)

          # Find contours
          contours, _ = cv2.findContours(
              closed,
              cv2.RETR_EXTERNAL,        # Retrieve only outer contours
              cv2.CHAIN_APPROX_SIMPLE   # Compress horizontal/vertical segments
          )

          if not contours:
              print("[Contour Finder] No contours found.")
              return None

          # Sort contours by area (descending) and filter small ones
          contours = sorted(contours, key=cv2.contourArea, reverse=True)
          min_area = gray.size * 0.05 # Require contour to be at least 5% of image area

          if debug_dir:
              img_contours = img.copy() if img.ndim == 3 else cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
              cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 1) # Draw all contours found
              cv2.imwrite(str(debug_dir / "04_all_contours.png"), img_contours)


          # Find the largest quadrilateral contour that resembles a square
          for i, cnt in enumerate(contours):
              area = cv2.contourArea(cnt)
              if area < min_area:
                  # print(f"[Contour Finder] Remaining contours too small (area {area} < {min_area}).")
                  break # No need to check smaller contours

              peri = cv2.arcLength(cnt, True)
              # Approximate the contour shape to a polygon
              approx = cv2.approxPolyDP(cnt, 0.02 * peri, True) # Epsilon factor determines accuracy

              # Check if the approximation has 4 vertices and is convex
              if len(approx) == 4 and cv2.isContourConvex(approx):
                  # Check aspect ratio of the bounding box
                  x, y, w, h = cv2.boundingRect(approx)
                  aspect_ratio = w / float(h) if h > 0 else 0

                  # Allow some tolerance for perspective distortion
                  if 0.7 < aspect_ratio < 1.3:
                      if debug_dir:
                          img_found = img.copy() if img.ndim == 3 else cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
                          cv2.drawContours(img_found, [approx], -1, (0, 0, 255), 3)
                          cv2.imwrite(str(debug_dir / f"05_found_contour_{i}.png"), img_found)
                      # print(f"[Contour Finder] Found potential grid contour (index {i}, area {area:.0f}, aspect {aspect_ratio:.2f}).")
                      return approx.reshape(4, 2).astype("float32") # Return the corner points

          print("[Contour Finder] No suitable Sudoku grid contour found.")
          return None


      def rectify_grid(
          img: np.ndarray,
          contour: np.ndarray,
          size: int = DEFAULT_RECTIFIED_SIZE
      ) -> Optional[np.ndarray]:
          """Perspective-correct the Sudoku grid to a square of given size."""
          if contour is None or contour.shape != (4, 2):
              print("[Rectifier] Invalid contour provided.")
              return None
          if img is None or img.size == 0:
              print("[Rectifier] Invalid image provided.")
              return None

          try:
              # Order the contour points: TL, TR, BR, BL
              src_pts = _order_points(contour)

              # Define the destination points for the square image
              dst_pts = np.array([
                  [0, 0],             # Top-left
                  [size - 1, 0],      # Top-right
                  [size - 1, size - 1], # Bottom-right
                  [0, size - 1],      # Bottom-left
              ], dtype="float32")

              # Calculate the perspective transform matrix
              matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)

              # Apply the perspective warp
              warped = cv2.warpPerspective(img, matrix, (size, size))
              return warped
          except Exception as e:
              print(f"[Rectifier] Error during perspective warp: {e}")
              return None


      def split_into_cells(
          rectified: np.ndarray
      ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray]]:
          """
          Split the rectified grid into GRID_SIZE × GRID_SIZE cell images.
          Applies a small margin removal.
          Returns (cells, rectified_image) or (None, None) on failure.
          """
          if rectified is None or rectified.shape[0] != rectified.shape[1]:
              print("[Splitter] Invalid rectified image provided.")
              return None, None

          h, w = rectified.shape[:2]
          if h == 0 or w == 0:
              print("[Splitter] Rectified image has zero dimension.")
              return None, None

          cell_sz_h = h // GRID_SIZE
          cell_sz_w = w // GRID_SIZE
          if cell_sz_h == 0 or cell_sz_w == 0:
              print("[Splitter] Calculated cell size is zero.")
              return None, None

          # Calculate margin to remove grid lines (e.g., 4% of cell size)
          margin_y = max(1, int(cell_sz_h * 0.04))
          margin_x = max(1, int(cell_sz_w * 0.04))

          cells: List[np.ndarray] = []
          for row in range(GRID_SIZE):
              for col in range(GRID_SIZE):
                  # Calculate cell boundaries with margin
                  y0 = row * cell_sz_h + margin_y
                  x0 = col * cell_sz_w + margin_x
                  y1 = (row + 1) * cell_sz_h - margin_y
                  x1 = (col + 1) * cell_sz_w - margin_x

                  # Ensure coordinates are valid and extract cell
                  if y0 < y1 and x0 < x1:
                      cell = rectified[y0:y1, x0:x1]
                      cells.append(cell)
                  else:
                      # Handle cases where margin is too large for cell size (should be rare)
                      # Fallback: extract cell without margin
                      y0_nomargin = row * cell_sz_h
                      x0_nomargin = col * cell_sz_w
                      y1_nomargin = (row + 1) * cell_sz_h
                      x1_nomargin = (col + 1) * cell_sz_w
                      cell = rectified[y0_nomargin:y1_nomargin, x0_nomargin:x1_nomargin]
                      # Add a blank cell if even no-margin extraction fails
                      if cell is None or cell.size == 0:
                           cell_shape = (cell_sz_h, cell_sz_w) + rectified.shape[2:] if rectified.ndim > 2 else (cell_sz_h, cell_sz_w)
                           cell = np.zeros(cell_shape, rectified.dtype) # Create blank cell
                      cells.append(cell)


          if len(cells) != GRID_SIZE * GRID_SIZE:
              print(f"[Splitter] Incorrect number of cells extracted: {len(cells)}")
              return None, rectified # Return None for cells but keep rectified image

          return cells, rectified


      def extract_cells_from_image(
          img_or_path,
          size: int = DEFAULT_RECTIFIED_SIZE,
          debug: bool = False
      ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray], Optional[np.ndarray]]:
          """
          High-level function: read image, find grid, rectify, and split into cells.
          Returns (cells, rectified_image, contour) or (None, None, None) on failure.
          """
          if isinstance(img_or_path, (str, Path)):
              img_path = str(img_or_path)
              if not Path(img_path).exists():
                  print(f"[Extractor] Image file not found: {img_path}")
                  return None, None, None
              img = cv2.imread(img_path)
              if img is None:
                  print(f"[Extractor] Failed to read image: {img_path}")
                  return None, None, None
          elif isinstance(img_or_path, np.ndarray):
              img = img_or_path.copy()
          else:
              print("[Extractor] Invalid input type (must be path or numpy array).")
              return None, None, None

          if img.size == 0:
              print("[Extractor] Input image is empty.")
              return None, None, None

          try:
              debug_dir = Path(f"debug_extract_{Path(img_path).stem}_{os.getpid()}") if debug and isinstance(img_or_path, (str, Path)) else None
              if debug and not debug_dir: debug_dir = Path(f"debug_extract_np_{os.getpid()}")

              # 1. Find Grid Contour
              contour = find_sudoku_grid_contour(img, debug_dir)
              if contour is None:
                  print("[Extractor] Failed to find Sudoku contour.")
                  return None, None, None # Contour finding failed

              # 2. Rectify Grid
              rectified = rectify_grid(img, contour, size=size)
              if rectified is None:
                  print("[Extractor] Failed to rectify grid.")
                  return None, None, contour # Rectification failed, return contour found

              if debug_dir:
                  cv2.imwrite(str(debug_dir / "06_rectified.png"), rectified)

              # 3. Split into Cells
              cells, rectified_output = split_into_cells(rectified)
              if cells is None:
                  print("[Extractor] Failed to split rectified grid into cells.")
                  # Return rectified image even if splitting fails, maybe useful for debugging
                  return None, rectified_output, contour

              if debug_dir:
                  # Save a montage of extracted cells
                  cell_h, cell_w = cells[0].shape[:2]
                  montage = np.zeros((GRID_SIZE * cell_h, GRID_SIZE * cell_w) + cells[0].shape[2:], dtype=cells[0].dtype)
                  for i, cell_img in enumerate(cells):
                      r, c = divmod(i, GRID_SIZE)
                      if cell_img.shape[:2] == (cell_h, cell_w): # Ensure shape consistency
                          montage[r*cell_h:(r+1)*cell_h, c*cell_w:(c+1)*cell_w] = cell_img
                  cv2.imwrite(str(debug_dir / "07_cells_montage.png"), montage)


              # Success
              return cells, rectified_output, contour

          except Exception as e:
              print(f"[Extractor] Unexpected error: {e}")
              import traceback
              traceback.print_exc()
              return None, None, None
    sudoku_recogniser.py: |
      """
      Command-line utility to detect a Sudoku grid in an image and recognise its digits
      using the full-grid classifier.
      """

      from __future__ import annotations

      import sys
      import time
      from pathlib import Path
      from typing import Tuple, Optional

      import cv2
      import numpy as np

      # Import the updated classifier and extractor
      import digit_classifier
      from digit_extractor import GRID_SIZE, DEFAULT_RECTIFIED_SIZE, extract_cells_from_image

      # Confidence threshold for final acceptance of a recognised digit (1-9)
      # This can be tuned based on model performance.
      FINAL_CONFIDENCE_THRESHOLD = 0.75 # Adjusted slightly


      def print_sudoku_grid(
          grid: np.ndarray,
          conf: Optional[np.ndarray] = None,
          threshold: float = FINAL_CONFIDENCE_THRESHOLD
      ) -> None:
          """
          Nicely print a 9×9 Sudoku grid.
          Marks digits below the threshold with '?' if confidences are provided.
          Expects grid values 0-9, where 0 is empty.
          """
          grid = np.asarray(grid)
          if grid.shape != (GRID_SIZE, GRID_SIZE):
              print(f"[print_sudoku_grid] Invalid grid shape: {grid.shape}")
              return

          print("-" * 25) # Top border
          for r in range(GRID_SIZE):
              if r > 0 and r % 3 == 0:
                  print("|-------+-------+-------|") # Separator line

              line = ["|"] # Start of row
              for c in range(GRID_SIZE):
                  digit = grid[r, c]
                  token = ""
                  if digit == 0:
                      token = "." # Represent empty cell
                  else:
                      token = str(digit)
                      # If confidence is provided and below threshold, mark as uncertain
                      if conf is not None and conf.shape == (GRID_SIZE, GRID_SIZE) and conf[r, c] < threshold:
                          token = "?"

                  line.append(f" {token} ") # Add token with spacing

                  if (c + 1) % 3 == 0:
                      line.append("|") # Add column separator

              print("".join(line)) # Print the row
          print("-" * 25) # Bottom border
          print() # Add a blank line after the grid


      def display_results_on_image(
          rectified: Optional[np.ndarray],
          grid: np.ndarray,
          conf: Optional[np.ndarray] = None,
          threshold: float = FINAL_CONFIDENCE_THRESHOLD
      ) -> Optional[np.ndarray]:
          """
          Draw recognised digits (above threshold) onto the rectified grid image.
          """
          if rectified is None:
              print("[Display] No rectified image provided.")
              return None

          # Ensure image is BGR for drawing colors
          img_display = (
              cv2.cvtColor(rectified, cv2.COLOR_GRAY2BGR)
              if rectified.ndim == 2 else rectified.copy()
          )
          h, w = img_display.shape[:2]
          if h == 0 or w == 0: return None # Invalid image dimensions

          cell_h, cell_w = h // GRID_SIZE, w // GRID_SIZE
          if cell_h == 0 or cell_w == 0: return img_display # Cannot draw if cells are too small

          # Choose font properties
          font_face = cv2.FONT_HERSHEY_SIMPLEX
          font_scale_base = min(cell_h, cell_w) / 35.0 # Scale font based on cell size
          font_thickness = max(1, int(font_scale_base * 1.5))

          for r in range(GRID_SIZE):
              for c in range(GRID_SIZE):
                  digit = grid[r, c]
                  confidence = conf[r, c] if conf is not None else 1.0 # Assume high conf if not provided

                  # Only draw digits that are not empty and meet the confidence threshold
                  if digit != 0 and confidence >= threshold:
                      text = str(digit)

                      # Calculate text size to center it
                      (text_w, text_h), baseline = cv2.getTextSize(text, font_face, font_scale_base, font_thickness)

                      # Calculate center position of the cell
                      center_x = c * cell_w + cell_w // 2
                      center_y = r * cell_h + cell_h // 2

                      # Calculate bottom-left corner of the text for centering
                      text_x = center_x - text_w // 2
                      text_y = center_y + text_h // 2

                      # Draw the text
                      cv2.putText(
                          img_display,
                          text,
                          (text_x, text_y),
                          font_face,
                          font_scale_base,
                          (0, 200, 0), # Green color for recognised digits
                          font_thickness,
                          cv2.LINE_AA # Anti-aliased text
                      )
                  # Optional: Draw uncertain digits differently (e.g., red '?')
                  # elif digit != 0 and conf is not None and confidence < threshold:
                  #     text = "?"
                  #     (text_w, text_h), baseline = cv2.getTextSize(text, font_face, font_scale_base, font_thickness)
                  #     center_x = c * cell_w + cell_w // 2
                  #     center_y = r * cell_h + cell_h // 2
                  #     text_x = center_x - text_w // 2
                  #     text_y = center_y + text_h // 2
                  #     cv2.putText(img_display, text, (text_x, text_y), font_face, font_scale_base, (0, 0, 255), font_thickness, cv2.LINE_AA)


          return img_display


      def recognise_sudoku(
          img_path: Path,
          classifier: digit_classifier.DigitClassifier
      ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
          """
          Extract rectified grid and run the full-grid classifier.

          Returns:
              Tuple of (predicted_grid, confidence_grid, rectified_image).
              predicted_grid: (9, 9) int array, 0 for empty/uncertain.
              confidence_grid: (9, 9) float array of confidences.
              rectified_image: The (e.g., 252x252) rectified image.
              Returns (None, None, None) on failure.
          """
          print(f"Processing {img_path.name}...")
          start_time = time.time()

          # 1. Extract the rectified grid image
          # We don't need individual cells from the extractor anymore
          # Use the input size expected by the classifier model
          rectified_size = classifier._model_input_shape[0]
          _, rectified_img, _ = extract_cells_from_image(
              img_path,
              size=rectified_size,
              debug=False # Set to True for extraction debugging images
          )

          if rectified_img is None:
              print("❌ Failed to extract or rectify the Sudoku grid.")
              return None, None, None
          print(f"✅ Grid extracted and rectified ({time.time() - start_time:.2f}s)")
          extract_time = time.time()

          # 2. Recognise digits using the full-grid classifier
          print("🧠 Running grid recognition model...")
          predicted_grid, confidence_grid = classifier.recognise_grid(
              rectified_img,
              confidence_threshold=FINAL_CONFIDENCE_THRESHOLD
          )

          if predicted_grid is None or confidence_grid is None:
              print("❌ Model recognition failed.")
              return None, None, rectified_img # Return rectified image even if recognition fails

          elapsed_time = time.time() - start_time
          print(f"✅ Recognition complete ({time.time() - extract_time:.2f}s)")
          print(f"⏱️ Total time: {elapsed_time:.2f}s")

          return predicted_grid, confidence_grid, rectified_img


      def main() -> None:
          if len(sys.argv) < 2:
              print("Usage: python sudoku_recogniser.py <image_path> [--no-train]")
              print("  <image_path>: Path to the Sudoku image file.")
              print("  --no-train: Optional flag to prevent training if the model is missing.")
              sys.exit(0)

          img_path = Path(sys.argv[1])
          if not img_path.is_file():
              print(f"❌ Error: Image file not found at '{img_path}'")
              sys.exit(1)

          # Check for --no-train flag
          force_no_train = "--no-train" in sys.argv

          # Instantiate the classifier
          # It will try to load the model. Training is required if the model file
          # doesn't exist, unless --no-train is specified.
          model_exists = Path(digit_classifier.MODEL_FILENAME).exists()
          training_required = not model_exists

          if training_required and force_no_train:
              print("Model file not found, but --no-train specified. Exiting.")
              sys.exit(1)
          elif training_required:
              print(f"⚠️ Model file '{digit_classifier.MODEL_FILENAME}' not found.")
              print("Initiating training process...")
              classifier = digit_classifier.DigitClassifier(training_required=True)
              classifier.train() # Use default training parameters from classifier script
              # Check if model was successfully created after training
              if classifier.model is None:
                   print("❌ Training failed to produce a model. Exiting.")
                   sys.exit(1)
              print("✅ Training complete. Proceeding with recognition...")
          else:
              # Model exists or --no-train was used with existing model
              classifier = digit_classifier.DigitClassifier(training_required=False)
              if classifier.model is None:
                   print(f"❌ Failed to load existing model '{digit_classifier.MODEL_FILENAME}'. Exiting.")
                   sys.exit(1)
              print(f"✅ Model '{digit_classifier.MODEL_FILENAME}' loaded.")


          # Recognise the Sudoku in the input image
          try:
              grid, conf, rectified = recognise_sudoku(img_path, classifier)

              if grid is None or conf is None:
                  print("\n❌ Sudoku recognition process failed.")
                  # Rectified might still exist, show it if possible
                  if rectified is not None:
                       cv2.imshow("Failed Extraction/Rectification", rectified)
                       cv2.waitKey(0)
                  sys.exit(1)

              # Print the recognised grid to the console
              print("\n--- Recognised Sudoku Grid ---")
              print_sudoku_grid(grid, conf, threshold=FINAL_CONFIDENCE_THRESHOLD)

              # Display the rectified image with recognised digits overlaid
              result_img = display_results_on_image(rectified, grid, conf, threshold=FINAL_CONFIDENCE_THRESHOLD)
              if result_img is not None:
                  print("ℹ️ Displaying recognised grid on image. Press any key to close.")
                  cv2.imshow("Sudoku Recognition Result", result_img)
                  cv2.waitKey(0)
              else:
                  print("ℹ️ Could not generate result image.")

          except Exception as e:
              print(f"\n❌ An unexpected error occurred: {e}")
              import traceback
              traceback.print_exc()
              sys.exit(1)
          finally:
              cv2.destroyAllWindows() # Ensure any OpenCV windows are closed


      if __name__ == "__main__":
          main()
    sudoku_renderer.py: |
      """
      Synthetic Sudoku image generator for on‑the‑fly training data.
      Generates puzzles based on valid, solvable Sudoku grids.
      """

      import random
      import time
      from pathlib import Path
      from typing import Tuple, Optional, List

      import cv2
      import numpy as np
      import keras

      GRID_SIZE = 9
      BASE_IMAGE_SIZE = 1000 # Initial rendering size before warp
      CELL_SIZE = BASE_IMAGE_SIZE // GRID_SIZE
      # Ensure MNIST is loaded only once
      MNIST_BUCKETS: Optional[dict[int, list[np.ndarray]]] = None

      # --- Sudoku Generation Helpers ---

      def _is_safe(grid: np.ndarray, row: int, col: int, num: int) -> bool:
          """Check if it's safe to place 'num' at grid[row, col]."""
          # Check row
          if num in grid[row, :]:
              return False
          # Check column
          if num in grid[:, col]:
              return False
          # Check 3x3 box
          start_row, start_col = 3 * (row // 3), 3 * (col // 3)
          if num in grid[start_row:start_row + 3, start_col:start_col + 3]:
              return False
          return True

      def _find_empty(grid: np.ndarray) -> Optional[Tuple[int, int]]:
          """Find an empty cell (marked with 0)."""
          for r in range(GRID_SIZE):
              for c in range(GRID_SIZE):
                  if grid[r, c] == 0:
                      return (r, c)
          return None

      def _solve_sudoku(grid: np.ndarray) -> bool:
          """Solve the Sudoku grid in-place using backtracking."""
          find = _find_empty(grid)
          if not find:
              return True  # Solved
          else:
              row, col = find

          nums = list(range(1, GRID_SIZE + 1))
          random.shuffle(nums) # Introduce randomness for generation

          for num in nums:
              if _is_safe(grid, row, col, num):
                  grid[row, col] = num
                  if _solve_sudoku(grid):
                      return True
                  grid[row, col] = 0  # Backtrack

          return False

      def _generate_sudoku_solution() -> np.ndarray:
          """Generate a complete, valid Sudoku grid."""
          while True: # Keep trying until a valid solution is found
              grid = np.zeros((GRID_SIZE, GRID_SIZE), dtype=int)
              if _solve_sudoku(grid):
                  return grid
              # print("Failed to generate solution, retrying...") # Optional debug
              time.sleep(0.01) # Avoid busy-waiting if something goes wrong

      def _create_puzzle(solution: np.ndarray, difficulty: float = 0.5) -> np.ndarray:
          """
          Create a puzzle by removing cells from a solution.
          Difficulty: approx. fraction of cells to remove (0.1 easy, 0.5 medium, 0.7 hard).
          Note: This simple removal doesn't guarantee unique solvability, but ensures
                the underlying pattern is valid.
          """
          puzzle = solution.copy()
          num_cells = GRID_SIZE * GRID_SIZE
          num_remove = int(num_cells * difficulty)

          attempts = 0
          removed_count = 0
          while removed_count < num_remove and attempts < num_cells * 2:
              row, col = random.randint(0, GRID_SIZE - 1), random.randint(0, GRID_SIZE - 1)
              if puzzle[row, col] != 0:
                  puzzle[row, col] = 0
                  removed_count += 1
              attempts += 1
          # print(f"Removed {removed_count} cells for difficulty {difficulty}") # Optional debug
          return puzzle

      # --- MNIST Loading ---

      def _load_mnist_digits() -> dict[int, list[np.ndarray]]:
          """
          Download MNIST once and bucket images by label for rendering.
          """
          global MNIST_BUCKETS
          if MNIST_BUCKETS is not None:
              return MNIST_BUCKETS

          print("Loading MNIST dataset for rendering...")
          try:
              (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
              images = np.concatenate([x_train, x_test])
              labels = np.concatenate([y_train, y_test])

              buckets: dict[int, list[np.ndarray]] = {i: [] for i in range(10)}
              for img, lbl in zip(images, labels):
                  # Invert (black digit on white bg) and add padding
                  inv = cv2.bitwise_not(img)
                  padded = cv2.copyMakeBorder(
                      inv, 4, 4, 4, 4,
                      cv2.BORDER_CONSTANT, value=255 # White padding
                  )
                  buckets[int(lbl)].append(padded)
              print("MNIST loaded.")
              MNIST_BUCKETS = buckets
              return MNIST_BUCKETS
          except Exception as e:
              print(f"Error loading MNIST: {e}. Will only use font rendering.")
              MNIST_BUCKETS = {i: [] for i in range(10)} # Empty buckets
              return MNIST_BUCKETS


      # --- Renderer Class ---

      class SudokuRenderer:
          """
          Render a random Sudoku puzzle (based on a valid solution) to a synthetic image.
          """

          def __init__(self) -> None:
              self.mnist_buckets = _load_mnist_digits() # Ensure MNIST is loaded/attempted

          def _digit_source(self, digit: int) -> Tuple[Optional[np.ndarray], str]:
              """Choose between MNIST digit or font rendering."""
              sources = []
              # Only allow MNIST if buckets[digit] is not empty
              if self.mnist_buckets and self.mnist_buckets.get(digit):
                  sources.append("mnist")
              sources.append("font") # Always allow font as fallback
              choice = random.choice(sources)

              if choice == "mnist":
                  img = random.choice(self.mnist_buckets[digit])
                  # Ensure it's BGR for consistency
                  if img.ndim == 2:
                      img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                  return img, "mnist"
              # Fallback to font rendering if MNIST chosen but failed, or if font chosen
              return None, "font"

          def render_sudoku(
              self,
              grid_spec: Optional[np.ndarray] = None,
              *,
              allow_empty: bool = True, # If True, difficulty is random, otherwise uses grid_spec or full solution
              difficulty: float = 0.5 # Used if allow_empty=True and grid_spec=None
          ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
              """
              Generate a synthetic Sudoku image based on a valid grid.

              Args:
                  grid_spec: A specific (9, 9) puzzle grid (0 for empty). If None, generates randomly.
                  allow_empty: If True and grid_spec is None, generate a puzzle with random difficulty.
                               If False and grid_spec is None, render the full solution.
                  difficulty: Target fraction of empty cells if generating randomly (approx).

              Returns:
                  Tuple of (image, ground_truth_puzzle_grid, warped_corners).
                  Returns (None, None, None) on generation failure.
              """
              try:
                  if grid_spec is not None:
                      # Use the provided puzzle spec directly
                      gt_puzzle = grid_spec.copy()
                      # We don't have the full solution here, but the puzzle itself is the ground truth
                  else:
                      # Generate a full solution first
                      solution = _generate_sudoku_solution()
                      if not allow_empty:
                          # Render the full solution
                          gt_puzzle = solution.copy()
                      else:
                          # Create a puzzle by removing digits from the solution
                          rand_difficulty = random.uniform(0.3, 0.7) # Randomize difficulty
                          gt_puzzle = _create_puzzle(solution, difficulty=rand_difficulty)

                  # --- Start Rendering ---
                  bg_color = tuple(random.randint(200, 240) for _ in range(3))
                  img = np.full((BASE_IMAGE_SIZE, BASE_IMAGE_SIZE, 3), bg_color, np.uint8)

                  # Draw grid lines
                  for i in range(GRID_SIZE + 1):
                      major = (i % 3 == 0)
                      thickness = random.randint(3 if major else 1, 5 if major else 3)
                      color = (0, 0, 0) # Black lines
                      # Horizontal lines
                      cv2.line(img, (0, i * CELL_SIZE), (BASE_IMAGE_SIZE, i * CELL_SIZE), color, thickness)
                      # Vertical lines
                      cv2.line(img, (i * CELL_SIZE, 0), (i * CELL_SIZE, BASE_IMAGE_SIZE), color, thickness)

                  # Draw digits onto the grid based on gt_puzzle
                  for r in range(GRID_SIZE):
                      for c in range(GRID_SIZE):
                          digit_to_render = gt_puzzle[r, c]
                          if digit_to_render == 0:
                              continue # Skip empty cells

                          src_img, src_type = self._digit_source(digit_to_render)
                          scale = random.uniform(0.5, 0.8) # Size relative to cell
                          target_size = int(CELL_SIZE * scale)
                          if target_size < 10: continue # Skip if too small

                          # Calculate center position with jitter
                          center_x = c * CELL_SIZE + CELL_SIZE // 2
                          center_y = r * CELL_SIZE + CELL_SIZE // 2
                          dx = int(random.uniform(-0.1, 0.1) * CELL_SIZE)
                          dy = int(random.uniform(-0.1, 0.1) * CELL_SIZE)
                          cx, cy = center_x + dx, center_y + dy

                          if src_type == "mnist" and src_img is not None:
                              # Resize MNIST digit
                              digit_img = cv2.resize(src_img, (target_size, target_size), interpolation=cv2.INTER_AREA)

                              # Random rotation
                              angle = random.uniform(-10, 10)
                              M = cv2.getRotationMatrix2D((target_size / 2, target_size / 2), angle, 1)
                              digit_img = cv2.warpAffine(
                                  digit_img, M, (target_size, target_size),
                                  borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255) # Match padding
                              )

                              # Create mask (assuming black digit on white background from MNIST processing)
                              mask = cv2.cvtColor(digit_img, cv2.COLOR_BGR2GRAY)
                              _, mask = cv2.threshold(mask, 250, 255, cv2.THRESH_BINARY_INV) # Invert to get digit mask

                              # Calculate ROI in the main image
                              x0 = max(0, cx - target_size // 2)
                              y0 = max(0, cy - target_size // 2)
                              x1 = min(img.shape[1], x0 + target_size)
                              y1 = min(img.shape[0], y0 + target_size)
                              roi = img[y0:y1, x0:x1]

                              # Adjust digit image and mask if ROI is smaller (near edges)
                              digit_roi = digit_img[0:roi.shape[0], 0:roi.shape[1]]
                              mask_roi = mask[0:roi.shape[0], 0:roi.shape[1]]
                              mask_inv_roi = cv2.bitwise_not(mask_roi)

                              # Place digit using mask
                              bg_region = cv2.bitwise_and(roi, roi, mask=mask_inv_roi)
                              fg_region = cv2.bitwise_and(digit_roi, digit_roi, mask=mask_roi)
                              img[y0:y1, x0:x1] = cv2.add(bg_region, fg_region)

                          else: # Use font rendering
                              font = cv2.FONT_HERSHEY_SIMPLEX # Or try FONT_HERSHEY_DUPLEX etc.
                              thickness = random.randint(2, 4)
                              # Adjust font scale to fit target size
                              font_scale = cv2.getFontScaleFromHeight(font, target_size, thickness) * 0.8
                              text = str(digit_to_render)
                              (tw, th), _ = cv2.getTextSize(text, font, font_scale, thickness)

                              # Calculate position for font rendering
                              text_x = cx - tw // 2
                              text_y = cy + th // 2
                              cv2.putText(img, text, (text_x, text_y),
                                          font, font_scale, (0, 0, 0), thickness, cv2.LINE_AA)

                  # --- Post-processing ---
                  # Add noise
                  noise_level = random.uniform(5, 15)
                  noise = np.random.normal(0, noise_level, img.shape).astype(np.float32)
                  noisy_img = np.clip(img.astype(np.float32) + noise, 0, 255).astype(np.uint8)

                  # Random perspective warp
                  h, w = noisy_img.shape[:2]
                  orig_corners = np.array([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype="float32")
                  shift_factor = random.uniform(0.02, 0.15) # Reduced max shift slightly
                  max_dx, max_dy = w * shift_factor, h * shift_factor

                  # Generate new corner positions with some randomness
                  warped_corners = np.array([
                      [random.uniform(0, max_dx), random.uniform(0, max_dy)], # Top-left
                      [w - 1 - random.uniform(0, max_dx), random.uniform(0, max_dy)], # Top-right
                      [w - 1 - random.uniform(0, max_dx), h - 1 - random.uniform(0, max_dy)], # Bottom-right
                      [random.uniform(0, max_dx), h - 1 - random.uniform(0, max_dy)], # Bottom-left
                  ], dtype="float32")

                  # Ensure corners maintain roughly the correct order (prevent extreme warps)
                  # Simple check: ensure TL x < TR x, BL x < BR x, TL y < BL y, TR y < BR y
                  if (warped_corners[0,0] >= warped_corners[1,0] or \
                      warped_corners[3,0] >= warped_corners[2,0] or \
                      warped_corners[0,1] >= warped_corners[3,1] or \
                      warped_corners[1,1] >= warped_corners[2,1]):
                       # If order is messed up, use less aggressive warp or skip warp
                       warped_corners = orig_corners # Fallback to no warp this time

                  M = cv2.getPerspectiveTransform(orig_corners, warped_corners)

                  # Calculate output bounds for warped image
                  out_w = int(np.max(warped_corners[:, 0])) + 1
                  out_h = int(np.max(warped_corners[:, 1])) + 1
                  out_w = max(out_w, 100) # Ensure minimum size
                  out_h = max(out_h, 100)

                  warped_img = cv2.warpPerspective(
                      noisy_img, M, (out_w, out_h),
                      flags=cv2.INTER_LINEAR, # Smoother interpolation
                      borderMode=cv2.BORDER_REPLICATE # Replicate border pixels
                  )

                  # Apply slight blur after warping
                  final_img = cv2.GaussianBlur(warped_img, (3, 3), 0)

                  # Return the final image, the puzzle grid (0 for empty), and the warped corners
                  return final_img, gt_puzzle, warped_corners

              except Exception as e:
                  print(f"[Renderer Error] Failed to render Sudoku: {e}")
                  import traceback
                  traceback.print_exc()
                  return None, None, None


      def generate_and_save_test_example(
          prefix: str = "epoch_test_sudoku",
          force: bool = False
      ) -> Tuple[Optional[str], Optional[np.ndarray]]:
          """
          Generate or load a fixed Sudoku test example for epoch callbacks.
          Returns (image_path, ground_truth_puzzle_grid).
          """
          img_path = Path(f"{prefix}.png")
          gt_path = Path(f"{prefix}_gt.npy")

          if not force and img_path.exists() and gt_path.exists():
              try:
                  gt = np.load(gt_path)
                  # Basic check if loaded files are valid
                  if cv2.imread(str(img_path)) is not None and gt.shape == (GRID_SIZE, GRID_SIZE):
                       print(f"Loaded existing test example: {img_path}, {gt_path}")
                       return str(img_path), gt
                  else:
                       print("Existing test example files corrupted, regenerating...")
              except Exception as e:
                  print(f"Error loading existing test example ({e}), regenerating...")

          print("Generating new test example...")
          renderer = SudokuRenderer()
          # Define a specific puzzle grid (0 for empty)
          # This puzzle should ideally be solvable and have a unique solution
          # Example puzzle (source: websudoku.com easy)
          test_puzzle_grid = np.array([
              [0, 0, 3, 0, 2, 0, 6, 0, 0],
              [9, 0, 0, 3, 0, 5, 0, 0, 1],
              [0, 0, 1, 8, 0, 6, 4, 0, 0],
              [0, 0, 8, 1, 0, 2, 9, 0, 0],
              [7, 0, 0, 0, 0, 0, 0, 0, 8],
              [0, 0, 6, 7, 0, 8, 2, 0, 0],
              [0, 0, 2, 6, 0, 9, 5, 0, 0],
              [8, 0, 0, 2, 0, 3, 0, 0, 9],
              [0, 0, 5, 0, 1, 0, 3, 0, 0]
          ], dtype=int)

          # Render this specific puzzle
          img, gt, _ = renderer.render_sudoku(grid_spec=test_puzzle_grid)

          if img is None or gt is None:
              print("[Error] Failed to generate test example image.")
              return None, None

          try:
              cv2.imwrite(str(img_path), img)
              np.save(gt_path, gt)
              print(f"Saved new test example: {img_path}, {gt_path}")
              return str(img_path), gt
          except Exception as e:
              print(f"[Error] Failed to save test example: {e}")
              return None, None

      # Example usage for debugging
      if __name__ == "__main__":
          print("Generating a sample Sudoku image...")
          renderer = SudokuRenderer()
          img, gt, corners = renderer.render_sudoku(allow_empty=True, difficulty=0.6)

          if img is not None:
              print("Generated Ground Truth Puzzle Grid:")
              print(gt)
              cv2.imwrite("sample_sudoku_generated.png", img)
              print("Saved sample image to sample_sudoku_generated.png")

              # Also generate the fixed test example if needed
              generate_and_save_test_example(force=True)
          else:
              print("Failed to generate sample image.")
  prev_file_contents:
    digit_classifier.py: |
      """
      SudokuBot – Digit Classifier (Full Grid Prediction)
      Version 2025-04-22

      Major Changes:
      - Model predicts all 81 cells from the rectified grid image at once.
      - Uses a Fully Convolutional Network (FCN) based on ResNet blocks.
      - Data generator yields full grid images and corresponding label grids.
      - Training data uses puzzles derived from valid, solvable Sudoku solutions.
      - Preprocessing and augmentation apply to the full grid image.
      """

      # ------------------------------------------------------------------ #
      # 1.  choose backend BEFORE importing keras
      # ------------------------------------------------------------------ #
      import os
      os.environ["KERAS_BACKEND"] = "torch"  # must be first – do NOT move

      # ------------------------------------------------------------------ #
      # 2.  std‑lib & 3rd‑party imports
      # ------------------------------------------------------------------ #
      import gc
      import random
      from pathlib import Path
      from typing import Callable, Generator, Optional, Tuple

      import cv2
      import numpy as np
      import torch
      import keras
      from keras import callbacks, layers, models, activations, regularizers

      # ------------------------------------------------------------------ #
      # 3.  project‑local imports
      # ------------------------------------------------------------------ #
      try:
          # Use the updated renderer and extractor
          from sudoku_renderer import SudokuRenderer, generate_and_save_test_example
          from digit_extractor import (
              GRID_SIZE,
              DEFAULT_RECTIFIED_SIZE, # Use the size defined in extractor
              extract_cells_from_image,
              rectify_grid,
              # split_into_cells is not directly needed by the classifier anymore
          )
          import sudoku_recogniser # Needed for printing grids in callback
      except ImportError as e:
          print(f"Error importing local modules: {e}")
          print("Please ensure sudoku_renderer.py, digit_extractor.py, and sudoku_recogniser.py are available.")
          # Provide dummy implementations or raise error if essential
          GRID_SIZE = 9
          DEFAULT_RECTIFIED_SIZE = 252
          class SudokuRenderer:
              def render_sudoku(self, allow_empty=True, grid_spec=None): return None, None, None
          def generate_and_save_test_example(force=False): return Path("dummy_test.png"), np.zeros((9,9), dtype=int)
          def extract_cells_from_image(path, size=252, debug=False): return [], np.zeros((size,size), dtype=np.uint8), None
          class sudoku_recogniser:
              FINAL_CONFIDENCE_THRESHOLD = 0.8
              @staticmethod
              def print_sudoku_grid(grid, confs=None, threshold=0.0): pass


      # ------------------------------------------------------------------ #
      # 4.  constants
      # ------------------------------------------------------------------ #
      MODEL_FILENAME = "sudoku_full_grid_classifier_fcn.keras" # New filename for the new model type
      # Input shape based on the rectified grid size from digit_extractor
      MODEL_INPUT_SHAPE = (DEFAULT_RECTIFIED_SIZE, DEFAULT_RECTIFIED_SIZE, 1) # Grayscale input
      NUM_CLASSES = 11  # digits 0-9 + "empty"
      EMPTY_LABEL = 10  # Label used for empty cells in the target data (y)

      # Training parameters
      EPOCHS = 25 # Might need more epochs for a larger model/task
      STEPS_PER_EPOCH = 100 # Adjust based on data generation speed and dataset size
      BATCH_SIZE = 16 # Reduced batch size due to larger input images
      VALIDATION_STEPS = 30

      # Type alias for data batches
      DataBatch = Tuple[np.ndarray, np.ndarray] # (batch_of_grids, batch_of_labels)

      # ------------------------------------------------------------------ #
      # 5.  data generator (simplified for full grids)
      # ------------------------------------------------------------------ #
      def sudoku_data_generator(
          renderer: SudokuRenderer,
          batch_size: int,
          preprocess_func: Callable[[np.ndarray], Optional[np.ndarray]],
          augment_func: Optional[Callable[[np.ndarray], np.ndarray]], # Optional augmentation
          input_shape: Tuple[int, int, int], # e.g., (252, 252, 1)
      ) -> Generator[DataBatch, None, None]:
          """
          Yields batches of (preprocessed_grid_image, target_label_grid).
          Generates valid Sudoku puzzles on the fly.
          """
          target_h, target_w, target_c = input_shape
          is_grayscale = (target_c == 1)

          batch_counter = 0
          while True:
              batch_x = np.zeros((batch_size, target_h, target_w, target_c), dtype="float32")
              batch_y = np.zeros((batch_size, GRID_SIZE, GRID_SIZE), dtype="int64")
              
              items_in_batch = 0
              while items_in_batch < batch_size:
                  # Generate a rendered Sudoku image and its ground truth puzzle grid (0 for empty)
                  img, gt_puzzle_grid, corners = renderer.render_sudoku(allow_empty=True) # Let renderer handle difficulty

                  if img is None or gt_puzzle_grid is None or corners is None:
                      # print("[Generator] Renderer failed, skipping.")
                      time.sleep(0.1) # Avoid busy-looping if renderer fails consistently
                      continue

                  # Rectify the grid using the known corners
                  # Use the target input size for rectification directly
                  rectified = rectify_grid(img, corners, size=target_h) # Assuming target_h == target_w
                  if rectified is None:
                      # print("[Generator] Rectification failed, skipping.")
                      continue

                  # Preprocess the entire rectified grid image
                  processed_grid = preprocess_func(rectified)
                  if processed_grid is None:
                      # print("[Generator] Preprocessing failed, skipping.")
                      continue

                  # Apply augmentation if provided (usually only for training)
                  if augment_func:
                      processed_grid = augment_func(processed_grid)

                  # Ensure the processed grid has the correct shape (H, W, C)
                  if processed_grid.shape != (target_h, target_w, target_c):
                       print(f"[Generator Warning] Processed grid shape mismatch: expected {(target_h, target_w, target_c)}, got {processed_grid.shape}. Skipping.")
                       continue


                  # Convert the ground truth puzzle grid (0 for empty) to the target format
                  # where empty cells are represented by EMPTY_LABEL (10)
                  target_labels = gt_puzzle_grid.copy()
                  target_labels[target_labels == 0] = EMPTY_LABEL

                  # Add to batch
                  batch_x[items_in_batch] = processed_grid
                  batch_y[items_in_batch] = target_labels
                  items_in_batch += 1

              # Yield the complete batch
              batch_counter += 1
              # Optional debug print
              # if batch_counter % 10 == 0:
              #     print(f"[Generator] Yielding batch {batch_counter}. Example label counts: {np.bincount(batch_y[0].flatten(), minlength=NUM_CLASSES)}")

              yield batch_x, batch_y
              # No need for explicit gc.collect() here usually, Python handles it.


      # ------------------------------------------------------------------ #
      # 6.  classifier object (handles full grid model)
      # ------------------------------------------------------------------ #
      class DigitClassifier:
          """
          Handles loading, training and inference of the FCN Sudoku grid classifier.
          """

          # -------------------------------------------------------------- #
          # constructor
          # -------------------------------------------------------------- #
          def __init__(
              self,
              model_path: Optional[str | Path] = None,
              training_required: bool = False,
          ) -> None:
              self.model_path = Path(model_path) if model_path else Path(MODEL_FILENAME)
              self.model: Optional[keras.Model] = None
              self._model_input_shape = MODEL_INPUT_SHAPE # e.g., (252, 252, 1)

              if not training_required and self.model_path.exists():
                  print(f"Attempting to load model from {self.model_path}...")
                  try:
                      self.model = keras.models.load_model(self.model_path)
                      # Check if loaded model's input shape matches config
                      # Keras models sometimes store input shape as (None, H, W, C)
                      loaded_shape = self.model.input_shape[1:]
                      if loaded_shape != self._model_input_shape:
                          print(f"[Warning] Loaded model input shape {loaded_shape} "
                                f"differs from expected {self._model_input_shape}. Mismatch may cause errors.")
                      print(f"Full-grid classifier model loaded successfully.")
                  except Exception as e:
                      print(f"[Error] Failed to load model from {self.model_path}: {e}")
                      print("Will build and train a new model if training is enabled.")
                      self.model = None # Ensure model is None if loading failed

              # Handle training_required flag
              if training_required and self.model is not None:
                   print("Training required: Ignoring previously loaded model and building a new one.")
                   self.model = None
              elif training_required and self.model is None:
                   print("Training required: Model will be built.")
              elif not training_required and self.model is None:
                   print("Model not found or failed to load, and training not required. Classifier is inactive.")


          # -------------------------------------------------------------- #
          # ResNet-style building block (same as before)
          # -------------------------------------------------------------- #
          def _residual_block(self, x, filters, strides=1, activation="relu"):
              """Basic residual block."""
              shortcut = x
              # Downsample shortcut if needed
              if strides > 1 or shortcut.shape[-1] != filters:
                  shortcut = layers.Conv2D(
                      filters, 1, strides=strides, use_bias=False, kernel_initializer="he_normal",
                      kernel_regularizer=regularizers.l2(1e-5) # Added slight L2 regularization
                  )(shortcut)
                  shortcut = layers.BatchNormalization()(shortcut)

              # First convolution
              y = layers.Conv2D(
                  filters, 3, strides=strides, padding="same", use_bias=False, kernel_initializer="he_normal",
                  kernel_regularizer=regularizers.l2(1e-5)
              )(x)
              y = layers.BatchNormalization()(y)
              y = layers.Activation(activation)(y)

              # Second convolution
              y = layers.Conv2D(
                  filters, 3, padding="same", use_bias=False, kernel_initializer="he_normal",
                  kernel_regularizer=regularizers.l2(1e-5)
              )(y)
              y = layers.BatchNormalization()(y)

              # Add shortcut
              y = layers.Add()([shortcut, y])
              y = layers.Activation(activation)(y)
              return y

          # -------------------------------------------------------------- #
          # backbone (FCN for full grid prediction)
          # -------------------------------------------------------------- #
          def _build_cnn_model(self) -> keras.Model:
              """Builds a Fully Convolutional Network (FCN) for grid prediction."""
              activation_func = "relu" # Or 'gelu'

              x_in = keras.Input(shape=self._model_input_shape) # e.g., (252, 252, 1)

              # --- Encoder Path (Downsampling) ---
              # Initial Conv Layer (Stem)
              # Use stride 3 to quickly reduce dimensions: 252 -> 84
              filters = 32
              x = layers.Conv2D(filters, 7, strides=3, padding="same", use_bias=False, kernel_initializer="he_normal")(x_in)
              x = layers.BatchNormalization()(x)
              x = layers.Activation(activation_func)(x)
              # x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # Optional extra pooling

              # Residual Blocks with increasing filters and downsampling
              # Block 1: 84x84 -> 84x84 (filters=32)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 2: 84x84 -> 28x28 (filters=64, stride=3)
              filters *= 2 # 64
              x = self._residual_block(x, filters, strides=3, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 3: 28x28 -> 28x28 (filters=128) - Stride 1 here
              filters *= 2 # 128
              x = self._residual_block(x, filters, strides=1, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 4: 28x28 -> 14x14 (filters=256, stride=2) - Aiming for spatial dim > 9
              filters *= 2 # 256
              x = self._residual_block(x, filters, strides=2, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # --- Prediction Head ---
              # At this point, spatial dimension is 14x14. We need 9x9 output.
              # Option 1: Use a Conv layer with stride to reduce size (might lose info)
              # Option 2: Use Adaptive Pooling (if available/easy in Keras backend)
              # Option 3: Use Conv + Upsampling (more complex)
              # Option 4: Use a final Conv layer that implicitly handles the size reduction (less common)

              # Let's try a Conv2D layer designed to output the correct spatial dimensions.
              # We need to get closer to 9x9. Add another block?
              # Block 5: 14x14 -> 7x7 (filters=512, stride=2)
              # filters *= 2 # 512
              # x = self._residual_block(x, filters, strides=2, activation=activation_func)
              # x = self._residual_block(x, filters, strides=1, activation=activation_func)
              # Now spatial dim is 7x7. This is too small.

              # Backtrack: Let's stop at 14x14 (Block 4 output).
              # How to get to (9, 9, NUM_CLASSES)?
              # Use a 1x1 Conv to reduce filters, then maybe resize/crop or use specific conv?

              # Try a final Conv layer with appropriate kernel/padding to target 9x9.
              # Input to this layer is (None, 14, 14, 256)
              # Output needed is (None, 9, 9, NUM_CLASSES)

              # Use a 1x1 convolution to adjust the number of channels first
              x = layers.Conv2D(128, 1, padding='same', activation=activation_func, kernel_initializer='he_normal')(x)
              x = layers.BatchNormalization()(x)
              # Now (None, 14, 14, 128)

              # Use a final Conv2D layer to produce the output map.
              # A kernel size of 6 with valid padding on a 14x14 input gives (14-6+1) = 9x9 output.
              # Stride 1 is implicit.
              x = layers.Conv2D(
                  filters=NUM_CLASSES,
                  kernel_size=6, # Kernel size chosen to map 14x14 -> 9x9 with 'valid' padding
                  padding="valid", # 'valid' means no padding
                  activation=None, # Apply softmax separately across the class dimension
                  kernel_initializer='he_normal',
                  name="final_conv_logits"
              )(x)
              # Output shape should now be (None, 9, 9, NUM_CLASSES)

              # Apply Softmax activation across the last axis (classes)
              y_out = layers.Activation("softmax", name="output_softmax")(x)

              # Create the model
              model = models.Model(x_in, y_out, name="fcn_sudoku_grid")

              # Compile the model
              optimizer = keras.optimizers.Adam(learning_rate=5e-4) # Slightly higher LR?
              # Loss function suitable for integer targets and probability outputs
              loss = "sparse_categorical_crossentropy"
              # Metrics: Accuracy calculated per cell prediction
              metrics = ["accuracy"]

              model.compile(
                  optimizer=optimizer,
                  loss=loss,
                  metrics=metrics,
              )
              model.summary(line_length=120)
              return model

          # -------------------------------------------------------------- #
          # preprocessing (for full grid image)
          # -------------------------------------------------------------- #
          def _preprocess_grid_for_model(self, rectified_img: np.ndarray) -> Optional[np.ndarray]:
              """
              Prepares the rectified grid image for the FCN model.
              Resizes, converts to grayscale, normalizes to [0, 1], adds channel dim.
              """
              if rectified_img is None or rectified_img.size == 0:
                  return None

              target_h, target_w, target_c = self._model_input_shape
              is_grayscale = (target_c == 1)

              # Resize to target input size
              # Use INTER_AREA for shrinking, INTER_LINEAR for enlarging
              current_h, current_w = rectified_img.shape[:2]
              if current_h * current_w > target_h * target_w:
                  interp = cv2.INTER_AREA
              else:
                  interp = cv2.INTER_LINEAR
              resized = cv2.resize(rectified_img, (target_w, target_h), interpolation=interp)

              # Ensure correct number of channels (grayscale)
              if is_grayscale:
                  if resized.ndim == 3 and resized.shape[2] == 3:
                      processed = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)
                  elif resized.ndim == 3 and resized.shape[2] == 4:
                      processed = cv2.cvtColor(resized, cv2.COLOR_BGRA2GRAY)
                  elif resized.ndim == 2:
                      processed = resized
                  else:
                      print(f"[Preprocess Error] Unexpected image shape: {resized.shape}")
                      return None
                  # Add channel dimension: (H, W) -> (H, W, 1)
                  processed = processed[..., np.newaxis]
              else: # If model expected color input (target_c == 3)
                  if resized.ndim == 2: # Convert grayscale to BGR
                      processed = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)
                  elif resized.ndim == 3 and resized.shape[2] == 4: # Convert BGRA to BGR
                       processed = cv2.cvtColor(resized, cv2.COLOR_BGRA2BGR)
                  elif resized.ndim == 3 and resized.shape[2] == 3:
                       processed = resized # Already BGR
                  else:
                      print(f"[Preprocess Error] Unexpected image shape for color: {resized.shape}")
                      return None

              # Normalize to [0, 1] float32
              processed = processed.astype("float32") / 255.0

              return processed


          # ------------------------------------------------------------------ #
          # 7.1  augmentation (for full grid image)
          # ------------------------------------------------------------------ #
          def _augment_grid(self, grid_img: np.ndarray) -> np.ndarray:
              """Apply augmentations to the full grid image."""
              h, w = grid_img.shape[:2]
              augmented = grid_img.copy()

              # 1. Small Rotation
              if random.random() < 0.5:
                  angle = random.uniform(-8, 8) # Reduced angle for full grid
                  M_rot = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1.0)
                  augmented = cv2.warpAffine(augmented, M_rot, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0) # Black border

              # 2. Small Translation
              if random.random() < 0.5:
                  tx = random.uniform(-w * 0.03, w * 0.03) # Max 3% translation
                  ty = random.uniform(-h * 0.03, h * 0.03)
                  M_trans = np.float32([[1, 0, tx], [0, 1, ty]])
                  augmented = cv2.warpAffine(augmented, M_trans, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0)

              # 3. Brightness/Contrast Jitter
              if random.random() < 0.6:
                  alpha = random.uniform(0.85, 1.15) # Contrast
                  beta = random.uniform(-0.1, 0.1)   # Brightness
                  augmented = np.clip(augmented * alpha + beta, 0.0, 1.0)

              # 4. Gaussian Noise
              if random.random() < 0.3:
                  noise = np.random.normal(0, random.uniform(0.01, 0.05), augmented.shape)
                  augmented = np.clip(augmented + noise, 0.0, 1.0)

              # Ensure output is float32
              return augmented.astype("float32")


          # -------------------------------------------------------------- #
          # training
          # -------------------------------------------------------------- #
          def train(
              self,
              epochs: int = EPOCHS,
              steps_per_epoch: int = STEPS_PER_EPOCH,
              batch_size: int = BATCH_SIZE,
              validation_steps: int = VALIDATION_STEPS,
          ) -> None:
              """Trains the full-grid FCN model."""
              print(f"\n--- Training Full Grid Classifier ---")
              print(f"Epochs: {epochs}, Steps/Epoch: {steps_per_epoch}, Batch Size: {batch_size}")
              print(f"Input Shape: {self._model_input_shape}, Output: (9, 9, {NUM_CLASSES})")

              if self.model is None:
                  self.model = self._build_cnn_model()
              elif not isinstance(self.model, keras.Model):
                   print("[Error] self.model is not a valid Keras model. Cannot train.")
                   return

              # Prepare test example for callback
              try:
                  test_img_path, test_gt_grid = generate_and_save_test_example()
                  if test_img_path is None or test_gt_grid is None:
                       raise ValueError("Failed to generate/load test example.")
                  # Pass the classifier instance and the ground truth grid (0 for empty)
                  epoch_cb = EpochTestCallback(test_img_path, test_gt_grid, self)
              except Exception as e:
                  print(f"[Warning] Failed to set up EpochTestCallback: {e}. Callback disabled.")
                  epoch_cb = None

              # Create data generators
              # Training generator uses augmentation
              train_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  self._augment_grid, # Apply augmentation
                  self._model_input_shape,
              )
              # Validation generator does not use augmentation
              val_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  None, # No augmentation for validation
                  self._model_input_shape,
              )

              # Dump a batch of augmented training samples for visualization
              dump_dir = Path("dumped_training_grids")
              dump_dir.mkdir(exist_ok=True)
              try:
                  x_vis, y_vis = next(train_gen) # Get one batch from training gen
                  n_dump = min(4, x_vis.shape[0]) # Dump fewer, larger images
                  for i in range(n_dump):
                      # Convert float32 [0,1] -> uint8 [0,255]
                      img = (x_vis[i] * 255).astype(np.uint8)
                      # Maybe add label info to filename if needed, but grid is complex
                      cv2.imwrite(str(dump_dir / f"sample_grid_{i}.png"), img)
                  print(f"[Info] Dumped {n_dump} augmented training grid samples to {dump_dir}")
              except Exception as e:
                  print(f"[Warning] Could not dump training samples: {e}")


              # Callbacks
              cbs: list[callbacks.Callback] = [
                  callbacks.EarlyStopping(
                      monitor="val_accuracy", # Monitor validation accuracy (per-cell)
                      patience=10,          # Increased patience for larger model
                      restore_best_weights=True,
                      verbose=1,
                      mode='max'
                  ),
                  callbacks.ModelCheckpoint(
                      filepath=str(self.model_path), # Ensure path is string
                      monitor="val_accuracy",
                      save_best_only=True,
                      verbose=1,
                      mode='max'
                  ),
                  callbacks.ReduceLROnPlateau(
                      monitor="val_loss", # Reduce LR based on validation loss
                      factor=0.2,
                      patience=4,
                      min_lr=1e-7,
                      verbose=1,
                      mode='min' # Reduce LR when loss plateaus
                  ),
                  # Optional: TensorBoard
                  # callbacks.TensorBoard(log_dir='./logs_fcn', histogram_freq=1)
              ]
              if epoch_cb:
                  cbs.append(epoch_cb)

              # Start Training
              print("\nStarting model training...")
              history = self.model.fit(
                  train_gen,
                  epochs=epochs,
                  steps_per_epoch=steps_per_epoch,
                  validation_data=val_gen,
                  validation_steps=validation_steps,
                  callbacks=cbs,
                  verbose=1, # Use 1 for progress bar, 2 for one line per epoch
              )

              # Ensure the best model is loaded (EarlyStopping might restore, Checkpoint saves)
              if self.model_path.exists():
                   print(f"Reloading best weights from {self.model_path}...")
                   try:
                       # Use load_model if the whole architecture might change,
                       # or load_weights if only weights are saved/needed.
                       # ModelCheckpoint saves the whole model by default.
                       self.model = keras.models.load_model(self.model_path)
                       print("Best model reloaded.")
                   except Exception as e:
                       print(f"[Error] Failed to reload best model after training: {e}")
                       # The model instance might still hold the best weights if EarlyStopping restored them.

              print("\n--- Final Evaluation (using best weights) ---")
              # Use a fresh validation generator for final evaluation
              final_eval_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  None, # No augmentation
                  self._model_input_shape,
              )
              loss, acc = self.model.evaluate(
                  final_eval_gen,
                  steps=validation_steps * 2, # Evaluate on more validation steps
                  verbose=1,
              )
              print(f"Final Validation Loss: {loss:.5f}")
              print(f"Final Validation Accuracy (per cell): {acc:.5f}")

              # Explicitly save the final best model again (belt-and-suspenders)
              try:
                  print(f"Saving final best model to {self.model_path}")
                  self.model.save(self.model_path)
              except Exception as e:
                  print(f"[Error] Failed to save final model: {e}")

              del train_gen, val_gen, final_eval_gen, history
              gc.collect()
              print("--- Training Finished ---")


          # -------------------------------------------------------------- #
          # inference (for full grid)
          # -------------------------------------------------------------- #
          @torch.no_grad() # Keep decorator if using torch backend
          def recognise_grid(
              self,
              rectified_img: np.ndarray,
              confidence_threshold: float = 0.80, # Default threshold for accepting a digit
          ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
              """
              Recognises digits in a rectified Sudoku grid image using the FCN model.

              Args:
                  rectified_img: The (e.g., 252x252) rectified grid image (uint8 or float).
                  confidence_threshold: Minimum confidence to accept a digit prediction (1-9).

              Returns:
                  A tuple (predicted_grid, confidence_grid):
                  - predicted_grid: (9, 9) numpy array with recognised digits (1-9) or 0 for empty/uncertain.
                  - confidence_grid: (9, 9) numpy array with confidence scores for the predicted class in each cell.
                  Returns (None, None) if inference fails.
              """
              if self.model is None:
                  print("[Error] Recognise_grid called but model is not loaded.")
                  return None, None

              # 1. Preprocess the input grid image
              proc_grid = self._preprocess_grid_for_model(rectified_img)
              if proc_grid is None:
                  print("[Error] Preprocessing failed during recognition.")
                  return None, None # Indicate failure

              # 2. Add batch dimension: (H, W, C) -> (1, H, W, C)
              x = proc_grid[np.newaxis, ...]

              # 3. Predict using the Keras model
              try:
                  # Use training=False for inference (important for layers like BatchNorm, Dropout)
                  raw_output = self.model(x, training=False) # Shape: (1, 9, 9, NUM_CLASSES)
              except Exception as e:
                  print(f"[Error] Model prediction failed: {e}")
                  return None, None

              # 4. Convert to NumPy and remove batch dimension
              # Keras with torch backend might return torch tensors
              if hasattr(raw_output, 'cpu') and hasattr(raw_output, 'numpy'): # Check if it's a tensor with cpu/numpy methods
                   probs = raw_output.cpu().numpy()
              elif isinstance(raw_output, np.ndarray):
                   probs = raw_output
              else:
                   print(f"[Error] Unexpected model output type: {type(raw_output)}")
                   return None, None

              probs = probs[0] # Shape: (9, 9, NUM_CLASSES)

              # 5. Decode probabilities to predictions and confidences
              predicted_indices = np.argmax(probs, axis=-1) # Shape: (9, 9), contains indices 0-10
              confidences = np.max(probs, axis=-1)       # Shape: (9, 9), contains max probability

              # 6. Create the final output grid
              # Initialize with zeros (representing empty/uncertain)
              final_grid = np.zeros((GRID_SIZE, GRID_SIZE), dtype=int)

              # Iterate through each cell prediction
              for r in range(GRID_SIZE):
                  for c in range(GRID_SIZE):
                      pred_idx = predicted_indices[r, c]
                      conf = confidences[r, c]

                      # Check if the prediction is a digit (1-9), not EMPTY_LABEL (10),
                      # and if the confidence meets the threshold.
                      if pred_idx != EMPTY_LABEL and conf >= confidence_threshold:
                          final_grid[r, c] = pred_idx # Assign the predicted digit (1-9)
                      # Otherwise, leave it as 0 (empty/uncertain)

              return final_grid, confidences


      # ------------------------------------------------------------------ #
      # 8.  epoch‑end callback (adapted for full grid)
      # ------------------------------------------------------------------ #
      class EpochTestCallback(callbacks.Callback):
          def __init__(
              self,
              test_img_path: Path | str,
              gt_puzzle_grid: np.ndarray, # Ground truth puzzle (0 for empty)
              classifier: "DigitClassifier",
              frequency: int = 1,
          ) -> None:
              super().__init__()
              self.frequency = max(1, frequency)
              self.gt_puzzle_grid = gt_puzzle_grid # Shape (9, 9), 0 for empty
              self.classifier = classifier
              self.test_img_path = test_img_path
              self.preprocessed_test_grid = None # To store the single preprocessed grid

          def on_train_begin(self, logs=None):
              """Preprocess the test image once before training starts."""
              print("\n[Callback] Preprocessing test example for epoch-end evaluation...")
              try:
                  # Extract the rectified grid from the test image file
                  # We don't need the individual cells here, just the rectified image
                  _, rectified_test_img, _ = extract_cells_from_image(
                      self.test_img_path,
                      size=self.classifier._model_input_shape[0], # Use model's input size
                      debug=False
                  )

                  if rectified_test_img is None:
                      print("[Callback Error] Failed to extract rectified grid from test image.")
                      self.preprocessed_test_grid = None
                      return

                  # Preprocess the rectified grid using the classifier's method
                  self.preprocessed_test_grid = self.classifier._preprocess_grid_for_model(rectified_test_img)

                  if self.preprocessed_test_grid is None:
                      print("[Callback Error] Preprocessing of the test grid failed.")
                  else:
                      print(f"[Callback] Test grid preprocessed successfully ({self.preprocessed_test_grid.shape}).")

              except Exception as e:
                  print(f"[Callback Error] Failed during test example setup: {e}")
                  self.preprocessed_test_grid = None

          def on_epoch_end(self, epoch, logs=None):
              # Check if preprocessing was successful and if it's the right epoch
              if self.preprocessed_test_grid is None or (epoch + 1) % self.frequency != 0:
                  return

              if not hasattr(self.model, 'predict'):
                   print("[Callback Error] Model object in callback does not have predict method.")
                   return

              print(f"\n--- Epoch {epoch+1} Test Example Evaluation ---")
              try:
                  # Add batch dimension for prediction
                  x_test = self.preprocessed_test_grid[np.newaxis, ...]

                  # Predict using the model being trained
                  raw_output = self.model.predict(x_test, verbose=0) # Shape: (1, 9, 9, NUM_CLASSES)

                  # Decode the output (similar to recognise_grid)
                  probs = raw_output[0] # Remove batch dim -> (9, 9, NUM_CLASSES)
                  pred_indices = np.argmax(probs, axis=-1) # (9, 9) indices 0-10
                  confs = np.max(probs, axis=-1)       # (9, 9) confidences

                  # Apply thresholding for display (use a slightly lower threshold maybe)
                  display_threshold = 0.7 # Threshold for visualization purposes
                  display_grid = np.zeros_like(pred_indices, dtype=int)
                  for r in range(GRID_SIZE):
                      for c in range(GRID_SIZE):
                          idx = pred_indices[r, c]
                          cf = confs[r, c]
                          if idx != EMPTY_LABEL and cf >= display_threshold:
                              display_grid[r, c] = idx

                  print("Ground Truth Puzzle:")
                  # print_sudoku_grid expects 0 for empty
                  sudoku_recogniser.print_sudoku_grid(self.gt_puzzle_grid)

                  print(f"Prediction (Thresholded @ {display_threshold:.2f}):")
                  sudoku_recogniser.print_sudoku_grid(display_grid, confs, threshold=display_threshold)

                  # --- Calculate Accuracy ---
                  # Compare prediction indices directly with the GT grid converted to use EMPTY_LABEL
                  gt_labels = self.gt_puzzle_grid.copy()
                  gt_labels[gt_labels == 0] = EMPTY_LABEL # Convert GT to use 10 for empty

                  correct_cells = (pred_indices == gt_labels).sum()
                  total_cells = GRID_SIZE * GRID_SIZE
                  accuracy = correct_cells / total_cells
                  print(f"Test Example Accuracy (Raw Prediction vs GT Labels): {correct_cells}/{total_cells} = {accuracy:.4f}")
                  print("--- End Epoch Test ---\n")

              except Exception as e:
                  print(f"[Callback Error] Failed during prediction or display: {e}")
                  import traceback
                  traceback.print_exc()


      # ------------------------------------------------------------------ #
      # 9.  CLI helper
      # ------------------------------------------------------------------ #
      if __name__ == "__main__":
          # Set to True to force retraining even if a model file exists
          FORCE_TRAIN = False

          model_file = Path(MODEL_FILENAME)
          train_needed = FORCE_TRAIN or not model_file.exists()

          if FORCE_TRAIN and model_file.exists():
              print(f"FORCE_TRAIN is True. Deleting existing model: {model_file}")
              try:
                  model_file.unlink()
                  train_needed = True
              except OSError as e:
                  print(f"Error deleting existing model: {e}. Proceeding might use old model if loading works.")
                  # Decide whether to exit or continue
                  # exit(1)

          # Instantiate the classifier. It will try to load if train_needed is False.
          clf = DigitClassifier(model_path=model_file, training_required=train_needed)

          # Train if needed
          if train_needed:
              if clf.model is not None:
                   print("[Warning] Model was loaded despite train_needed=True? Retraining anyway.")
                   clf.model = None # Ensure model is rebuilt
              print("Starting training process...")
              clf.train(epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, batch_size=BATCH_SIZE)
              # After training, the best model should be saved and reloaded by the train method.
              if clf.model is None:
                   print("[Error] Training finished, but model is still None. Cannot proceed.")
                   exit(1)
          elif clf.model is None:
               print("[Error] Model loading failed, and training was not requested. Cannot proceed.")
               exit(1)
          else:
               print("Model loaded successfully. Skipping training.")


          # --- Perform Sanity Check using the Test Example ---
          if clf.model:
              print("\n--- Sanity Check: Recognising the Test Example ---")
              test_img_path_str, test_gt_grid = generate_and_save_test_example() # Get path and GT

              if test_img_path_str is None or test_gt_grid is None:
                  print("Failed to load test example for sanity check.")
              else:
                  test_img_path = Path(test_img_path_str)
                  print(f"Loading test image: {test_img_path}")
                  # Extract rectified grid from the test image
                  _, rectified_test, _ = extract_cells_from_image(
                      test_img_path,
                      size=clf._model_input_shape[0], # Use model's input size
                      debug=False
                  )

                  if rectified_test is None:
                      print("Failed to extract rectified grid from test image for sanity check.")
                  else:
                      print("Running recognise_grid on the test image...")
                      # Use a reasonable confidence threshold for the check
                      pred_grid, conf_grid = clf.recognise_grid(rectified_test, confidence_threshold=0.75)

                      if pred_grid is None:
                          print("Recognition failed during sanity check.")
                      else:
                          print("\nGround Truth Puzzle:")
                          sudoku_recogniser.print_sudoku_grid(test_gt_grid)

                          print("Recognised Grid (Thresholded @ 0.75):")
                          sudoku_recogniser.print_sudoku_grid(pred_grid, conf_grid, threshold=0.75)

                          # Calculate accuracy for the sanity check
                          correct_cells = (pred_grid == test_gt_grid).sum()
                          # Account for empty cells being 0 in both GT and prediction (correctly)
                          # Non-empty cells must match exactly
                          correct_non_empty = ((pred_grid == test_gt_grid) & (test_gt_grid != 0)).sum()
                          correct_empty = ((pred_grid == 0) & (test_gt_grid == 0)).sum()
                          total_correct = correct_non_empty + correct_empty

                          total_cells = GRID_SIZE * GRID_SIZE
                          accuracy = total_correct / total_cells
                          print(f"\nSanity Check Accuracy: {total_correct}/{total_cells} = {accuracy:.4f}")
          else:
              print("\nSanity check skipped: No model available.")

          print("\nScript finished.")
    digit_extractor.py: |
      """
      Find and extract Sudoku grid cells from an image.
      """

      import os
      from pathlib import Path
      from typing import List, Tuple, Optional

      import cv2
      import numpy as np

      GRID_SIZE = 9
      # Changed default size to be divisible by common CNN strides (e.g., 2^3=8 or 3^3=27)
      # 252 = 9 * 28 -> divisible by 2, 3, 4, 6, 7, 9, 12, 14, 18, 21, 28...
      DEFAULT_RECTIFIED_SIZE = 252


      def _order_points(pts: np.ndarray) -> np.ndarray:
          """Order four points as top-left, top-right, bottom-right, bottom-left."""
          pts = pts.reshape(4, 2).astype("float32")
          rect = np.zeros((4, 2), dtype="float32")
          s = pts.sum(axis=1)
          rect[0] = pts[np.argmin(s)] # Top-left has smallest sum
          rect[2] = pts[np.argmax(s)] # Bottom-right has largest sum
          diff = np.diff(pts, axis=1) # diff = y - x
          rect[1] = pts[np.argmin(diff)] # Top-right has smallest diff
          rect[3] = pts[np.argmax(diff)] # Bottom-left has largest diff
          return rect


      def find_sudoku_grid_contour(
          img: np.ndarray,
          debug_dir: Optional[Path] = None
      ) -> Optional[np.ndarray]:
          """
          Find the largest 4-point contour approximating the Sudoku grid boundary.
          Returns the contour points (4, 2) or None if not found.
          """
          if img is None or img.size == 0:
              print("[Contour Finder] Invalid input image.")
              return None

          gray = (
              cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
              if img.ndim == 3 and img.shape[2] == 3 else img.copy()
          )
          if gray.ndim == 3: # Handle case like RGBA input
              gray = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)

          if debug_dir:
              debug_dir.mkdir(parents=True, exist_ok=True)
              cv2.imwrite(str(debug_dir / "00_gray.png"), gray)

          # Preprocessing: Blur and Threshold
          # GaussianBlur helps reduce noise before thresholding
          blur = cv2.GaussianBlur(gray, (7, 7), 0)
          if debug_dir: cv2.imwrite(str(debug_dir / "01_blur.png"), blur)

          # Adaptive thresholding is generally robust to lighting changes
          thresh = cv2.adaptiveThreshold(
              blur, 255,
              cv2.ADAPTIVE_THRESH_GAUSSIAN_C, # Method
              cv2.THRESH_BINARY_INV,         # Threshold type (invert to get black lines on white)
              15,                            # Block size (must be odd) - adjust based on image size/line thickness
              4                              # Constant C subtracted from mean
          )
          if debug_dir: cv2.imwrite(str(debug_dir / "02_thresh.png"), thresh)

          # Morphological closing to connect broken lines
          kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
          closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)
          if debug_dir: cv2.imwrite(str(debug_dir / "03_closed.png"), closed)

          # Find contours
          contours, _ = cv2.findContours(
              closed,
              cv2.RETR_EXTERNAL,        # Retrieve only outer contours
              cv2.CHAIN_APPROX_SIMPLE   # Compress horizontal/vertical segments
          )

          if not contours:
              print("[Contour Finder] No contours found.")
              return None

          # Sort contours by area (descending) and filter small ones
          contours = sorted(contours, key=cv2.contourArea, reverse=True)
          min_area = gray.size * 0.05 # Require contour to be at least 5% of image area

          if debug_dir:
              img_contours = img.copy() if img.ndim == 3 else cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
              cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 1) # Draw all contours found
              cv2.imwrite(str(debug_dir / "04_all_contours.png"), img_contours)


          # Find the largest quadrilateral contour that resembles a square
          for i, cnt in enumerate(contours):
              area = cv2.contourArea(cnt)
              if area < min_area:
                  # print(f"[Contour Finder] Remaining contours too small (area {area} < {min_area}).")
                  break # No need to check smaller contours

              peri = cv2.arcLength(cnt, True)
              # Approximate the contour shape to a polygon
              approx = cv2.approxPolyDP(cnt, 0.02 * peri, True) # Epsilon factor determines accuracy

              # Check if the approximation has 4 vertices and is convex
              if len(approx) == 4 and cv2.isContourConvex(approx):
                  # Check aspect ratio of the bounding box
                  x, y, w, h = cv2.boundingRect(approx)
                  aspect_ratio = w / float(h) if h > 0 else 0

                  # Allow some tolerance for perspective distortion
                  if 0.7 < aspect_ratio < 1.3:
                      if debug_dir:
                          img_found = img.copy() if img.ndim == 3 else cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
                          cv2.drawContours(img_found, [approx], -1, (0, 0, 255), 3)
                          cv2.imwrite(str(debug_dir / f"05_found_contour_{i}.png"), img_found)
                      # print(f"[Contour Finder] Found potential grid contour (index {i}, area {area:.0f}, aspect {aspect_ratio:.2f}).")
                      return approx.reshape(4, 2).astype("float32") # Return the corner points

          print("[Contour Finder] No suitable Sudoku grid contour found.")
          return None


      def rectify_grid(
          img: np.ndarray,
          contour: np.ndarray,
          size: int = DEFAULT_RECTIFIED_SIZE
      ) -> Optional[np.ndarray]:
          """Perspective-correct the Sudoku grid to a square of given size."""
          if contour is None or contour.shape != (4, 2):
              print("[Rectifier] Invalid contour provided.")
              return None
          if img is None or img.size == 0:
              print("[Rectifier] Invalid image provided.")
              return None

          try:
              # Order the contour points: TL, TR, BR, BL
              src_pts = _order_points(contour)

              # Define the destination points for the square image
              dst_pts = np.array([
                  [0, 0],             # Top-left
                  [size - 1, 0],      # Top-right
                  [size - 1, size - 1], # Bottom-right
                  [0, size - 1],      # Bottom-left
              ], dtype="float32")

              # Calculate the perspective transform matrix
              matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)

              # Apply the perspective warp
              warped = cv2.warpPerspective(img, matrix, (size, size))
              return warped
          except Exception as e:
              print(f"[Rectifier] Error during perspective warp: {e}")
              return None


      def split_into_cells(
          rectified: np.ndarray
      ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray]]:
          """
          Split the rectified grid into GRID_SIZE × GRID_SIZE cell images.
          Applies a small margin removal.
          Returns (cells, rectified_image) or (None, None) on failure.
          """
          if rectified is None or rectified.shape[0] != rectified.shape[1]:
              print("[Splitter] Invalid rectified image provided.")
              return None, None

          h, w = rectified.shape[:2]
          if h == 0 or w == 0:
              print("[Splitter] Rectified image has zero dimension.")
              return None, None

          cell_sz_h = h // GRID_SIZE
          cell_sz_w = w // GRID_SIZE
          if cell_sz_h == 0 or cell_sz_w == 0:
              print("[Splitter] Calculated cell size is zero.")
              return None, None

          # Calculate margin to remove grid lines (e.g., 4% of cell size)
          margin_y = max(1, int(cell_sz_h * 0.04))
          margin_x = max(1, int(cell_sz_w * 0.04))

          cells: List[np.ndarray] = []
          for row in range(GRID_SIZE):
              for col in range(GRID_SIZE):
                  # Calculate cell boundaries with margin
                  y0 = row * cell_sz_h + margin_y
                  x0 = col * cell_sz_w + margin_x
                  y1 = (row + 1) * cell_sz_h - margin_y
                  x1 = (col + 1) * cell_sz_w - margin_x

                  # Ensure coordinates are valid and extract cell
                  if y0 < y1 and x0 < x1:
                      cell = rectified[y0:y1, x0:x1]
                      cells.append(cell)
                  else:
                      # Handle cases where margin is too large for cell size (should be rare)
                      # Fallback: extract cell without margin
                      y0_nomargin = row * cell_sz_h
                      x0_nomargin = col * cell_sz_w
                      y1_nomargin = (row + 1) * cell_sz_h
                      x1_nomargin = (col + 1) * cell_sz_w
                      cell = rectified[y0_nomargin:y1_nomargin, x0_nomargin:x1_nomargin]
                      # Add a blank cell if even no-margin extraction fails
                      if cell is None or cell.size == 0:
                           cell_shape = (cell_sz_h, cell_sz_w) + rectified.shape[2:] if rectified.ndim > 2 else (cell_sz_h, cell_sz_w)
                           cell = np.zeros(cell_shape, rectified.dtype) # Create blank cell
                      cells.append(cell)


          if len(cells) != GRID_SIZE * GRID_SIZE:
              print(f"[Splitter] Incorrect number of cells extracted: {len(cells)}")
              return None, rectified # Return None for cells but keep rectified image

          return cells, rectified


      def extract_cells_from_image(
          img_or_path,
          size: int = DEFAULT_RECTIFIED_SIZE,
          debug: bool = False
      ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray], Optional[np.ndarray]]:
          """
          High-level function: read image, find grid, rectify, and split into cells.
          Returns (cells, rectified_image, contour) or (None, None, None) on failure.
          """
          if isinstance(img_or_path, (str, Path)):
              img_path = str(img_or_path)
              if not Path(img_path).exists():
                  print(f"[Extractor] Image file not found: {img_path}")
                  return None, None, None
              img = cv2.imread(img_path)
              if img is None:
                  print(f"[Extractor] Failed to read image: {img_path}")
                  return None, None, None
          elif isinstance(img_or_path, np.ndarray):
              img = img_or_path.copy()
          else:
              print("[Extractor] Invalid input type (must be path or numpy array).")
              return None, None, None

          if img.size == 0:
              print("[Extractor] Input image is empty.")
              return None, None, None

          try:
              debug_dir = Path(f"debug_extract_{Path(img_path).stem}_{os.getpid()}") if debug and isinstance(img_or_path, (str, Path)) else None
              if debug and not debug_dir: debug_dir = Path(f"debug_extract_np_{os.getpid()}")

              # 1. Find Grid Contour
              contour = find_sudoku_grid_contour(img, debug_dir)
              if contour is None:
                  print("[Extractor] Failed to find Sudoku contour.")
                  return None, None, None # Contour finding failed

              # 2. Rectify Grid
              rectified = rectify_grid(img, contour, size=size)
              if rectified is None:
                  print("[Extractor] Failed to rectify grid.")
                  return None, None, contour # Rectification failed, return contour found

              if debug_dir:
                  cv2.imwrite(str(debug_dir / "06_rectified.png"), rectified)

              # 3. Split into Cells
              cells, rectified_output = split_into_cells(rectified)
              if cells is None:
                  print("[Extractor] Failed to split rectified grid into cells.")
                  # Return rectified image even if splitting fails, maybe useful for debugging
                  return None, rectified_output, contour

              if debug_dir:
                  # Save a montage of extracted cells
                  cell_h, cell_w = cells[0].shape[:2]
                  montage = np.zeros((GRID_SIZE * cell_h, GRID_SIZE * cell_w) + cells[0].shape[2:], dtype=cells[0].dtype)
                  for i, cell_img in enumerate(cells):
                      r, c = divmod(i, GRID_SIZE)
                      if cell_img.shape[:2] == (cell_h, cell_w): # Ensure shape consistency
                          montage[r*cell_h:(r+1)*cell_h, c*cell_w:(c+1)*cell_w] = cell_img
                  cv2.imwrite(str(debug_dir / "07_cells_montage.png"), montage)


              # Success
              return cells, rectified_output, contour

          except Exception as e:
              print(f"[Extractor] Unexpected error: {e}")
              import traceback
              traceback.print_exc()
              return None, None, None
    sudoku_recogniser.py: |
      """
      Command-line utility to detect a Sudoku grid in an image and recognise its digits
      using the full-grid classifier.
      """

      from __future__ import annotations

      import sys
      import time
      from pathlib import Path
      from typing import Tuple, Optional

      import cv2
      import numpy as np

      # Import the updated classifier and extractor
      import digit_classifier
      from digit_extractor import GRID_SIZE, DEFAULT_RECTIFIED_SIZE, extract_cells_from_image

      # Confidence threshold for final acceptance of a recognised digit (1-9)
      # This can be tuned based on model performance.
      FINAL_CONFIDENCE_THRESHOLD = 0.75 # Adjusted slightly


      def print_sudoku_grid(
          grid: np.ndarray,
          conf: Optional[np.ndarray] = None,
          threshold: float = FINAL_CONFIDENCE_THRESHOLD
      ) -> None:
          """
          Nicely print a 9×9 Sudoku grid.
          Marks digits below the threshold with '?' if confidences are provided.
          Expects grid values 0-9, where 0 is empty.
          """
          grid = np.asarray(grid)
          if grid.shape != (GRID_SIZE, GRID_SIZE):
              print(f"[print_sudoku_grid] Invalid grid shape: {grid.shape}")
              return

          print("-" * 25) # Top border
          for r in range(GRID_SIZE):
              if r > 0 and r % 3 == 0:
                  print("|-------+-------+-------|") # Separator line

              line = ["|"] # Start of row
              for c in range(GRID_SIZE):
                  digit = grid[r, c]
                  token = ""
                  if digit == 0:
                      token = "." # Represent empty cell
                  else:
                      token = str(digit)
                      # If confidence is provided and below threshold, mark as uncertain
                      if conf is not None and conf.shape == (GRID_SIZE, GRID_SIZE) and conf[r, c] < threshold:
                          token = "?"

                  line.append(f" {token} ") # Add token with spacing

                  if (c + 1) % 3 == 0:
                      line.append("|") # Add column separator

              print("".join(line)) # Print the row
          print("-" * 25) # Bottom border
          print() # Add a blank line after the grid


      def display_results_on_image(
          rectified: Optional[np.ndarray],
          grid: np.ndarray,
          conf: Optional[np.ndarray] = None,
          threshold: float = FINAL_CONFIDENCE_THRESHOLD
      ) -> Optional[np.ndarray]:
          """
          Draw recognised digits (above threshold) onto the rectified grid image.
          """
          if rectified is None:
              print("[Display] No rectified image provided.")
              return None

          # Ensure image is BGR for drawing colors
          img_display = (
              cv2.cvtColor(rectified, cv2.COLOR_GRAY2BGR)
              if rectified.ndim == 2 else rectified.copy()
          )
          h, w = img_display.shape[:2]
          if h == 0 or w == 0: return None # Invalid image dimensions

          cell_h, cell_w = h // GRID_SIZE, w // GRID_SIZE
          if cell_h == 0 or cell_w == 0: return img_display # Cannot draw if cells are too small

          # Choose font properties
          font_face = cv2.FONT_HERSHEY_SIMPLEX
          font_scale_base = min(cell_h, cell_w) / 35.0 # Scale font based on cell size
          font_thickness = max(1, int(font_scale_base * 1.5))

          for r in range(GRID_SIZE):
              for c in range(GRID_SIZE):
                  digit = grid[r, c]
                  confidence = conf[r, c] if conf is not None else 1.0 # Assume high conf if not provided

                  # Only draw digits that are not empty and meet the confidence threshold
                  if digit != 0 and confidence >= threshold:
                      text = str(digit)

                      # Calculate text size to center it
                      (text_w, text_h), baseline = cv2.getTextSize(text, font_face, font_scale_base, font_thickness)

                      # Calculate center position of the cell
                      center_x = c * cell_w + cell_w // 2
                      center_y = r * cell_h + cell_h // 2

                      # Calculate bottom-left corner of the text for centering
                      text_x = center_x - text_w // 2
                      text_y = center_y + text_h // 2

                      # Draw the text
                      cv2.putText(
                          img_display,
                          text,
                          (text_x, text_y),
                          font_face,
                          font_scale_base,
                          (0, 200, 0), # Green color for recognised digits
                          font_thickness,
                          cv2.LINE_AA # Anti-aliased text
                      )
                  # Optional: Draw uncertain digits differently (e.g., red '?')
                  # elif digit != 0 and conf is not None and confidence < threshold:
                  #     text = "?"
                  #     (text_w, text_h), baseline = cv2.getTextSize(text, font_face, font_scale_base, font_thickness)
                  #     center_x = c * cell_w + cell_w // 2
                  #     center_y = r * cell_h + cell_h // 2
                  #     text_x = center_x - text_w // 2
                  #     text_y = center_y + text_h // 2
                  #     cv2.putText(img_display, text, (text_x, text_y), font_face, font_scale_base, (0, 0, 255), font_thickness, cv2.LINE_AA)


          return img_display


      def recognise_sudoku(
          img_path: Path,
          classifier: digit_classifier.DigitClassifier
      ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
          """
          Extract rectified grid and run the full-grid classifier.

          Returns:
              Tuple of (predicted_grid, confidence_grid, rectified_image).
              predicted_grid: (9, 9) int array, 0 for empty/uncertain.
              confidence_grid: (9, 9) float array of confidences.
              rectified_image: The (e.g., 252x252) rectified image.
              Returns (None, None, None) on failure.
          """
          print(f"Processing {img_path.name}...")
          start_time = time.time()

          # 1. Extract the rectified grid image
          # We don't need individual cells from the extractor anymore
          # Use the input size expected by the classifier model
          rectified_size = classifier._model_input_shape[0]
          _, rectified_img, _ = extract_cells_from_image(
              img_path,
              size=rectified_size,
              debug=False # Set to True for extraction debugging images
          )

          if rectified_img is None:
              print("❌ Failed to extract or rectify the Sudoku grid.")
              return None, None, None
          print(f"✅ Grid extracted and rectified ({time.time() - start_time:.2f}s)")
          extract_time = time.time()

          # 2. Recognise digits using the full-grid classifier
          print("🧠 Running grid recognition model...")
          predicted_grid, confidence_grid = classifier.recognise_grid(
              rectified_img,
              confidence_threshold=FINAL_CONFIDENCE_THRESHOLD
          )

          if predicted_grid is None or confidence_grid is None:
              print("❌ Model recognition failed.")
              return None, None, rectified_img # Return rectified image even if recognition fails

          elapsed_time = time.time() - start_time
          print(f"✅ Recognition complete ({time.time() - extract_time:.2f}s)")
          print(f"⏱️ Total time: {elapsed_time:.2f}s")

          return predicted_grid, confidence_grid, rectified_img


      def main() -> None:
          if len(sys.argv) < 2:
              print("Usage: python sudoku_recogniser.py <image_path> [--no-train]")
              print("  <image_path>: Path to the Sudoku image file.")
              print("  --no-train: Optional flag to prevent training if the model is missing.")
              sys.exit(0)

          img_path = Path(sys.argv[1])
          if not img_path.is_file():
              print(f"❌ Error: Image file not found at '{img_path}'")
              sys.exit(1)

          # Check for --no-train flag
          force_no_train = "--no-train" in sys.argv

          # Instantiate the classifier
          # It will try to load the model. Training is required if the model file
          # doesn't exist, unless --no-train is specified.
          model_exists = Path(digit_classifier.MODEL_FILENAME).exists()
          training_required = not model_exists

          if training_required and force_no_train:
              print("Model file not found, but --no-train specified. Exiting.")
              sys.exit(1)
          elif training_required:
              print(f"⚠️ Model file '{digit_classifier.MODEL_FILENAME}' not found.")
              print("Initiating training process...")
              classifier = digit_classifier.DigitClassifier(training_required=True)
              classifier.train() # Use default training parameters from classifier script
              # Check if model was successfully created after training
              if classifier.model is None:
                   print("❌ Training failed to produce a model. Exiting.")
                   sys.exit(1)
              print("✅ Training complete. Proceeding with recognition...")
          else:
              # Model exists or --no-train was used with existing model
              classifier = digit_classifier.DigitClassifier(training_required=False)
              if classifier.model is None:
                   print(f"❌ Failed to load existing model '{digit_classifier.MODEL_FILENAME}'. Exiting.")
                   sys.exit(1)
              print(f"✅ Model '{digit_classifier.MODEL_FILENAME}' loaded.")


          # Recognise the Sudoku in the input image
          try:
              grid, conf, rectified = recognise_sudoku(img_path, classifier)

              if grid is None or conf is None:
                  print("\n❌ Sudoku recognition process failed.")
                  # Rectified might still exist, show it if possible
                  if rectified is not None:
                       cv2.imshow("Failed Extraction/Rectification", rectified)
                       cv2.waitKey(0)
                  sys.exit(1)

              # Print the recognised grid to the console
              print("\n--- Recognised Sudoku Grid ---")
              print_sudoku_grid(grid, conf, threshold=FINAL_CONFIDENCE_THRESHOLD)

              # Display the rectified image with recognised digits overlaid
              result_img = display_results_on_image(rectified, grid, conf, threshold=FINAL_CONFIDENCE_THRESHOLD)
              if result_img is not None:
                  print("ℹ️ Displaying recognised grid on image. Press any key to close.")
                  cv2.imshow("Sudoku Recognition Result", result_img)
                  cv2.waitKey(0)
              else:
                  print("ℹ️ Could not generate result image.")

          except Exception as e:
              print(f"\n❌ An unexpected error occurred: {e}")
              import traceback
              traceback.print_exc()
              sys.exit(1)
          finally:
              cv2.destroyAllWindows() # Ensure any OpenCV windows are closed


      if __name__ == "__main__":
          main()
    sudoku_renderer.py: |
      """
      Synthetic Sudoku image generator for on‑the‑fly training data.
      Generates puzzles based on valid, solvable Sudoku grids.
      """

      import random
      import time
      from pathlib import Path
      from typing import Tuple, Optional, List

      import cv2
      import numpy as np
      import keras

      GRID_SIZE = 9
      BASE_IMAGE_SIZE = 1000 # Initial rendering size before warp
      CELL_SIZE = BASE_IMAGE_SIZE // GRID_SIZE
      # Ensure MNIST is loaded only once
      MNIST_BUCKETS: Optional[dict[int, list[np.ndarray]]] = None

      # --- Sudoku Generation Helpers ---

      def _is_safe(grid: np.ndarray, row: int, col: int, num: int) -> bool:
          """Check if it's safe to place 'num' at grid[row, col]."""
          # Check row
          if num in grid[row, :]:
              return False
          # Check column
          if num in grid[:, col]:
              return False
          # Check 3x3 box
          start_row, start_col = 3 * (row // 3), 3 * (col // 3)
          if num in grid[start_row:start_row + 3, start_col:start_col + 3]:
              return False
          return True

      def _find_empty(grid: np.ndarray) -> Optional[Tuple[int, int]]:
          """Find an empty cell (marked with 0)."""
          for r in range(GRID_SIZE):
              for c in range(GRID_SIZE):
                  if grid[r, c] == 0:
                      return (r, c)
          return None

      def _solve_sudoku(grid: np.ndarray) -> bool:
          """Solve the Sudoku grid in-place using backtracking."""
          find = _find_empty(grid)
          if not find:
              return True  # Solved
          else:
              row, col = find

          nums = list(range(1, GRID_SIZE + 1))
          random.shuffle(nums) # Introduce randomness for generation

          for num in nums:
              if _is_safe(grid, row, col, num):
                  grid[row, col] = num
                  if _solve_sudoku(grid):
                      return True
                  grid[row, col] = 0  # Backtrack

          return False

      def _generate_sudoku_solution() -> np.ndarray:
          """Generate a complete, valid Sudoku grid."""
          while True: # Keep trying until a valid solution is found
              grid = np.zeros((GRID_SIZE, GRID_SIZE), dtype=int)
              if _solve_sudoku(grid):
                  return grid
              # print("Failed to generate solution, retrying...") # Optional debug
              time.sleep(0.01) # Avoid busy-waiting if something goes wrong

      def _create_puzzle(solution: np.ndarray, difficulty: float = 0.5) -> np.ndarray:
          """
          Create a puzzle by removing cells from a solution.
          Difficulty: approx. fraction of cells to remove (0.1 easy, 0.5 medium, 0.7 hard).
          Note: This simple removal doesn't guarantee unique solvability, but ensures
                the underlying pattern is valid.
          """
          puzzle = solution.copy()
          num_cells = GRID_SIZE * GRID_SIZE
          num_remove = int(num_cells * difficulty)

          attempts = 0
          removed_count = 0
          while removed_count < num_remove and attempts < num_cells * 2:
              row, col = random.randint(0, GRID_SIZE - 1), random.randint(0, GRID_SIZE - 1)
              if puzzle[row, col] != 0:
                  puzzle[row, col] = 0
                  removed_count += 1
              attempts += 1
          # print(f"Removed {removed_count} cells for difficulty {difficulty}") # Optional debug
          return puzzle

      # --- MNIST Loading ---

      def _load_mnist_digits() -> dict[int, list[np.ndarray]]:
          """
          Download MNIST once and bucket images by label for rendering.
          """
          global MNIST_BUCKETS
          if MNIST_BUCKETS is not None:
              return MNIST_BUCKETS

          print("Loading MNIST dataset for rendering...")
          try:
              (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
              images = np.concatenate([x_train, x_test])
              labels = np.concatenate([y_train, y_test])

              buckets: dict[int, list[np.ndarray]] = {i: [] for i in range(10)}
              for img, lbl in zip(images, labels):
                  # Invert (black digit on white bg) and add padding
                  inv = cv2.bitwise_not(img)
                  padded = cv2.copyMakeBorder(
                      inv, 4, 4, 4, 4,
                      cv2.BORDER_CONSTANT, value=255 # White padding
                  )
                  buckets[int(lbl)].append(padded)
              print("MNIST loaded.")
              MNIST_BUCKETS = buckets
              return MNIST_BUCKETS
          except Exception as e:
              print(f"Error loading MNIST: {e}. Will only use font rendering.")
              MNIST_BUCKETS = {i: [] for i in range(10)} # Empty buckets
              return MNIST_BUCKETS


      # --- Renderer Class ---

      class SudokuRenderer:
          """
          Render a random Sudoku puzzle (based on a valid solution) to a synthetic image.
          """

          def __init__(self) -> None:
              self.mnist_buckets = _load_mnist_digits() # Ensure MNIST is loaded/attempted

          def _digit_source(self, digit: int) -> Tuple[Optional[np.ndarray], str]:
              """Choose between MNIST digit or font rendering."""
              sources = []
              # Only allow MNIST if buckets[digit] is not empty
              if self.mnist_buckets and self.mnist_buckets.get(digit):
                  sources.append("mnist")
              sources.append("font") # Always allow font as fallback
              choice = random.choice(sources)

              if choice == "mnist":
                  img = random.choice(self.mnist_buckets[digit])
                  # Ensure it's BGR for consistency
                  if img.ndim == 2:
                      img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                  return img, "mnist"
              # Fallback to font rendering if MNIST chosen but failed, or if font chosen
              return None, "font"

          def render_sudoku(
              self,
              grid_spec: Optional[np.ndarray] = None,
              *,
              allow_empty: bool = True, # If True, difficulty is random, otherwise uses grid_spec or full solution
              difficulty: float = 0.5 # Used if allow_empty=True and grid_spec=None
          ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
              """
              Generate a synthetic Sudoku image based on a valid grid.

              Args:
                  grid_spec: A specific (9, 9) puzzle grid (0 for empty). If None, generates randomly.
                  allow_empty: If True and grid_spec is None, generate a puzzle with random difficulty.
                               If False and grid_spec is None, render the full solution.
                  difficulty: Target fraction of empty cells if generating randomly (approx).

              Returns:
                  Tuple of (image, ground_truth_puzzle_grid, warped_corners).
                  Returns (None, None, None) on generation failure.
              """
              try:
                  if grid_spec is not None:
                      # Use the provided puzzle spec directly
                      gt_puzzle = grid_spec.copy()
                      # We don't have the full solution here, but the puzzle itself is the ground truth
                  else:
                      # Generate a full solution first
                      solution = _generate_sudoku_solution()
                      if not allow_empty:
                          # Render the full solution
                          gt_puzzle = solution.copy()
                      else:
                          # Create a puzzle by removing digits from the solution
                          rand_difficulty = random.uniform(0.3, 0.7) # Randomize difficulty
                          gt_puzzle = _create_puzzle(solution, difficulty=rand_difficulty)

                  # --- Start Rendering ---
                  bg_color = tuple(random.randint(200, 240) for _ in range(3))
                  img = np.full((BASE_IMAGE_SIZE, BASE_IMAGE_SIZE, 3), bg_color, np.uint8)

                  # Draw grid lines
                  for i in range(GRID_SIZE + 1):
                      major = (i % 3 == 0)
                      thickness = random.randint(3 if major else 1, 5 if major else 3)
                      color = (0, 0, 0) # Black lines
                      # Horizontal lines
                      cv2.line(img, (0, i * CELL_SIZE), (BASE_IMAGE_SIZE, i * CELL_SIZE), color, thickness)
                      # Vertical lines
                      cv2.line(img, (i * CELL_SIZE, 0), (i * CELL_SIZE, BASE_IMAGE_SIZE), color, thickness)

                  # Draw digits onto the grid based on gt_puzzle
                  for r in range(GRID_SIZE):
                      for c in range(GRID_SIZE):
                          digit_to_render = gt_puzzle[r, c]
                          if digit_to_render == 0:
                              continue # Skip empty cells

                          src_img, src_type = self._digit_source(digit_to_render)
                          scale = random.uniform(0.5, 0.8) # Size relative to cell
                          target_size = int(CELL_SIZE * scale)
                          if target_size < 10: continue # Skip if too small

                          # Calculate center position with jitter
                          center_x = c * CELL_SIZE + CELL_SIZE // 2
                          center_y = r * CELL_SIZE + CELL_SIZE // 2
                          dx = int(random.uniform(-0.1, 0.1) * CELL_SIZE)
                          dy = int(random.uniform(-0.1, 0.1) * CELL_SIZE)
                          cx, cy = center_x + dx, center_y + dy

                          if src_type == "mnist" and src_img is not None:
                              # Resize MNIST digit
                              digit_img = cv2.resize(src_img, (target_size, target_size), interpolation=cv2.INTER_AREA)

                              # Random rotation
                              angle = random.uniform(-10, 10)
                              M = cv2.getRotationMatrix2D((target_size / 2, target_size / 2), angle, 1)
                              digit_img = cv2.warpAffine(
                                  digit_img, M, (target_size, target_size),
                                  borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255) # Match padding
                              )

                              # Create mask (assuming black digit on white background from MNIST processing)
                              mask = cv2.cvtColor(digit_img, cv2.COLOR_BGR2GRAY)
                              _, mask = cv2.threshold(mask, 250, 255, cv2.THRESH_BINARY_INV) # Invert to get digit mask

                              # Calculate ROI in the main image
                              x0 = max(0, cx - target_size // 2)
                              y0 = max(0, cy - target_size // 2)
                              x1 = min(img.shape[1], x0 + target_size)
                              y1 = min(img.shape[0], y0 + target_size)
                              roi = img[y0:y1, x0:x1]

                              # Adjust digit image and mask if ROI is smaller (near edges)
                              digit_roi = digit_img[0:roi.shape[0], 0:roi.shape[1]]
                              mask_roi = mask[0:roi.shape[0], 0:roi.shape[1]]
                              mask_inv_roi = cv2.bitwise_not(mask_roi)

                              # Place digit using mask
                              bg_region = cv2.bitwise_and(roi, roi, mask=mask_inv_roi)
                              fg_region = cv2.bitwise_and(digit_roi, digit_roi, mask=mask_roi)
                              img[y0:y1, x0:x1] = cv2.add(bg_region, fg_region)

                          else: # Use font rendering
                              font = cv2.FONT_HERSHEY_SIMPLEX # Or try FONT_HERSHEY_DUPLEX etc.
                              thickness = random.randint(2, 4)
                              # Adjust font scale to fit target size
                              font_scale = cv2.getFontScaleFromHeight(font, target_size, thickness) * 0.8
                              text = str(digit_to_render)
                              (tw, th), _ = cv2.getTextSize(text, font, font_scale, thickness)

                              # Calculate position for font rendering
                              text_x = cx - tw // 2
                              text_y = cy + th // 2
                              cv2.putText(img, text, (text_x, text_y),
                                          font, font_scale, (0, 0, 0), thickness, cv2.LINE_AA)

                  # --- Post-processing ---
                  # Add noise
                  noise_level = random.uniform(5, 15)
                  noise = np.random.normal(0, noise_level, img.shape).astype(np.float32)
                  noisy_img = np.clip(img.astype(np.float32) + noise, 0, 255).astype(np.uint8)

                  # Random perspective warp
                  h, w = noisy_img.shape[:2]
                  orig_corners = np.array([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype="float32")
                  shift_factor = random.uniform(0.02, 0.15) # Reduced max shift slightly
                  max_dx, max_dy = w * shift_factor, h * shift_factor

                  # Generate new corner positions with some randomness
                  warped_corners = np.array([
                      [random.uniform(0, max_dx), random.uniform(0, max_dy)], # Top-left
                      [w - 1 - random.uniform(0, max_dx), random.uniform(0, max_dy)], # Top-right
                      [w - 1 - random.uniform(0, max_dx), h - 1 - random.uniform(0, max_dy)], # Bottom-right
                      [random.uniform(0, max_dx), h - 1 - random.uniform(0, max_dy)], # Bottom-left
                  ], dtype="float32")

                  # Ensure corners maintain roughly the correct order (prevent extreme warps)
                  # Simple check: ensure TL x < TR x, BL x < BR x, TL y < BL y, TR y < BR y
                  if (warped_corners[0,0] >= warped_corners[1,0] or \
                      warped_corners[3,0] >= warped_corners[2,0] or \
                      warped_corners[0,1] >= warped_corners[3,1] or \
                      warped_corners[1,1] >= warped_corners[2,1]):
                       # If order is messed up, use less aggressive warp or skip warp
                       warped_corners = orig_corners # Fallback to no warp this time

                  M = cv2.getPerspectiveTransform(orig_corners, warped_corners)

                  # Calculate output bounds for warped image
                  out_w = int(np.max(warped_corners[:, 0])) + 1
                  out_h = int(np.max(warped_corners[:, 1])) + 1
                  out_w = max(out_w, 100) # Ensure minimum size
                  out_h = max(out_h, 100)

                  warped_img = cv2.warpPerspective(
                      noisy_img, M, (out_w, out_h),
                      flags=cv2.INTER_LINEAR, # Smoother interpolation
                      borderMode=cv2.BORDER_REPLICATE # Replicate border pixels
                  )

                  # Apply slight blur after warping
                  final_img = cv2.GaussianBlur(warped_img, (3, 3), 0)

                  # Return the final image, the puzzle grid (0 for empty), and the warped corners
                  return final_img, gt_puzzle, warped_corners

              except Exception as e:
                  print(f"[Renderer Error] Failed to render Sudoku: {e}")
                  import traceback
                  traceback.print_exc()
                  return None, None, None


      def generate_and_save_test_example(
          prefix: str = "epoch_test_sudoku",
          force: bool = False
      ) -> Tuple[Optional[str], Optional[np.ndarray]]:
          """
          Generate or load a fixed Sudoku test example for epoch callbacks.
          Returns (image_path, ground_truth_puzzle_grid).
          """
          img_path = Path(f"{prefix}.png")
          gt_path = Path(f"{prefix}_gt.npy")

          if not force and img_path.exists() and gt_path.exists():
              try:
                  gt = np.load(gt_path)
                  # Basic check if loaded files are valid
                  if cv2.imread(str(img_path)) is not None and gt.shape == (GRID_SIZE, GRID_SIZE):
                       print(f"Loaded existing test example: {img_path}, {gt_path}")
                       return str(img_path), gt
                  else:
                       print("Existing test example files corrupted, regenerating...")
              except Exception as e:
                  print(f"Error loading existing test example ({e}), regenerating...")

          print("Generating new test example...")
          renderer = SudokuRenderer()
          # Define a specific puzzle grid (0 for empty)
          # This puzzle should ideally be solvable and have a unique solution
          # Example puzzle (source: websudoku.com easy)
          test_puzzle_grid = np.array([
              [0, 0, 3, 0, 2, 0, 6, 0, 0],
              [9, 0, 0, 3, 0, 5, 0, 0, 1],
              [0, 0, 1, 8, 0, 6, 4, 0, 0],
              [0, 0, 8, 1, 0, 2, 9, 0, 0],
              [7, 0, 0, 0, 0, 0, 0, 0, 8],
              [0, 0, 6, 7, 0, 8, 2, 0, 0],
              [0, 0, 2, 6, 0, 9, 5, 0, 0],
              [8, 0, 0, 2, 0, 3, 0, 0, 9],
              [0, 0, 5, 0, 1, 0, 3, 0, 0]
          ], dtype=int)

          # Render this specific puzzle
          img, gt, _ = renderer.render_sudoku(grid_spec=test_puzzle_grid)

          if img is None or gt is None:
              print("[Error] Failed to generate test example image.")
              return None, None

          try:
              cv2.imwrite(str(img_path), img)
              np.save(gt_path, gt)
              print(f"Saved new test example: {img_path}, {gt_path}")
              return str(img_path), gt
          except Exception as e:
              print(f"[Error] Failed to save test example: {e}")
              return None, None

      # Example usage for debugging
      if __name__ == "__main__":
          print("Generating a sample Sudoku image...")
          renderer = SudokuRenderer()
          img, gt, corners = renderer.render_sudoku(allow_empty=True, difficulty=0.6)

          if img is not None:
              print("Generated Ground Truth Puzzle Grid:")
              print(gt)
              cv2.imwrite("sample_sudoku_generated.png", img)
              print("Saved sample image to sample_sudoku_generated.png")

              # Also generate the fixed test example if needed
              generate_and_save_test_example(force=True)
          else:
              print("Failed to generate sample image.")
  diffs_applied_this_send: true
system:
  message: |2

    You are a helpful assistant.
    Respond in markdown format.
    Respond with the full code for any modified or added files. No placeholders.
    A git diff uses "+" or "-" at the start lines. Do NOT use "+" or "-" at the start of any line (unless incidental and not part of a git diff).
    Avoid asking the user to clear their caches or do local configuration related stuff. That's rarely the cause of errors.
    If you ask them, and they reply with a compilation error, assume they've already done everything you suggested and move on.
    But try to avoid such suggestions. It's a cop out. It's like when tech support says 'Have you tried turning it off and on again?'.
    Try to actually fix the error instead.
  model:
    - copy/paste
  code_completion_model:
    - gemini/gemini-2.0-flash-thinking-exp-01-21
  commit_message_model:
    - gemini/gemini-2.0-flash-thinking-exp-01-21
  max_completion_tokens:
  temperature: 0.0
  apply_mode: simple
messages:
  - user: |-
      ```python 'digit_classifier.py'
      """
      SudokuBot – Digit Classifier (Full Grid Prediction)
      Version 2025-04-22

      Major Changes:
      - Model predicts all 81 cells from the rectified grid image at once.
      - Uses a Fully Convolutional Network (FCN) based on ResNet blocks.
      - Data generator yields full grid images and corresponding label grids.
      - Training data uses puzzles derived from valid, solvable Sudoku solutions.
      - Preprocessing and augmentation apply to the full grid image.
      """

      # ------------------------------------------------------------------ #
      # 1.  choose backend BEFORE importing keras
      # ------------------------------------------------------------------ #
      import os
      os.environ["KERAS_BACKEND"] = "torch"  # must be first – do NOT move

      # ------------------------------------------------------------------ #
      # 2.  std‑lib & 3rd‑party imports
      # ------------------------------------------------------------------ #
      import gc
      import random
      from pathlib import Path
      from typing import Callable, Generator, Optional, Tuple

      import cv2
      import numpy as np
      import torch
      import keras
      from keras import callbacks, layers, models, activations, regularizers

      # ------------------------------------------------------------------ #
      # 3.  project‑local imports
      # ------------------------------------------------------------------ #
      try:
          # Use the updated renderer and extractor
          from sudoku_renderer import SudokuRenderer, generate_and_save_test_example
          from digit_extractor import (
              GRID_SIZE,
              DEFAULT_RECTIFIED_SIZE, # Use the size defined in extractor
              extract_cells_from_image,
              rectify_grid,
              # split_into_cells is not directly needed by the classifier anymore
          )
          import sudoku_recogniser # Needed for printing grids in callback
      except ImportError as e:
          print(f"Error importing local modules: {e}")
          print("Please ensure sudoku_renderer.py, digit_extractor.py, and sudoku_recogniser.py are available.")
          # Provide dummy implementations or raise error if essential
          GRID_SIZE = 9
          DEFAULT_RECTIFIED_SIZE = 252
          class SudokuRenderer:
              def render_sudoku(self, allow_empty=True, grid_spec=None): return None, None, None
          def generate_and_save_test_example(force=False): return Path("dummy_test.png"), np.zeros((9,9), dtype=int)
          def extract_cells_from_image(path, size=252, debug=False): return [], np.zeros((size,size), dtype=np.uint8), None
          class sudoku_recogniser:
              FINAL_CONFIDENCE_THRESHOLD = 0.8
              @staticmethod
              def print_sudoku_grid(grid, confs=None, threshold=0.0): pass


      # ------------------------------------------------------------------ #
      # 4.  constants
      # ------------------------------------------------------------------ #
      MODEL_FILENAME = "sudoku_full_grid_classifier_fcn.keras" # New filename for the new model type
      # Input shape based on the rectified grid size from digit_extractor
      MODEL_INPUT_SHAPE = (DEFAULT_RECTIFIED_SIZE, DEFAULT_RECTIFIED_SIZE, 1) # Grayscale input
      NUM_CLASSES = 11  # digits 0-9 + "empty"
      EMPTY_LABEL = 10  # Label used for empty cells in the target data (y)

      # Training parameters
      EPOCHS = 25 # Might need more epochs for a larger model/task
      STEPS_PER_EPOCH = 100 # Adjust based on data generation speed and dataset size
      BATCH_SIZE = 16 # Reduced batch size due to larger input images
      VALIDATION_STEPS = 30

      # Type alias for data batches
      DataBatch = Tuple[np.ndarray, np.ndarray] # (batch_of_grids, batch_of_labels)

      # ------------------------------------------------------------------ #
      # 5.  data generator (simplified for full grids)
      # ------------------------------------------------------------------ #
      def sudoku_data_generator(
          renderer: SudokuRenderer,
          batch_size: int,
          preprocess_func: Callable[[np.ndarray], Optional[np.ndarray]],
          augment_func: Optional[Callable[[np.ndarray], np.ndarray]], # Optional augmentation
          input_shape: Tuple[int, int, int], # e.g., (252, 252, 1)
      ) -> Generator[DataBatch, None, None]:
          """
          Yields batches of (preprocessed_grid_image, target_label_grid).
          Generates valid Sudoku puzzles on the fly.
          """
          target_h, target_w, target_c = input_shape
          is_grayscale = (target_c == 1)

          batch_counter = 0
          while True:
              batch_x = np.zeros((batch_size, target_h, target_w, target_c), dtype="float32")
              batch_y = np.zeros((batch_size, GRID_SIZE, GRID_SIZE), dtype="int64")
              
              items_in_batch = 0
              while items_in_batch < batch_size:
                  # Generate a rendered Sudoku image and its ground truth puzzle grid (0 for empty)
                  img, gt_puzzle_grid, corners = renderer.render_sudoku(allow_empty=True) # Let renderer handle difficulty

                  if img is None or gt_puzzle_grid is None or corners is None:
                      # print("[Generator] Renderer failed, skipping.")
                      time.sleep(0.1) # Avoid busy-looping if renderer fails consistently
                      continue

                  # Rectify the grid using the known corners
                  # Use the target input size for rectification directly
                  rectified = rectify_grid(img, corners, size=target_h) # Assuming target_h == target_w
                  if rectified is None:
                      # print("[Generator] Rectification failed, skipping.")
                      continue

                  # Preprocess the entire rectified grid image
                  processed_grid = preprocess_func(rectified)
                  if processed_grid is None:
                      # print("[Generator] Preprocessing failed, skipping.")
                      continue

                  # Apply augmentation if provided (usually only for training)
                  if augment_func:
                      processed_grid = augment_func(processed_grid)

                  # Ensure the processed grid has the correct shape (H, W, C)
                  if processed_grid.shape != (target_h, target_w, target_c):
                       print(f"[Generator Warning] Processed grid shape mismatch: expected {(target_h, target_w, target_c)}, got {processed_grid.shape}. Skipping.")
                       continue


                  # Convert the ground truth puzzle grid (0 for empty) to the target format
                  # where empty cells are represented by EMPTY_LABEL (10)
                  target_labels = gt_puzzle_grid.copy()
                  target_labels[target_labels == 0] = EMPTY_LABEL

                  # Add to batch
                  batch_x[items_in_batch] = processed_grid
                  batch_y[items_in_batch] = target_labels
                  items_in_batch += 1

              # Yield the complete batch
              batch_counter += 1
              # Optional debug print
              # if batch_counter % 10 == 0:
              #     print(f"[Generator] Yielding batch {batch_counter}. Example label counts: {np.bincount(batch_y[0].flatten(), minlength=NUM_CLASSES)}")

              yield batch_x, batch_y
              # No need for explicit gc.collect() here usually, Python handles it.


      # ------------------------------------------------------------------ #
      # 6.  classifier object (handles full grid model)
      # ------------------------------------------------------------------ #
      class DigitClassifier:
          """
          Handles loading, training and inference of the FCN Sudoku grid classifier.
          """

          # -------------------------------------------------------------- #
          # constructor
          # -------------------------------------------------------------- #
          def __init__(
              self,
              model_path: Optional[str | Path] = None,
              training_required: bool = False,
          ) -> None:
              self.model_path = Path(model_path) if model_path else Path(MODEL_FILENAME)
              self.model: Optional[keras.Model] = None
              self._model_input_shape = MODEL_INPUT_SHAPE # e.g., (252, 252, 1)

              if not training_required and self.model_path.exists():
                  print(f"Attempting to load model from {self.model_path}...")
                  try:
                      self.model = keras.models.load_model(self.model_path)
                      # Check if loaded model's input shape matches config
                      # Keras models sometimes store input shape as (None, H, W, C)
                      loaded_shape = self.model.input_shape[1:]
                      if loaded_shape != self._model_input_shape:
                          print(f"[Warning] Loaded model input shape {loaded_shape} "
                                f"differs from expected {self._model_input_shape}. Mismatch may cause errors.")
                      print(f"Full-grid classifier model loaded successfully.")
                  except Exception as e:
                      print(f"[Error] Failed to load model from {self.model_path}: {e}")
                      print("Will build and train a new model if training is enabled.")
                      self.model = None # Ensure model is None if loading failed

              # Handle training_required flag
              if training_required and self.model is not None:
                   print("Training required: Ignoring previously loaded model and building a new one.")
                   self.model = None
              elif training_required and self.model is None:
                   print("Training required: Model will be built.")
              elif not training_required and self.model is None:
                   print("Model not found or failed to load, and training not required. Classifier is inactive.")


          # -------------------------------------------------------------- #
          # ResNet-style building block (same as before)
          # -------------------------------------------------------------- #
          def _residual_block(self, x, filters, strides=1, activation="relu"):
              """Basic residual block."""
              shortcut = x
              # Downsample shortcut if needed
              if strides > 1 or shortcut.shape[-1] != filters:
                  shortcut = layers.Conv2D(
                      filters, 1, strides=strides, use_bias=False, kernel_initializer="he_normal",
                      kernel_regularizer=regularizers.l2(1e-5) # Added slight L2 regularization
                  )(shortcut)
                  shortcut = layers.BatchNormalization()(shortcut)

              # First convolution
              y = layers.Conv2D(
                  filters, 3, strides=strides, padding="same", use_bias=False, kernel_initializer="he_normal",
                  kernel_regularizer=regularizers.l2(1e-5)
              )(x)
              y = layers.BatchNormalization()(y)
              y = layers.Activation(activation)(y)

              # Second convolution
              y = layers.Conv2D(
                  filters, 3, padding="same", use_bias=False, kernel_initializer="he_normal",
                  kernel_regularizer=regularizers.l2(1e-5)
              )(y)
              y = layers.BatchNormalization()(y)

              # Add shortcut
              y = layers.Add()([shortcut, y])
              y = layers.Activation(activation)(y)
              return y

          # -------------------------------------------------------------- #
          # backbone (FCN for full grid prediction)
          # -------------------------------------------------------------- #
          def _build_cnn_model(self) -> keras.Model:
              """Builds a Fully Convolutional Network (FCN) for grid prediction."""
              activation_func = "relu" # Or 'gelu'

              x_in = keras.Input(shape=self._model_input_shape) # e.g., (252, 252, 1)

              # --- Encoder Path (Downsampling) ---
              # Initial Conv Layer (Stem)
              # Use stride 3 to quickly reduce dimensions: 252 -> 84
              filters = 32
              x = layers.Conv2D(filters, 7, strides=3, padding="same", use_bias=False, kernel_initializer="he_normal")(x_in)
              x = layers.BatchNormalization()(x)
              x = layers.Activation(activation_func)(x)
              # x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # Optional extra pooling

              # Residual Blocks with increasing filters and downsampling
              # Block 1: 84x84 -> 84x84 (filters=32)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 2: 84x84 -> 28x28 (filters=64, stride=3)
              filters *= 2 # 64
              x = self._residual_block(x, filters, strides=3, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 3: 28x28 -> 28x28 (filters=128) - Stride 1 here
              filters *= 2 # 128
              x = self._residual_block(x, filters, strides=1, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 4: 28x28 -> 14x14 (filters=256, stride=2) - Aiming for spatial dim > 9
              filters *= 2 # 256
              x = self._residual_block(x, filters, strides=2, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # --- Prediction Head ---
              # At this point, spatial dimension is 14x14. We need 9x9 output.
              # Option 1: Use a Conv layer with stride to reduce size (might lose info)
              # Option 2: Use Adaptive Pooling (if available/easy in Keras backend)
              # Option 3: Use Conv + Upsampling (more complex)
              # Option 4: Use a final Conv layer that implicitly handles the size reduction (less common)

              # Let's try a Conv2D layer designed to output the correct spatial dimensions.
              # We need to get closer to 9x9. Add another block?
              # Block 5: 14x14 -> 7x7 (filters=512, stride=2)
              # filters *= 2 # 512
              # x = self._residual_block(x, filters, strides=2, activation=activation_func)
              # x = self._residual_block(x, filters, strides=1, activation=activation_func)
              # Now spatial dim is 7x7. This is too small.

              # Backtrack: Let's stop at 14x14 (Block 4 output).
              # How to get to (9, 9, NUM_CLASSES)?
              # Use a 1x1 Conv to reduce filters, then maybe resize/crop or use specific conv?

              # Try a final Conv layer with appropriate kernel/padding to target 9x9.
              # Input to this layer is (None, 14, 14, 256)
              # Output needed is (None, 9, 9, NUM_CLASSES)

              # Use a 1x1 convolution to adjust the number of channels first
              x = layers.Conv2D(128, 1, padding='same', activation=activation_func, kernel_initializer='he_normal')(x)
              x = layers.BatchNormalization()(x)
              # Now (None, 14, 14, 128)

              # Use a final Conv2D layer to produce the output map.
              # A kernel size of 6 with valid padding on a 14x14 input gives (14-6+1) = 9x9 output.
              # Stride 1 is implicit.
              x = layers.Conv2D(
                  filters=NUM_CLASSES,
                  kernel_size=6, # Kernel size chosen to map 14x14 -> 9x9 with 'valid' padding
                  padding="valid", # 'valid' means no padding
                  activation=None, # Apply softmax separately across the class dimension
                  kernel_initializer='he_normal',
                  name="final_conv_logits"
              )(x)
              # Output shape should now be (None, 9, 9, NUM_CLASSES)

              # Apply Softmax activation across the last axis (classes)
              y_out = layers.Activation("softmax", name="output_softmax")(x)

              # Create the model
              model = models.Model(x_in, y_out, name="fcn_sudoku_grid")

              # Compile the model
              optimizer = keras.optimizers.Adam(learning_rate=5e-4) # Slightly higher LR?
              # Loss function suitable for integer targets and probability outputs
              loss = "sparse_categorical_crossentropy"
              # Metrics: Accuracy calculated per cell prediction
              metrics = ["accuracy"]

              model.compile(
                  optimizer=optimizer,
                  loss=loss,
                  metrics=metrics,
              )
              model.summary(line_length=120)
              return model

          # -------------------------------------------------------------- #
          # preprocessing (for full grid image)
          # -------------------------------------------------------------- #
          def _preprocess_grid_for_model(self, rectified_img: np.ndarray) -> Optional[np.ndarray]:
              """
              Prepares the rectified grid image for the FCN model.
              Resizes, converts to grayscale, normalizes to [0, 1], adds channel dim.
              """
              if rectified_img is None or rectified_img.size == 0:
                  return None

              target_h, target_w, target_c = self._model_input_shape
              is_grayscale = (target_c == 1)

              # Resize to target input size
              # Use INTER_AREA for shrinking, INTER_LINEAR for enlarging
              current_h, current_w = rectified_img.shape[:2]
              if current_h * current_w > target_h * target_w:
                  interp = cv2.INTER_AREA
              else:
                  interp = cv2.INTER_LINEAR
              resized = cv2.resize(rectified_img, (target_w, target_h), interpolation=interp)

              # Ensure correct number of channels (grayscale)
              if is_grayscale:
                  if resized.ndim == 3 and resized.shape[2] == 3:
                      processed = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)
                  elif resized.ndim == 3 and resized.shape[2] == 4:
                      processed = cv2.cvtColor(resized, cv2.COLOR_BGRA2GRAY)
                  elif resized.ndim == 2:
                      processed = resized
                  else:
                      print(f"[Preprocess Error] Unexpected image shape: {resized.shape}")
                      return None
                  # Add channel dimension: (H, W) -> (H, W, 1)
                  processed = processed[..., np.newaxis]
              else: # If model expected color input (target_c == 3)
                  if resized.ndim == 2: # Convert grayscale to BGR
                      processed = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)
                  elif resized.ndim == 3 and resized.shape[2] == 4: # Convert BGRA to BGR
                       processed = cv2.cvtColor(resized, cv2.COLOR_BGRA2BGR)
                  elif resized.ndim == 3 and resized.shape[2] == 3:
                       processed = resized # Already BGR
                  else:
                      print(f"[Preprocess Error] Unexpected image shape for color: {resized.shape}")
                      return None

              # Normalize to [0, 1] float32
              processed = processed.astype("float32") / 255.0

              return processed


          # ------------------------------------------------------------------ #
          # 7.1  augmentation (for full grid image)
          # ------------------------------------------------------------------ #
          def _augment_grid(self, grid_img: np.ndarray) -> np.ndarray:
              """Apply augmentations to the full grid image."""
              h, w = grid_img.shape[:2]
              augmented = grid_img.copy()

              # 1. Small Rotation
              if random.random() < 0.5:
                  angle = random.uniform(-8, 8) # Reduced angle for full grid
                  M_rot = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1.0)
                  augmented = cv2.warpAffine(augmented, M_rot, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0) # Black border

              # 2. Small Translation
              if random.random() < 0.5:
                  tx = random.uniform(-w * 0.03, w * 0.03) # Max 3% translation
                  ty = random.uniform(-h * 0.03, h * 0.03)
                  M_trans = np.float32([[1, 0, tx], [0, 1, ty]])
                  augmented = cv2.warpAffine(augmented, M_trans, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0)

              # 3. Brightness/Contrast Jitter
              if random.random() < 0.6:
                  alpha = random.uniform(0.85, 1.15) # Contrast
                  beta = random.uniform(-0.1, 0.1)   # Brightness
                  augmented = np.clip(augmented * alpha + beta, 0.0, 1.0)

              # 4. Gaussian Noise
              if random.random() < 0.3:
                  noise = np.random.normal(0, random.uniform(0.01, 0.05), augmented.shape)
                  augmented = np.clip(augmented + noise, 0.0, 1.0)

              # Ensure output is float32
              return augmented.astype("float32")


          # -------------------------------------------------------------- #
          # training
          # -------------------------------------------------------------- #
          def train(
              self,
              epochs: int = EPOCHS,
              steps_per_epoch: int = STEPS_PER_EPOCH,
              batch_size: int = BATCH_SIZE,
              validation_steps: int = VALIDATION_STEPS,
          ) -> None:
              """Trains the full-grid FCN model."""
              print(f"\n--- Training Full Grid Classifier ---")
              print(f"Epochs: {epochs}, Steps/Epoch: {steps_per_epoch}, Batch Size: {batch_size}")
              print(f"Input Shape: {self._model_input_shape}, Output: (9, 9, {NUM_CLASSES})")

              if self.model is None:
                  self.model = self._build_cnn_model()
              elif not isinstance(self.model, keras.Model):
                   print("[Error] self.model is not a valid Keras model. Cannot train.")
                   return

              # Prepare test example for callback
              try:
                  test_img_path, test_gt_grid = generate_and_save_test_example()
                  if test_img_path is None or test_gt_grid is None:
                       raise ValueError("Failed to generate/load test example.")
                  # Pass the classifier instance and the ground truth grid (0 for empty)
                  epoch_cb = EpochTestCallback(test_img_path, test_gt_grid, self)
              except Exception as e:
                  print(f"[Warning] Failed to set up EpochTestCallback: {e}. Callback disabled.")
                  epoch_cb = None

              # Create data generators
              # Training generator uses augmentation
              train_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  self._augment_grid, # Apply augmentation
                  self._model_input_shape,
              )
              # Validation generator does not use augmentation
              val_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  None, # No augmentation for validation
                  self._model_input_shape,
              )

              # Dump a batch of augmented training samples for visualization
              dump_dir = Path("dumped_training_grids")
              dump_dir.mkdir(exist_ok=True)
              try:
                  x_vis, y_vis = next(train_gen) # Get one batch from training gen
                  n_dump = min(4, x_vis.shape[0]) # Dump fewer, larger images
                  for i in range(n_dump):
                      # Convert float32 [0,1] -> uint8 [0,255]
                      img = (x_vis[i] * 255).astype(np.uint8)
                      # Maybe add label info to filename if needed, but grid is complex
                      cv2.imwrite(str(dump_dir / f"sample_grid_{i}.png"), img)
                  print(f"[Info] Dumped {n_dump} augmented training grid samples to {dump_dir}")
              except Exception as e:
                  print(f"[Warning] Could not dump training samples: {e}")


              # Callbacks
              cbs: list[callbacks.Callback] = [
                  callbacks.EarlyStopping(
                      monitor="val_accuracy", # Monitor validation accuracy (per-cell)
                      patience=10,          # Increased patience for larger model
                      restore_best_weights=True,
                      verbose=1,
                      mode='max'
                  ),
                  callbacks.ModelCheckpoint(
                      filepath=str(self.model_path), # Ensure path is string
                      monitor="val_accuracy",
                      save_best_only=True,
                      verbose=1,
                      mode='max'
                  ),
                  callbacks.ReduceLROnPlateau(
                      monitor="val_loss", # Reduce LR based on validation loss
                      factor=0.2,
                      patience=4,
                      min_lr=1e-7,
                      verbose=1,
                      mode='min' # Reduce LR when loss plateaus
                  ),
                  # Optional: TensorBoard
                  # callbacks.TensorBoard(log_dir='./logs_fcn', histogram_freq=1)
              ]
              if epoch_cb:
                  cbs.append(epoch_cb)

              # Start Training
              print("\nStarting model training...")
              history = self.model.fit(
                  train_gen,
                  epochs=epochs,
                  steps_per_epoch=steps_per_epoch,
                  validation_data=val_gen,
                  validation_steps=validation_steps,
                  callbacks=cbs,
                  verbose=1, # Use 1 for progress bar, 2 for one line per epoch
              )

              # Ensure the best model is loaded (EarlyStopping might restore, Checkpoint saves)
              if self.model_path.exists():
                   print(f"Reloading best weights from {self.model_path}...")
                   try:
                       # Use load_model if the whole architecture might change,
                       # or load_weights if only weights are saved/needed.
                       # ModelCheckpoint saves the whole model by default.
                       self.model = keras.models.load_model(self.model_path)
                       print("Best model reloaded.")
                   except Exception as e:
                       print(f"[Error] Failed to reload best model after training: {e}")
                       # The model instance might still hold the best weights if EarlyStopping restored them.

              print("\n--- Final Evaluation (using best weights) ---")
              # Use a fresh validation generator for final evaluation
              final_eval_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  None, # No augmentation
                  self._model_input_shape,
              )
              loss, acc = self.model.evaluate(
                  final_eval_gen,
                  steps=validation_steps * 2, # Evaluate on more validation steps
                  verbose=1,
              )
              print(f"Final Validation Loss: {loss:.5f}")
              print(f"Final Validation Accuracy (per cell): {acc:.5f}")

              # Explicitly save the final best model again (belt-and-suspenders)
              try:
                  print(f"Saving final best model to {self.model_path}")
                  self.model.save(self.model_path)
              except Exception as e:
                  print(f"[Error] Failed to save final model: {e}")

              del train_gen, val_gen, final_eval_gen, history
              gc.collect()
              print("--- Training Finished ---")


          # -------------------------------------------------------------- #
          # inference (for full grid)
          # -------------------------------------------------------------- #
          @torch.no_grad() # Keep decorator if using torch backend
          def recognise_grid(
              self,
              rectified_img: np.ndarray,
              confidence_threshold: float = 0.80, # Default threshold for accepting a digit
          ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
              """
              Recognises digits in a rectified Sudoku grid image using the FCN model.

              Args:
                  rectified_img: The (e.g., 252x252) rectified grid image (uint8 or float).
                  confidence_threshold: Minimum confidence to accept a digit prediction (1-9).

              Returns:
                  A tuple (predicted_grid, confidence_grid):
                  - predicted_grid: (9, 9) numpy array with recognised digits (1-9) or 0 for empty/uncertain.
                  - confidence_grid: (9, 9) numpy array with confidence scores for the predicted class in each cell.
                  Returns (None, None) if inference fails.
              """
              if self.model is None:
                  print("[Error] Recognise_grid called but model is not loaded.")
                  return None, None

              # 1. Preprocess the input grid image
              proc_grid = self._preprocess_grid_for_model(rectified_img)
              if proc_grid is None:
                  print("[Error] Preprocessing failed during recognition.")
                  return None, None # Indicate failure

              # 2. Add batch dimension: (H, W, C) -> (1, H, W, C)
              x = proc_grid[np.newaxis, ...]

              # 3. Predict using the Keras model
              try:
                  # Use training=False for inference (important for layers like BatchNorm, Dropout)
                  raw_output = self.model(x, training=False) # Shape: (1, 9, 9, NUM_CLASSES)
              except Exception as e:
                  print(f"[Error] Model prediction failed: {e}")
                  return None, None

              # 4. Convert to NumPy and remove batch dimension
              # Keras with torch backend might return torch tensors
              if hasattr(raw_output, 'cpu') and hasattr(raw_output, 'numpy'): # Check if it's a tensor with cpu/numpy methods
                   probs = raw_output.cpu().numpy()
              elif isinstance(raw_output, np.ndarray):
                   probs = raw_output
              else:
                   print(f"[Error] Unexpected model output type: {type(raw_output)}")
                   return None, None

              probs = probs[0] # Shape: (9, 9, NUM_CLASSES)

              # 5. Decode probabilities to predictions and confidences
              predicted_indices = np.argmax(probs, axis=-1) # Shape: (9, 9), contains indices 0-10
              confidences = np.max(probs, axis=-1)       # Shape: (9, 9), contains max probability

              # 6. Create the final output grid
              # Initialize with zeros (representing empty/uncertain)
              final_grid = np.zeros((GRID_SIZE, GRID_SIZE), dtype=int)

              # Iterate through each cell prediction
              for r in range(GRID_SIZE):
                  for c in range(GRID_SIZE):
                      pred_idx = predicted_indices[r, c]
                      conf = confidences[r, c]

                      # Check if the prediction is a digit (1-9), not EMPTY_LABEL (10),
                      # and if the confidence meets the threshold.
                      if pred_idx != EMPTY_LABEL and conf >= confidence_threshold:
                          final_grid[r, c] = pred_idx # Assign the predicted digit (1-9)
                      # Otherwise, leave it as 0 (empty/uncertain)

              return final_grid, confidences


      # ------------------------------------------------------------------ #
      # 8.  epoch‑end callback (adapted for full grid)
      # ------------------------------------------------------------------ #
      class EpochTestCallback(callbacks.Callback):
          def __init__(
              self,
              test_img_path: Path | str,
              gt_puzzle_grid: np.ndarray, # Ground truth puzzle (0 for empty)
              classifier: "DigitClassifier",
              frequency: int = 1,
          ) -> None:
              super().__init__()
              self.frequency = max(1, frequency)
              self.gt_puzzle_grid = gt_puzzle_grid # Shape (9, 9), 0 for empty
              self.classifier = classifier
              self.test_img_path = test_img_path
              self.preprocessed_test_grid = None # To store the single preprocessed grid

          def on_train_begin(self, logs=None):
              """Preprocess the test image once before training starts."""
              print("\n[Callback] Preprocessing test example for epoch-end evaluation...")
              try:
                  # Extract the rectified grid from the test image file
                  # We don't need the individual cells here, just the rectified image
                  _, rectified_test_img, _ = extract_cells_from_image(
                      self.test_img_path,
                      size=self.classifier._model_input_shape[0], # Use model's input size
                      debug=False
                  )

                  if rectified_test_img is None:
                      print("[Callback Error] Failed to extract rectified grid from test image.")
                      self.preprocessed_test_grid = None
                      return

                  # Preprocess the rectified grid using the classifier's method
                  self.preprocessed_test_grid = self.classifier._preprocess_grid_for_model(rectified_test_img)

                  if self.preprocessed_test_grid is None:
                      print("[Callback Error] Preprocessing of the test grid failed.")
                  else:
                      print(f"[Callback] Test grid preprocessed successfully ({self.preprocessed_test_grid.shape}).")

              except Exception as e:
                  print(f"[Callback Error] Failed during test example setup: {e}")
                  self.preprocessed_test_grid = None

          def on_epoch_end(self, epoch, logs=None):
              # Check if preprocessing was successful and if it's the right epoch
              if self.preprocessed_test_grid is None or (epoch + 1) % self.frequency != 0:
                  return

              if not hasattr(self.model, 'predict'):
                   print("[Callback Error] Model object in callback does not have predict method.")
                   return

              print(f"\n--- Epoch {epoch+1} Test Example Evaluation ---")
              try:
                  # Add batch dimension for prediction
                  x_test = self.preprocessed_test_grid[np.newaxis, ...]

                  # Predict using the model being trained
                  raw_output = self.model.predict(x_test, verbose=0) # Shape: (1, 9, 9, NUM_CLASSES)

                  # Decode the output (similar to recognise_grid)
                  probs = raw_output[0] # Remove batch dim -> (9, 9, NUM_CLASSES)
                  pred_indices = np.argmax(probs, axis=-1) # (9, 9) indices 0-10
                  confs = np.max(probs, axis=-1)       # (9, 9) confidences

                  # Apply thresholding for display (use a slightly lower threshold maybe)
                  display_threshold = 0.7 # Threshold for visualization purposes
                  display_grid = np.zeros_like(pred_indices, dtype=int)
                  for r in range(GRID_SIZE):
                      for c in range(GRID_SIZE):
                          idx = pred_indices[r, c]
                          cf = confs[r, c]
                          if idx != EMPTY_LABEL and cf >= display_threshold:
                              display_grid[r, c] = idx

                  print("Ground Truth Puzzle:")
                  # print_sudoku_grid expects 0 for empty
                  sudoku_recogniser.print_sudoku_grid(self.gt_puzzle_grid)

                  print(f"Prediction (Thresholded @ {display_threshold:.2f}):")
                  sudoku_recogniser.print_sudoku_grid(display_grid, confs, threshold=display_threshold)

                  # --- Calculate Accuracy ---
                  # Compare prediction indices directly with the GT grid converted to use EMPTY_LABEL
                  gt_labels = self.gt_puzzle_grid.copy()
                  gt_labels[gt_labels == 0] = EMPTY_LABEL # Convert GT to use 10 for empty

                  correct_cells = (pred_indices == gt_labels).sum()
                  total_cells = GRID_SIZE * GRID_SIZE
                  accuracy = correct_cells / total_cells
                  print(f"Test Example Accuracy (Raw Prediction vs GT Labels): {correct_cells}/{total_cells} = {accuracy:.4f}")
                  print("--- End Epoch Test ---\n")

              except Exception as e:
                  print(f"[Callback Error] Failed during prediction or display: {e}")
                  import traceback
                  traceback.print_exc()


      # ------------------------------------------------------------------ #
      # 9.  CLI helper
      # ------------------------------------------------------------------ #
      if __name__ == "__main__":
          # Set to True to force retraining even if a model file exists
          FORCE_TRAIN = False

          model_file = Path(MODEL_FILENAME)
          train_needed = FORCE_TRAIN or not model_file.exists()

          if FORCE_TRAIN and model_file.exists():
              print(f"FORCE_TRAIN is True. Deleting existing model: {model_file}")
              try:
                  model_file.unlink()
                  train_needed = True
              except OSError as e:
                  print(f"Error deleting existing model: {e}. Proceeding might use old model if loading works.")
                  # Decide whether to exit or continue
                  # exit(1)

          # Instantiate the classifier. It will try to load if train_needed is False.
          clf = DigitClassifier(model_path=model_file, training_required=train_needed)

          # Train if needed
          if train_needed:
              if clf.model is not None:
                   print("[Warning] Model was loaded despite train_needed=True? Retraining anyway.")
                   clf.model = None # Ensure model is rebuilt
              print("Starting training process...")
              clf.train(epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, batch_size=BATCH_SIZE)
              # After training, the best model should be saved and reloaded by the train method.
              if clf.model is None:
                   print("[Error] Training finished, but model is still None. Cannot proceed.")
                   exit(1)
          elif clf.model is None:
               print("[Error] Model loading failed, and training was not requested. Cannot proceed.")
               exit(1)
          else:
               print("Model loaded successfully. Skipping training.")


          # --- Perform Sanity Check using the Test Example ---
          if clf.model:
              print("\n--- Sanity Check: Recognising the Test Example ---")
              test_img_path_str, test_gt_grid = generate_and_save_test_example() # Get path and GT

              if test_img_path_str is None or test_gt_grid is None:
                  print("Failed to load test example for sanity check.")
              else:
                  test_img_path = Path(test_img_path_str)
                  print(f"Loading test image: {test_img_path}")
                  # Extract rectified grid from the test image
                  _, rectified_test, _ = extract_cells_from_image(
                      test_img_path,
                      size=clf._model_input_shape[0], # Use model's input size
                      debug=False
                  )

                  if rectified_test is None:
                      print("Failed to extract rectified grid from test image for sanity check.")
                  else:
                      print("Running recognise_grid on the test image...")
                      # Use a reasonable confidence threshold for the check
                      pred_grid, conf_grid = clf.recognise_grid(rectified_test, confidence_threshold=0.75)

                      if pred_grid is None:
                          print("Recognition failed during sanity check.")
                      else:
                          print("\nGround Truth Puzzle:")
                          sudoku_recogniser.print_sudoku_grid(test_gt_grid)

                          print("Recognised Grid (Thresholded @ 0.75):")
                          sudoku_recogniser.print_sudoku_grid(pred_grid, conf_grid, threshold=0.75)

                          # Calculate accuracy for the sanity check
                          correct_cells = (pred_grid == test_gt_grid).sum()
                          # Account for empty cells being 0 in both GT and prediction (correctly)
                          # Non-empty cells must match exactly
                          correct_non_empty = ((pred_grid == test_gt_grid) & (test_gt_grid != 0)).sum()
                          correct_empty = ((pred_grid == 0) & (test_gt_grid == 0)).sum()
                          total_correct = correct_non_empty + correct_empty

                          total_cells = GRID_SIZE * GRID_SIZE
                          accuracy = total_correct / total_cells
                          print(f"\nSanity Check Accuracy: {total_correct}/{total_cells} = {accuracy:.4f}")
          else:
              print("\nSanity check skipped: No model available.")

          print("\nScript finished.")

      ```
    metadata:
      filename: digit_classifier.py
  - user: |-
      ```python 'digit_extractor.py'
      """
      Find and extract Sudoku grid cells from an image.
      """

      import os
      from pathlib import Path
      from typing import List, Tuple, Optional

      import cv2
      import numpy as np

      GRID_SIZE = 9
      # Changed default size to be divisible by common CNN strides (e.g., 2^3=8 or 3^3=27)
      # 252 = 9 * 28 -> divisible by 2, 3, 4, 6, 7, 9, 12, 14, 18, 21, 28...
      DEFAULT_RECTIFIED_SIZE = 252


      def _order_points(pts: np.ndarray) -> np.ndarray:
          """Order four points as top-left, top-right, bottom-right, bottom-left."""
          pts = pts.reshape(4, 2).astype("float32")
          rect = np.zeros((4, 2), dtype="float32")
          s = pts.sum(axis=1)
          rect[0] = pts[np.argmin(s)] # Top-left has smallest sum
          rect[2] = pts[np.argmax(s)] # Bottom-right has largest sum
          diff = np.diff(pts, axis=1) # diff = y - x
          rect[1] = pts[np.argmin(diff)] # Top-right has smallest diff
          rect[3] = pts[np.argmax(diff)] # Bottom-left has largest diff
          return rect


      def find_sudoku_grid_contour(
          img: np.ndarray,
          debug_dir: Optional[Path] = None
      ) -> Optional[np.ndarray]:
          """
          Find the largest 4-point contour approximating the Sudoku grid boundary.
          Returns the contour points (4, 2) or None if not found.
          """
          if img is None or img.size == 0:
              print("[Contour Finder] Invalid input image.")
              return None

          gray = (
              cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
              if img.ndim == 3 and img.shape[2] == 3 else img.copy()
          )
          if gray.ndim == 3: # Handle case like RGBA input
              gray = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)

          if debug_dir:
              debug_dir.mkdir(parents=True, exist_ok=True)
              cv2.imwrite(str(debug_dir / "00_gray.png"), gray)

          # Preprocessing: Blur and Threshold
          # GaussianBlur helps reduce noise before thresholding
          blur = cv2.GaussianBlur(gray, (7, 7), 0)
          if debug_dir: cv2.imwrite(str(debug_dir / "01_blur.png"), blur)

          # Adaptive thresholding is generally robust to lighting changes
          thresh = cv2.adaptiveThreshold(
              blur, 255,
              cv2.ADAPTIVE_THRESH_GAUSSIAN_C, # Method
              cv2.THRESH_BINARY_INV,         # Threshold type (invert to get black lines on white)
              15,                            # Block size (must be odd) - adjust based on image size/line thickness
              4                              # Constant C subtracted from mean
          )
          if debug_dir: cv2.imwrite(str(debug_dir / "02_thresh.png"), thresh)

          # Morphological closing to connect broken lines
          kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
          closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)
          if debug_dir: cv2.imwrite(str(debug_dir / "03_closed.png"), closed)

          # Find contours
          contours, _ = cv2.findContours(
              closed,
              cv2.RETR_EXTERNAL,        # Retrieve only outer contours
              cv2.CHAIN_APPROX_SIMPLE   # Compress horizontal/vertical segments
          )

          if not contours:
              print("[Contour Finder] No contours found.")
              return None

          # Sort contours by area (descending) and filter small ones
          contours = sorted(contours, key=cv2.contourArea, reverse=True)
          min_area = gray.size * 0.05 # Require contour to be at least 5% of image area

          if debug_dir:
              img_contours = img.copy() if img.ndim == 3 else cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
              cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 1) # Draw all contours found
              cv2.imwrite(str(debug_dir / "04_all_contours.png"), img_contours)


          # Find the largest quadrilateral contour that resembles a square
          for i, cnt in enumerate(contours):
              area = cv2.contourArea(cnt)
              if area < min_area:
                  # print(f"[Contour Finder] Remaining contours too small (area {area} < {min_area}).")
                  break # No need to check smaller contours

              peri = cv2.arcLength(cnt, True)
              # Approximate the contour shape to a polygon
              approx = cv2.approxPolyDP(cnt, 0.02 * peri, True) # Epsilon factor determines accuracy

              # Check if the approximation has 4 vertices and is convex
              if len(approx) == 4 and cv2.isContourConvex(approx):
                  # Check aspect ratio of the bounding box
                  x, y, w, h = cv2.boundingRect(approx)
                  aspect_ratio = w / float(h) if h > 0 else 0

                  # Allow some tolerance for perspective distortion
                  if 0.7 < aspect_ratio < 1.3:
                      if debug_dir:
                          img_found = img.copy() if img.ndim == 3 else cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
                          cv2.drawContours(img_found, [approx], -1, (0, 0, 255), 3)
                          cv2.imwrite(str(debug_dir / f"05_found_contour_{i}.png"), img_found)
                      # print(f"[Contour Finder] Found potential grid contour (index {i}, area {area:.0f}, aspect {aspect_ratio:.2f}).")
                      return approx.reshape(4, 2).astype("float32") # Return the corner points

          print("[Contour Finder] No suitable Sudoku grid contour found.")
          return None


      def rectify_grid(
          img: np.ndarray,
          contour: np.ndarray,
          size: int = DEFAULT_RECTIFIED_SIZE
      ) -> Optional[np.ndarray]:
          """Perspective-correct the Sudoku grid to a square of given size."""
          if contour is None or contour.shape != (4, 2):
              print("[Rectifier] Invalid contour provided.")
              return None
          if img is None or img.size == 0:
              print("[Rectifier] Invalid image provided.")
              return None

          try:
              # Order the contour points: TL, TR, BR, BL
              src_pts = _order_points(contour)

              # Define the destination points for the square image
              dst_pts = np.array([
                  [0, 0],             # Top-left
                  [size - 1, 0],      # Top-right
                  [size - 1, size - 1], # Bottom-right
                  [0, size - 1],      # Bottom-left
              ], dtype="float32")

              # Calculate the perspective transform matrix
              matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)

              # Apply the perspective warp
              warped = cv2.warpPerspective(img, matrix, (size, size))
              return warped
          except Exception as e:
              print(f"[Rectifier] Error during perspective warp: {e}")
              return None


      def split_into_cells(
          rectified: np.ndarray
      ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray]]:
          """
          Split the rectified grid into GRID_SIZE × GRID_SIZE cell images.
          Applies a small margin removal.
          Returns (cells, rectified_image) or (None, None) on failure.
          """
          if rectified is None or rectified.shape[0] != rectified.shape[1]:
              print("[Splitter] Invalid rectified image provided.")
              return None, None

          h, w = rectified.shape[:2]
          if h == 0 or w == 0:
              print("[Splitter] Rectified image has zero dimension.")
              return None, None

          cell_sz_h = h // GRID_SIZE
          cell_sz_w = w // GRID_SIZE
          if cell_sz_h == 0 or cell_sz_w == 0:
              print("[Splitter] Calculated cell size is zero.")
              return None, None

          # Calculate margin to remove grid lines (e.g., 4% of cell size)
          margin_y = max(1, int(cell_sz_h * 0.04))
          margin_x = max(1, int(cell_sz_w * 0.04))

          cells: List[np.ndarray] = []
          for row in range(GRID_SIZE):
              for col in range(GRID_SIZE):
                  # Calculate cell boundaries with margin
                  y0 = row * cell_sz_h + margin_y
                  x0 = col * cell_sz_w + margin_x
                  y1 = (row + 1) * cell_sz_h - margin_y
                  x1 = (col + 1) * cell_sz_w - margin_x

                  # Ensure coordinates are valid and extract cell
                  if y0 < y1 and x0 < x1:
                      cell = rectified[y0:y1, x0:x1]
                      cells.append(cell)
                  else:
                      # Handle cases where margin is too large for cell size (should be rare)
                      # Fallback: extract cell without margin
                      y0_nomargin = row * cell_sz_h
                      x0_nomargin = col * cell_sz_w
                      y1_nomargin = (row + 1) * cell_sz_h
                      x1_nomargin = (col + 1) * cell_sz_w
                      cell = rectified[y0_nomargin:y1_nomargin, x0_nomargin:x1_nomargin]
                      # Add a blank cell if even no-margin extraction fails
                      if cell is None or cell.size == 0:
                           cell_shape = (cell_sz_h, cell_sz_w) + rectified.shape[2:] if rectified.ndim > 2 else (cell_sz_h, cell_sz_w)
                           cell = np.zeros(cell_shape, rectified.dtype) # Create blank cell
                      cells.append(cell)


          if len(cells) != GRID_SIZE * GRID_SIZE:
              print(f"[Splitter] Incorrect number of cells extracted: {len(cells)}")
              return None, rectified # Return None for cells but keep rectified image

          return cells, rectified


      def extract_cells_from_image(
          img_or_path,
          size: int = DEFAULT_RECTIFIED_SIZE,
          debug: bool = False
      ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray], Optional[np.ndarray]]:
          """
          High-level function: read image, find grid, rectify, and split into cells.
          Returns (cells, rectified_image, contour) or (None, None, None) on failure.
          """
          if isinstance(img_or_path, (str, Path)):
              img_path = str(img_or_path)
              if not Path(img_path).exists():
                  print(f"[Extractor] Image file not found: {img_path}")
                  return None, None, None
              img = cv2.imread(img_path)
              if img is None:
                  print(f"[Extractor] Failed to read image: {img_path}")
                  return None, None, None
          elif isinstance(img_or_path, np.ndarray):
              img = img_or_path.copy()
          else:
              print("[Extractor] Invalid input type (must be path or numpy array).")
              return None, None, None

          if img.size == 0:
              print("[Extractor] Input image is empty.")
              return None, None, None

          try:
              debug_dir = Path(f"debug_extract_{Path(img_path).stem}_{os.getpid()}") if debug and isinstance(img_or_path, (str, Path)) else None
              if debug and not debug_dir: debug_dir = Path(f"debug_extract_np_{os.getpid()}")

              # 1. Find Grid Contour
              contour = find_sudoku_grid_contour(img, debug_dir)
              if contour is None:
                  print("[Extractor] Failed to find Sudoku contour.")
                  return None, None, None # Contour finding failed

              # 2. Rectify Grid
              rectified = rectify_grid(img, contour, size=size)
              if rectified is None:
                  print("[Extractor] Failed to rectify grid.")
                  return None, None, contour # Rectification failed, return contour found

              if debug_dir:
                  cv2.imwrite(str(debug_dir / "06_rectified.png"), rectified)

              # 3. Split into Cells
              cells, rectified_output = split_into_cells(rectified)
              if cells is None:
                  print("[Extractor] Failed to split rectified grid into cells.")
                  # Return rectified image even if splitting fails, maybe useful for debugging
                  return None, rectified_output, contour

              if debug_dir:
                  # Save a montage of extracted cells
                  cell_h, cell_w = cells[0].shape[:2]
                  montage = np.zeros((GRID_SIZE * cell_h, GRID_SIZE * cell_w) + cells[0].shape[2:], dtype=cells[0].dtype)
                  for i, cell_img in enumerate(cells):
                      r, c = divmod(i, GRID_SIZE)
                      if cell_img.shape[:2] == (cell_h, cell_w): # Ensure shape consistency
                          montage[r*cell_h:(r+1)*cell_h, c*cell_w:(c+1)*cell_w] = cell_img
                  cv2.imwrite(str(debug_dir / "07_cells_montage.png"), montage)


              # Success
              return cells, rectified_output, contour

          except Exception as e:
              print(f"[Extractor] Unexpected error: {e}")
              import traceback
              traceback.print_exc()
              return None, None, None

      ```
    metadata:
      filename: digit_extractor.py
  - user: |-
      ```python 'sudoku_recogniser.py'
      """
      Command-line utility to detect a Sudoku grid in an image and recognise its digits
      using the full-grid classifier.
      """

      from __future__ import annotations

      import sys
      import time
      from pathlib import Path
      from typing import Tuple, Optional

      import cv2
      import numpy as np

      # Import the updated classifier and extractor
      import digit_classifier
      from digit_extractor import GRID_SIZE, DEFAULT_RECTIFIED_SIZE, extract_cells_from_image

      # Confidence threshold for final acceptance of a recognised digit (1-9)
      # This can be tuned based on model performance.
      FINAL_CONFIDENCE_THRESHOLD = 0.75 # Adjusted slightly


      def print_sudoku_grid(
          grid: np.ndarray,
          conf: Optional[np.ndarray] = None,
          threshold: float = FINAL_CONFIDENCE_THRESHOLD
      ) -> None:
          """
          Nicely print a 9×9 Sudoku grid.
          Marks digits below the threshold with '?' if confidences are provided.
          Expects grid values 0-9, where 0 is empty.
          """
          grid = np.asarray(grid)
          if grid.shape != (GRID_SIZE, GRID_SIZE):
              print(f"[print_sudoku_grid] Invalid grid shape: {grid.shape}")
              return

          print("-" * 25) # Top border
          for r in range(GRID_SIZE):
              if r > 0 and r % 3 == 0:
                  print("|-------+-------+-------|") # Separator line

              line = ["|"] # Start of row
              for c in range(GRID_SIZE):
                  digit = grid[r, c]
                  token = ""
                  if digit == 0:
                      token = "." # Represent empty cell
                  else:
                      token = str(digit)
                      # If confidence is provided and below threshold, mark as uncertain
                      if conf is not None and conf.shape == (GRID_SIZE, GRID_SIZE) and conf[r, c] < threshold:
                          token = "?"

                  line.append(f" {token} ") # Add token with spacing

                  if (c + 1) % 3 == 0:
                      line.append("|") # Add column separator

              print("".join(line)) # Print the row
          print("-" * 25) # Bottom border
          print() # Add a blank line after the grid


      def display_results_on_image(
          rectified: Optional[np.ndarray],
          grid: np.ndarray,
          conf: Optional[np.ndarray] = None,
          threshold: float = FINAL_CONFIDENCE_THRESHOLD
      ) -> Optional[np.ndarray]:
          """
          Draw recognised digits (above threshold) onto the rectified grid image.
          """
          if rectified is None:
              print("[Display] No rectified image provided.")
              return None

          # Ensure image is BGR for drawing colors
          img_display = (
              cv2.cvtColor(rectified, cv2.COLOR_GRAY2BGR)
              if rectified.ndim == 2 else rectified.copy()
          )
          h, w = img_display.shape[:2]
          if h == 0 or w == 0: return None # Invalid image dimensions

          cell_h, cell_w = h // GRID_SIZE, w // GRID_SIZE
          if cell_h == 0 or cell_w == 0: return img_display # Cannot draw if cells are too small

          # Choose font properties
          font_face = cv2.FONT_HERSHEY_SIMPLEX
          font_scale_base = min(cell_h, cell_w) / 35.0 # Scale font based on cell size
          font_thickness = max(1, int(font_scale_base * 1.5))

          for r in range(GRID_SIZE):
              for c in range(GRID_SIZE):
                  digit = grid[r, c]
                  confidence = conf[r, c] if conf is not None else 1.0 # Assume high conf if not provided

                  # Only draw digits that are not empty and meet the confidence threshold
                  if digit != 0 and confidence >= threshold:
                      text = str(digit)

                      # Calculate text size to center it
                      (text_w, text_h), baseline = cv2.getTextSize(text, font_face, font_scale_base, font_thickness)

                      # Calculate center position of the cell
                      center_x = c * cell_w + cell_w // 2
                      center_y = r * cell_h + cell_h // 2

                      # Calculate bottom-left corner of the text for centering
                      text_x = center_x - text_w // 2
                      text_y = center_y + text_h // 2

                      # Draw the text
                      cv2.putText(
                          img_display,
                          text,
                          (text_x, text_y),
                          font_face,
                          font_scale_base,
                          (0, 200, 0), # Green color for recognised digits
                          font_thickness,
                          cv2.LINE_AA # Anti-aliased text
                      )
                  # Optional: Draw uncertain digits differently (e.g., red '?')
                  # elif digit != 0 and conf is not None and confidence < threshold:
                  #     text = "?"
                  #     (text_w, text_h), baseline = cv2.getTextSize(text, font_face, font_scale_base, font_thickness)
                  #     center_x = c * cell_w + cell_w // 2
                  #     center_y = r * cell_h + cell_h // 2
                  #     text_x = center_x - text_w // 2
                  #     text_y = center_y + text_h // 2
                  #     cv2.putText(img_display, text, (text_x, text_y), font_face, font_scale_base, (0, 0, 255), font_thickness, cv2.LINE_AA)


          return img_display


      def recognise_sudoku(
          img_path: Path,
          classifier: digit_classifier.DigitClassifier
      ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
          """
          Extract rectified grid and run the full-grid classifier.

          Returns:
              Tuple of (predicted_grid, confidence_grid, rectified_image).
              predicted_grid: (9, 9) int array, 0 for empty/uncertain.
              confidence_grid: (9, 9) float array of confidences.
              rectified_image: The (e.g., 252x252) rectified image.
              Returns (None, None, None) on failure.
          """
          print(f"Processing {img_path.name}...")
          start_time = time.time()

          # 1. Extract the rectified grid image
          # We don't need individual cells from the extractor anymore
          # Use the input size expected by the classifier model
          rectified_size = classifier._model_input_shape[0]
          _, rectified_img, _ = extract_cells_from_image(
              img_path,
              size=rectified_size,
              debug=False # Set to True for extraction debugging images
          )

          if rectified_img is None:
              print("❌ Failed to extract or rectify the Sudoku grid.")
              return None, None, None
          print(f"✅ Grid extracted and rectified ({time.time() - start_time:.2f}s)")
          extract_time = time.time()

          # 2. Recognise digits using the full-grid classifier
          print("🧠 Running grid recognition model...")
          predicted_grid, confidence_grid = classifier.recognise_grid(
              rectified_img,
              confidence_threshold=FINAL_CONFIDENCE_THRESHOLD
          )

          if predicted_grid is None or confidence_grid is None:
              print("❌ Model recognition failed.")
              return None, None, rectified_img # Return rectified image even if recognition fails

          elapsed_time = time.time() - start_time
          print(f"✅ Recognition complete ({time.time() - extract_time:.2f}s)")
          print(f"⏱️ Total time: {elapsed_time:.2f}s")

          return predicted_grid, confidence_grid, rectified_img


      def main() -> None:
          if len(sys.argv) < 2:
              print("Usage: python sudoku_recogniser.py <image_path> [--no-train]")
              print("  <image_path>: Path to the Sudoku image file.")
              print("  --no-train: Optional flag to prevent training if the model is missing.")
              sys.exit(0)

          img_path = Path(sys.argv[1])
          if not img_path.is_file():
              print(f"❌ Error: Image file not found at '{img_path}'")
              sys.exit(1)

          # Check for --no-train flag
          force_no_train = "--no-train" in sys.argv

          # Instantiate the classifier
          # It will try to load the model. Training is required if the model file
          # doesn't exist, unless --no-train is specified.
          model_exists = Path(digit_classifier.MODEL_FILENAME).exists()
          training_required = not model_exists

          if training_required and force_no_train:
              print("Model file not found, but --no-train specified. Exiting.")
              sys.exit(1)
          elif training_required:
              print(f"⚠️ Model file '{digit_classifier.MODEL_FILENAME}' not found.")
              print("Initiating training process...")
              classifier = digit_classifier.DigitClassifier(training_required=True)
              classifier.train() # Use default training parameters from classifier script
              # Check if model was successfully created after training
              if classifier.model is None:
                   print("❌ Training failed to produce a model. Exiting.")
                   sys.exit(1)
              print("✅ Training complete. Proceeding with recognition...")
          else:
              # Model exists or --no-train was used with existing model
              classifier = digit_classifier.DigitClassifier(training_required=False)
              if classifier.model is None:
                   print(f"❌ Failed to load existing model '{digit_classifier.MODEL_FILENAME}'. Exiting.")
                   sys.exit(1)
              print(f"✅ Model '{digit_classifier.MODEL_FILENAME}' loaded.")


          # Recognise the Sudoku in the input image
          try:
              grid, conf, rectified = recognise_sudoku(img_path, classifier)

              if grid is None or conf is None:
                  print("\n❌ Sudoku recognition process failed.")
                  # Rectified might still exist, show it if possible
                  if rectified is not None:
                       cv2.imshow("Failed Extraction/Rectification", rectified)
                       cv2.waitKey(0)
                  sys.exit(1)

              # Print the recognised grid to the console
              print("\n--- Recognised Sudoku Grid ---")
              print_sudoku_grid(grid, conf, threshold=FINAL_CONFIDENCE_THRESHOLD)

              # Display the rectified image with recognised digits overlaid
              result_img = display_results_on_image(rectified, grid, conf, threshold=FINAL_CONFIDENCE_THRESHOLD)
              if result_img is not None:
                  print("ℹ️ Displaying recognised grid on image. Press any key to close.")
                  cv2.imshow("Sudoku Recognition Result", result_img)
                  cv2.waitKey(0)
              else:
                  print("ℹ️ Could not generate result image.")

          except Exception as e:
              print(f"\n❌ An unexpected error occurred: {e}")
              import traceback
              traceback.print_exc()
              sys.exit(1)
          finally:
              cv2.destroyAllWindows() # Ensure any OpenCV windows are closed


      if __name__ == "__main__":
          main()

      ```
    metadata:
      filename: sudoku_recogniser.py
  - user: |-
      ```python 'sudoku_renderer.py'
      """
      Synthetic Sudoku image generator for on‑the‑fly training data.
      Generates puzzles based on valid, solvable Sudoku grids.
      """

      import random
      import time
      from pathlib import Path
      from typing import Tuple, Optional, List

      import cv2
      import numpy as np
      import keras

      GRID_SIZE = 9
      BASE_IMAGE_SIZE = 1000 # Initial rendering size before warp
      CELL_SIZE = BASE_IMAGE_SIZE // GRID_SIZE
      # Ensure MNIST is loaded only once
      MNIST_BUCKETS: Optional[dict[int, list[np.ndarray]]] = None

      # --- Sudoku Generation Helpers ---

      def _is_safe(grid: np.ndarray, row: int, col: int, num: int) -> bool:
          """Check if it's safe to place 'num' at grid[row, col]."""
          # Check row
          if num in grid[row, :]:
              return False
          # Check column
          if num in grid[:, col]:
              return False
          # Check 3x3 box
          start_row, start_col = 3 * (row // 3), 3 * (col // 3)
          if num in grid[start_row:start_row + 3, start_col:start_col + 3]:
              return False
          return True

      def _find_empty(grid: np.ndarray) -> Optional[Tuple[int, int]]:
          """Find an empty cell (marked with 0)."""
          for r in range(GRID_SIZE):
              for c in range(GRID_SIZE):
                  if grid[r, c] == 0:
                      return (r, c)
          return None

      def _solve_sudoku(grid: np.ndarray) -> bool:
          """Solve the Sudoku grid in-place using backtracking."""
          find = _find_empty(grid)
          if not find:
              return True  # Solved
          else:
              row, col = find

          nums = list(range(1, GRID_SIZE + 1))
          random.shuffle(nums) # Introduce randomness for generation

          for num in nums:
              if _is_safe(grid, row, col, num):
                  grid[row, col] = num
                  if _solve_sudoku(grid):
                      return True
                  grid[row, col] = 0  # Backtrack

          return False

      def _generate_sudoku_solution() -> np.ndarray:
          """Generate a complete, valid Sudoku grid."""
          while True: # Keep trying until a valid solution is found
              grid = np.zeros((GRID_SIZE, GRID_SIZE), dtype=int)
              if _solve_sudoku(grid):
                  return grid
              # print("Failed to generate solution, retrying...") # Optional debug
              time.sleep(0.01) # Avoid busy-waiting if something goes wrong

      def _create_puzzle(solution: np.ndarray, difficulty: float = 0.5) -> np.ndarray:
          """
          Create a puzzle by removing cells from a solution.
          Difficulty: approx. fraction of cells to remove (0.1 easy, 0.5 medium, 0.7 hard).
          Note: This simple removal doesn't guarantee unique solvability, but ensures
                the underlying pattern is valid.
          """
          puzzle = solution.copy()
          num_cells = GRID_SIZE * GRID_SIZE
          num_remove = int(num_cells * difficulty)

          attempts = 0
          removed_count = 0
          while removed_count < num_remove and attempts < num_cells * 2:
              row, col = random.randint(0, GRID_SIZE - 1), random.randint(0, GRID_SIZE - 1)
              if puzzle[row, col] != 0:
                  puzzle[row, col] = 0
                  removed_count += 1
              attempts += 1
          # print(f"Removed {removed_count} cells for difficulty {difficulty}") # Optional debug
          return puzzle

      # --- MNIST Loading ---

      def _load_mnist_digits() -> dict[int, list[np.ndarray]]:
          """
          Download MNIST once and bucket images by label for rendering.
          """
          global MNIST_BUCKETS
          if MNIST_BUCKETS is not None:
              return MNIST_BUCKETS

          print("Loading MNIST dataset for rendering...")
          try:
              (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
              images = np.concatenate([x_train, x_test])
              labels = np.concatenate([y_train, y_test])

              buckets: dict[int, list[np.ndarray]] = {i: [] for i in range(10)}
              for img, lbl in zip(images, labels):
                  # Invert (black digit on white bg) and add padding
                  inv = cv2.bitwise_not(img)
                  padded = cv2.copyMakeBorder(
                      inv, 4, 4, 4, 4,
                      cv2.BORDER_CONSTANT, value=255 # White padding
                  )
                  buckets[int(lbl)].append(padded)
              print("MNIST loaded.")
              MNIST_BUCKETS = buckets
              return MNIST_BUCKETS
          except Exception as e:
              print(f"Error loading MNIST: {e}. Will only use font rendering.")
              MNIST_BUCKETS = {i: [] for i in range(10)} # Empty buckets
              return MNIST_BUCKETS


      # --- Renderer Class ---

      class SudokuRenderer:
          """
          Render a random Sudoku puzzle (based on a valid solution) to a synthetic image.
          """

          def __init__(self) -> None:
              self.mnist_buckets = _load_mnist_digits() # Ensure MNIST is loaded/attempted

          def _digit_source(self, digit: int) -> Tuple[Optional[np.ndarray], str]:
              """Choose between MNIST digit or font rendering."""
              sources = []
              # Only allow MNIST if buckets[digit] is not empty
              if self.mnist_buckets and self.mnist_buckets.get(digit):
                  sources.append("mnist")
              sources.append("font") # Always allow font as fallback
              choice = random.choice(sources)

              if choice == "mnist":
                  img = random.choice(self.mnist_buckets[digit])
                  # Ensure it's BGR for consistency
                  if img.ndim == 2:
                      img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                  return img, "mnist"
              # Fallback to font rendering if MNIST chosen but failed, or if font chosen
              return None, "font"

          def render_sudoku(
              self,
              grid_spec: Optional[np.ndarray] = None,
              *,
              allow_empty: bool = True, # If True, difficulty is random, otherwise uses grid_spec or full solution
              difficulty: float = 0.5 # Used if allow_empty=True and grid_spec=None
          ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
              """
              Generate a synthetic Sudoku image based on a valid grid.

              Args:
                  grid_spec: A specific (9, 9) puzzle grid (0 for empty). If None, generates randomly.
                  allow_empty: If True and grid_spec is None, generate a puzzle with random difficulty.
                               If False and grid_spec is None, render the full solution.
                  difficulty: Target fraction of empty cells if generating randomly (approx).

              Returns:
                  Tuple of (image, ground_truth_puzzle_grid, warped_corners).
                  Returns (None, None, None) on generation failure.
              """
              try:
                  if grid_spec is not None:
                      # Use the provided puzzle spec directly
                      gt_puzzle = grid_spec.copy()
                      # We don't have the full solution here, but the puzzle itself is the ground truth
                  else:
                      # Generate a full solution first
                      solution = _generate_sudoku_solution()
                      if not allow_empty:
                          # Render the full solution
                          gt_puzzle = solution.copy()
                      else:
                          # Create a puzzle by removing digits from the solution
                          rand_difficulty = random.uniform(0.3, 0.7) # Randomize difficulty
                          gt_puzzle = _create_puzzle(solution, difficulty=rand_difficulty)

                  # --- Start Rendering ---
                  bg_color = tuple(random.randint(200, 240) for _ in range(3))
                  img = np.full((BASE_IMAGE_SIZE, BASE_IMAGE_SIZE, 3), bg_color, np.uint8)

                  # Draw grid lines
                  for i in range(GRID_SIZE + 1):
                      major = (i % 3 == 0)
                      thickness = random.randint(3 if major else 1, 5 if major else 3)
                      color = (0, 0, 0) # Black lines
                      # Horizontal lines
                      cv2.line(img, (0, i * CELL_SIZE), (BASE_IMAGE_SIZE, i * CELL_SIZE), color, thickness)
                      # Vertical lines
                      cv2.line(img, (i * CELL_SIZE, 0), (i * CELL_SIZE, BASE_IMAGE_SIZE), color, thickness)

                  # Draw digits onto the grid based on gt_puzzle
                  for r in range(GRID_SIZE):
                      for c in range(GRID_SIZE):
                          digit_to_render = gt_puzzle[r, c]
                          if digit_to_render == 0:
                              continue # Skip empty cells

                          src_img, src_type = self._digit_source(digit_to_render)
                          scale = random.uniform(0.5, 0.8) # Size relative to cell
                          target_size = int(CELL_SIZE * scale)
                          if target_size < 10: continue # Skip if too small

                          # Calculate center position with jitter
                          center_x = c * CELL_SIZE + CELL_SIZE // 2
                          center_y = r * CELL_SIZE + CELL_SIZE // 2
                          dx = int(random.uniform(-0.1, 0.1) * CELL_SIZE)
                          dy = int(random.uniform(-0.1, 0.1) * CELL_SIZE)
                          cx, cy = center_x + dx, center_y + dy

                          if src_type == "mnist" and src_img is not None:
                              # Resize MNIST digit
                              digit_img = cv2.resize(src_img, (target_size, target_size), interpolation=cv2.INTER_AREA)

                              # Random rotation
                              angle = random.uniform(-10, 10)
                              M = cv2.getRotationMatrix2D((target_size / 2, target_size / 2), angle, 1)
                              digit_img = cv2.warpAffine(
                                  digit_img, M, (target_size, target_size),
                                  borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255) # Match padding
                              )

                              # Create mask (assuming black digit on white background from MNIST processing)
                              mask = cv2.cvtColor(digit_img, cv2.COLOR_BGR2GRAY)
                              _, mask = cv2.threshold(mask, 250, 255, cv2.THRESH_BINARY_INV) # Invert to get digit mask

                              # Calculate ROI in the main image
                              x0 = max(0, cx - target_size // 2)
                              y0 = max(0, cy - target_size // 2)
                              x1 = min(img.shape[1], x0 + target_size)
                              y1 = min(img.shape[0], y0 + target_size)
                              roi = img[y0:y1, x0:x1]

                              # Adjust digit image and mask if ROI is smaller (near edges)
                              digit_roi = digit_img[0:roi.shape[0], 0:roi.shape[1]]
                              mask_roi = mask[0:roi.shape[0], 0:roi.shape[1]]
                              mask_inv_roi = cv2.bitwise_not(mask_roi)

                              # Place digit using mask
                              bg_region = cv2.bitwise_and(roi, roi, mask=mask_inv_roi)
                              fg_region = cv2.bitwise_and(digit_roi, digit_roi, mask=mask_roi)
                              img[y0:y1, x0:x1] = cv2.add(bg_region, fg_region)

                          else: # Use font rendering
                              font = cv2.FONT_HERSHEY_SIMPLEX # Or try FONT_HERSHEY_DUPLEX etc.
                              thickness = random.randint(2, 4)
                              # Adjust font scale to fit target size
                              font_scale = cv2.getFontScaleFromHeight(font, target_size, thickness) * 0.8
                              text = str(digit_to_render)
                              (tw, th), _ = cv2.getTextSize(text, font, font_scale, thickness)

                              # Calculate position for font rendering
                              text_x = cx - tw // 2
                              text_y = cy + th // 2
                              cv2.putText(img, text, (text_x, text_y),
                                          font, font_scale, (0, 0, 0), thickness, cv2.LINE_AA)

                  # --- Post-processing ---
                  # Add noise
                  noise_level = random.uniform(5, 15)
                  noise = np.random.normal(0, noise_level, img.shape).astype(np.float32)
                  noisy_img = np.clip(img.astype(np.float32) + noise, 0, 255).astype(np.uint8)

                  # Random perspective warp
                  h, w = noisy_img.shape[:2]
                  orig_corners = np.array([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype="float32")
                  shift_factor = random.uniform(0.02, 0.15) # Reduced max shift slightly
                  max_dx, max_dy = w * shift_factor, h * shift_factor

                  # Generate new corner positions with some randomness
                  warped_corners = np.array([
                      [random.uniform(0, max_dx), random.uniform(0, max_dy)], # Top-left
                      [w - 1 - random.uniform(0, max_dx), random.uniform(0, max_dy)], # Top-right
                      [w - 1 - random.uniform(0, max_dx), h - 1 - random.uniform(0, max_dy)], # Bottom-right
                      [random.uniform(0, max_dx), h - 1 - random.uniform(0, max_dy)], # Bottom-left
                  ], dtype="float32")

                  # Ensure corners maintain roughly the correct order (prevent extreme warps)
                  # Simple check: ensure TL x < TR x, BL x < BR x, TL y < BL y, TR y < BR y
                  if (warped_corners[0,0] >= warped_corners[1,0] or \
                      warped_corners[3,0] >= warped_corners[2,0] or \
                      warped_corners[0,1] >= warped_corners[3,1] or \
                      warped_corners[1,1] >= warped_corners[2,1]):
                       # If order is messed up, use less aggressive warp or skip warp
                       warped_corners = orig_corners # Fallback to no warp this time

                  M = cv2.getPerspectiveTransform(orig_corners, warped_corners)

                  # Calculate output bounds for warped image
                  out_w = int(np.max(warped_corners[:, 0])) + 1
                  out_h = int(np.max(warped_corners[:, 1])) + 1
                  out_w = max(out_w, 100) # Ensure minimum size
                  out_h = max(out_h, 100)

                  warped_img = cv2.warpPerspective(
                      noisy_img, M, (out_w, out_h),
                      flags=cv2.INTER_LINEAR, # Smoother interpolation
                      borderMode=cv2.BORDER_REPLICATE # Replicate border pixels
                  )

                  # Apply slight blur after warping
                  final_img = cv2.GaussianBlur(warped_img, (3, 3), 0)

                  # Return the final image, the puzzle grid (0 for empty), and the warped corners
                  return final_img, gt_puzzle, warped_corners

              except Exception as e:
                  print(f"[Renderer Error] Failed to render Sudoku: {e}")
                  import traceback
                  traceback.print_exc()
                  return None, None, None


      def generate_and_save_test_example(
          prefix: str = "epoch_test_sudoku",
          force: bool = False
      ) -> Tuple[Optional[str], Optional[np.ndarray]]:
          """
          Generate or load a fixed Sudoku test example for epoch callbacks.
          Returns (image_path, ground_truth_puzzle_grid).
          """
          img_path = Path(f"{prefix}.png")
          gt_path = Path(f"{prefix}_gt.npy")

          if not force and img_path.exists() and gt_path.exists():
              try:
                  gt = np.load(gt_path)
                  # Basic check if loaded files are valid
                  if cv2.imread(str(img_path)) is not None and gt.shape == (GRID_SIZE, GRID_SIZE):
                       print(f"Loaded existing test example: {img_path}, {gt_path}")
                       return str(img_path), gt
                  else:
                       print("Existing test example files corrupted, regenerating...")
              except Exception as e:
                  print(f"Error loading existing test example ({e}), regenerating...")

          print("Generating new test example...")
          renderer = SudokuRenderer()
          # Define a specific puzzle grid (0 for empty)
          # This puzzle should ideally be solvable and have a unique solution
          # Example puzzle (source: websudoku.com easy)
          test_puzzle_grid = np.array([
              [0, 0, 3, 0, 2, 0, 6, 0, 0],
              [9, 0, 0, 3, 0, 5, 0, 0, 1],
              [0, 0, 1, 8, 0, 6, 4, 0, 0],
              [0, 0, 8, 1, 0, 2, 9, 0, 0],
              [7, 0, 0, 0, 0, 0, 0, 0, 8],
              [0, 0, 6, 7, 0, 8, 2, 0, 0],
              [0, 0, 2, 6, 0, 9, 5, 0, 0],
              [8, 0, 0, 2, 0, 3, 0, 0, 9],
              [0, 0, 5, 0, 1, 0, 3, 0, 0]
          ], dtype=int)

          # Render this specific puzzle
          img, gt, _ = renderer.render_sudoku(grid_spec=test_puzzle_grid)

          if img is None or gt is None:
              print("[Error] Failed to generate test example image.")
              return None, None

          try:
              cv2.imwrite(str(img_path), img)
              np.save(gt_path, gt)
              print(f"Saved new test example: {img_path}, {gt_path}")
              return str(img_path), gt
          except Exception as e:
              print(f"[Error] Failed to save test example: {e}")
              return None, None

      # Example usage for debugging
      if __name__ == "__main__":
          print("Generating a sample Sudoku image...")
          renderer = SudokuRenderer()
          img, gt, corners = renderer.render_sudoku(allow_empty=True, difficulty=0.6)

          if img is not None:
              print("Generated Ground Truth Puzzle Grid:")
              print(gt)
              cv2.imwrite("sample_sudoku_generated.png", img)
              print("Saved sample image to sample_sudoku_generated.png")

              # Also generate the fixed test example if needed
              generate_and_save_test_example(force=True)
          else:
              print("Failed to generate sample image.")

      ```
    metadata:
      filename: sudoku_renderer.py
  - user: |-
      Okay, let's refactor the system to predict the entire Sudoku grid at once from the rectified image and ensure the generated training puzzles are based on valid, solvable Sudoku grids.

      **Key Changes:**

      1.  **`sudoku_renderer.py`:**
          *   Added helper functions (`_is_safe`, `_find_empty`, `_solve_sudoku`, `_generate_sudoku_solution`) to create valid, complete Sudoku solutions.
          *   Modified `render_sudoku` to:
              *   Generate a full solution using the helpers.
              *   Create a puzzle (the `ground_truth_grid`) by removing digits from the solution based on `allow_empty` or a target number of clues.
              *   Render the *puzzle* grid.
              *   Return the rendered image, the ground truth grid (with 0s for empty cells), and corners.
      2.  **`digit_classifier.py`:**
          *   **Model Input/Output:** Changed `MODEL_INPUT_SHAPE` to accept the whole rectified grid (resized to `(252, 252, 1)` for divisibility). The output shape is now `(9, 9, NUM_CLASSES)`.
          *   **Architecture (`_build_cnn_model`):** Replaced the single-cell CNN with a Fully Convolutional Network (FCN) using ResNet-style blocks, designed to process the larger input and produce a `(9, 9, 11)` output tensor representing the probabilities for each cell. Downsampling is carefully managed.
          *   **Preprocessing:** Removed `_preprocess_cell_for_model`. Added `_preprocess_grid_for_model` to resize and normalize the entire rectified grid image.
          *   **Augmentation:** Removed `_augment_cell*`. Added `_augment_grid` to apply augmentations to the full grid image.
          *   **Data Generator (`sudoku_data_generator`):** Modified to yield batches of `(preprocessed_grid_image, grid_labels)`. The complex balancing logic is removed as each sample is now a full grid. The `gt_grid` returned by the renderer (with 0s) is converted to use `EMPTY_LABEL` (10) for the model's target `y`.
          *   **Inference (`recognise` -> `recognise_grid`):** Takes a rectified grid image, preprocesses it, runs the model once, decodes the `(9, 9, 11)` output using `argmax` and confidence checks, and returns the predicted `(9, 9)` integer grid and the `(9, 9)` confidence grid.
          *   **Training:** Updated to use the new generator, preprocessing, and augmentation. Visualization dump saves input grid images.
          *   **Callbacks (`EpochTestCallback`):** Updated to preprocess the full test grid image and evaluate the model's full grid prediction against the ground truth.
          *   **Sanity Check:** Replaced single-cell checks with a check that processes the standard test image.
      3.  **`digit_extractor.py`:**
          *   Updated `DEFAULT_RECTIFIED_SIZE` to match the new model input size (252).
      4.  **`sudoku_recogniser.py`:**
          *   Modified `recognise_sudoku` to call the new `classifier.recognise_grid` method.
          *   Adjusted `FINAL_CONFIDENCE_THRESHOLD` slightly.

      ```python 'sudoku_renderer.py'
      """
      Synthetic Sudoku image generator for on‑the‑fly training data.
      Generates puzzles based on valid, solvable Sudoku grids.
      """

      import random
      import time
      from pathlib import Path
      from typing import Tuple, Optional, List

      import cv2
      import numpy as np
      import keras

      GRID_SIZE = 9
      BASE_IMAGE_SIZE = 1000 # Initial rendering size before warp
      CELL_SIZE = BASE_IMAGE_SIZE // GRID_SIZE
      # Ensure MNIST is loaded only once
      MNIST_BUCKETS: Optional[dict[int, list[np.ndarray]]] = None

      # --- Sudoku Generation Helpers ---

      def _is_safe(grid: np.ndarray, row: int, col: int, num: int) -> bool:
          """Check if it's safe to place 'num' at grid[row, col]."""
          # Check row
          if num in grid[row, :]:
              return False
          # Check column
          if num in grid[:, col]:
              return False
          # Check 3x3 box
          start_row, start_col = 3 * (row // 3), 3 * (col // 3)
          if num in grid[start_row:start_row + 3, start_col:start_col + 3]:
              return False
          return True

      def _find_empty(grid: np.ndarray) -> Optional[Tuple[int, int]]:
          """Find an empty cell (marked with 0)."""
          for r in range(GRID_SIZE):
              for c in range(GRID_SIZE):
                  if grid[r, c] == 0:
                      return (r, c)
          return None

      def _solve_sudoku(grid: np.ndarray) -> bool:
          """Solve the Sudoku grid in-place using backtracking."""
          find = _find_empty(grid)
          if not find:
              return True  # Solved
          else:
              row, col = find

          nums = list(range(1, GRID_SIZE + 1))
          random.shuffle(nums) # Introduce randomness for generation

          for num in nums:
              if _is_safe(grid, row, col, num):
                  grid[row, col] = num
                  if _solve_sudoku(grid):
                      return True
                  grid[row, col] = 0  # Backtrack

          return False

      def _generate_sudoku_solution() -> np.ndarray:
          """Generate a complete, valid Sudoku grid."""
          while True: # Keep trying until a valid solution is found
              grid = np.zeros((GRID_SIZE, GRID_SIZE), dtype=int)
              if _solve_sudoku(grid):
                  return grid
              # print("Failed to generate solution, retrying...") # Optional debug
              time.sleep(0.01) # Avoid busy-waiting if something goes wrong

      def _create_puzzle(solution: np.ndarray, difficulty: float = 0.5) -> np.ndarray:
          """
          Create a puzzle by removing cells from a solution.
          Difficulty: approx. fraction of cells to remove (0.1 easy, 0.5 medium, 0.7 hard).
          Note: This simple removal doesn't guarantee unique solvability, but ensures
                the underlying pattern is valid.
          """
          puzzle = solution.copy()
          num_cells = GRID_SIZE * GRID_SIZE
          num_remove = int(num_cells * difficulty)

          attempts = 0
          removed_count = 0
          while removed_count < num_remove and attempts < num_cells * 2:
              row, col = random.randint(0, GRID_SIZE - 1), random.randint(0, GRID_SIZE - 1)
              if puzzle[row, col] != 0:
                  puzzle[row, col] = 0
                  removed_count += 1
              attempts += 1
          # print(f"Removed {removed_count} cells for difficulty {difficulty}") # Optional debug
          return puzzle

      # --- MNIST Loading ---

      def _load_mnist_digits() -> dict[int, list[np.ndarray]]:
          """
          Download MNIST once and bucket images by label for rendering.
          """
          global MNIST_BUCKETS
          if MNIST_BUCKETS is not None:
              return MNIST_BUCKETS

          print("Loading MNIST dataset for rendering...")
          try:
              (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
              images = np.concatenate([x_train, x_test])
              labels = np.concatenate([y_train, y_test])

              buckets: dict[int, list[np.ndarray]] = {i: [] for i in range(10)}
              for img, lbl in zip(images, labels):
                  # Invert (black digit on white bg) and add padding
                  inv = cv2.bitwise_not(img)
                  padded = cv2.copyMakeBorder(
                      inv, 4, 4, 4, 4,
                      cv2.BORDER_CONSTANT, value=255 # White padding
                  )
                  buckets[int(lbl)].append(padded)
              print("MNIST loaded.")
              MNIST_BUCKETS = buckets
              return MNIST_BUCKETS
          except Exception as e:
              print(f"Error loading MNIST: {e}. Will only use font rendering.")
              MNIST_BUCKETS = {i: [] for i in range(10)} # Empty buckets
              return MNIST_BUCKETS


      # --- Renderer Class ---

      class SudokuRenderer:
          """
          Render a random Sudoku puzzle (based on a valid solution) to a synthetic image.
          """

          def __init__(self) -> None:
              self.mnist_buckets = _load_mnist_digits() # Ensure MNIST is loaded/attempted

          def _digit_source(self, digit: int) -> Tuple[Optional[np.ndarray], str]:
              """Choose between MNIST digit or font rendering."""
              sources = []
              # Only allow MNIST if buckets[digit] is not empty
              if self.mnist_buckets and self.mnist_buckets.get(digit):
                  sources.append("mnist")
              sources.append("font") # Always allow font as fallback
              choice = random.choice(sources)

              if choice == "mnist":
                  img = random.choice(self.mnist_buckets[digit])
                  # Ensure it's BGR for consistency
                  if img.ndim == 2:
                      img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                  return img, "mnist"
              # Fallback to font rendering if MNIST chosen but failed, or if font chosen
              return None, "font"

          def render_sudoku(
              self,
              grid_spec: Optional[np.ndarray] = None,
              *,
              allow_empty: bool = True, # If True, difficulty is random, otherwise uses grid_spec or full solution
              difficulty: float = 0.5 # Used if allow_empty=True and grid_spec=None
          ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
              """
              Generate a synthetic Sudoku image based on a valid grid.

              Args:
                  grid_spec: A specific (9, 9) puzzle grid (0 for empty). If None, generates randomly.
                  allow_empty: If True and grid_spec is None, generate a puzzle with random difficulty.
                               If False and grid_spec is None, render the full solution.
                  difficulty: Target fraction of empty cells if generating randomly (approx).

              Returns:
                  Tuple of (image, ground_truth_puzzle_grid, warped_corners).
                  Returns (None, None, None) on generation failure.
              """
              try:
                  if grid_spec is not None:
                      # Use the provided puzzle spec directly
                      gt_puzzle = grid_spec.copy()
                      # We don't have the full solution here, but the puzzle itself is the ground truth
                  else:
                      # Generate a full solution first
                      solution = _generate_sudoku_solution()
                      if not allow_empty:
                          # Render the full solution
                          gt_puzzle = solution.copy()
                      else:
                          # Create a puzzle by removing digits from the solution
                          rand_difficulty = random.uniform(0.3, 0.7) # Randomize difficulty
                          gt_puzzle = _create_puzzle(solution, difficulty=rand_difficulty)

                  # --- Start Rendering ---
                  bg_color = tuple(random.randint(200, 240) for _ in range(3))
                  img = np.full((BASE_IMAGE_SIZE, BASE_IMAGE_SIZE, 3), bg_color, np.uint8)

                  # Draw grid lines
                  for i in range(GRID_SIZE + 1):
                      major = (i % 3 == 0)
                      thickness = random.randint(3 if major else 1, 5 if major else 3)
                      color = (0, 0, 0) # Black lines
                      # Horizontal lines
                      cv2.line(img, (0, i * CELL_SIZE), (BASE_IMAGE_SIZE, i * CELL_SIZE), color, thickness)
                      # Vertical lines
                      cv2.line(img, (i * CELL_SIZE, 0), (i * CELL_SIZE, BASE_IMAGE_SIZE), color, thickness)

                  # Draw digits onto the grid based on gt_puzzle
                  for r in range(GRID_SIZE):
                      for c in range(GRID_SIZE):
                          digit_to_render = gt_puzzle[r, c]
                          if digit_to_render == 0:
                              continue # Skip empty cells

                          src_img, src_type = self._digit_source(digit_to_render)
                          scale = random.uniform(0.5, 0.8) # Size relative to cell
                          target_size = int(CELL_SIZE * scale)
                          if target_size < 10: continue # Skip if too small

                          # Calculate center position with jitter
                          center_x = c * CELL_SIZE + CELL_SIZE // 2
                          center_y = r * CELL_SIZE + CELL_SIZE // 2
                          dx = int(random.uniform(-0.1, 0.1) * CELL_SIZE)
                          dy = int(random.uniform(-0.1, 0.1) * CELL_SIZE)
                          cx, cy = center_x + dx, center_y + dy

                          if src_type == "mnist" and src_img is not None:
                              # Resize MNIST digit
                              digit_img = cv2.resize(src_img, (target_size, target_size), interpolation=cv2.INTER_AREA)

                              # Random rotation
                              angle = random.uniform(-10, 10)
                              M = cv2.getRotationMatrix2D((target_size / 2, target_size / 2), angle, 1)
                              digit_img = cv2.warpAffine(
                                  digit_img, M, (target_size, target_size),
                                  borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255) # Match padding
                              )

                              # Create mask (assuming black digit on white background from MNIST processing)
                              mask = cv2.cvtColor(digit_img, cv2.COLOR_BGR2GRAY)
                              _, mask = cv2.threshold(mask, 250, 255, cv2.THRESH_BINARY_INV) # Invert to get digit mask

                              # Calculate ROI in the main image
                              x0 = max(0, cx - target_size // 2)
                              y0 = max(0, cy - target_size // 2)
                              x1 = min(img.shape[1], x0 + target_size)
                              y1 = min(img.shape[0], y0 + target_size)
                              roi = img[y0:y1, x0:x1]

                              # Adjust digit image and mask if ROI is smaller (near edges)
                              digit_roi = digit_img[0:roi.shape[0], 0:roi.shape[1]]
                              mask_roi = mask[0:roi.shape[0], 0:roi.shape[1]]
                              mask_inv_roi = cv2.bitwise_not(mask_roi)

                              # Place digit using mask
                              bg_region = cv2.bitwise_and(roi, roi, mask=mask_inv_roi)
                              fg_region = cv2.bitwise_and(digit_roi, digit_roi, mask=mask_roi)
                              img[y0:y1, x0:x1] = cv2.add(bg_region, fg_region)

                          else: # Use font rendering
                              font = cv2.FONT_HERSHEY_SIMPLEX # Or try FONT_HERSHEY_DUPLEX etc.
                              thickness = random.randint(2, 4)
                              # Adjust font scale to fit target size
                              font_scale = cv2.getFontScaleFromHeight(font, target_size, thickness) * 0.8
                              text = str(digit_to_render)
                              (tw, th), _ = cv2.getTextSize(text, font, font_scale, thickness)

                              # Calculate position for font rendering
                              text_x = cx - tw // 2
                              text_y = cy + th // 2
                              cv2.putText(img, text, (text_x, text_y),
                                          font, font_scale, (0, 0, 0), thickness, cv2.LINE_AA)

                  # --- Post-processing ---
                  # Add noise
                  noise_level = random.uniform(5, 15)
                  noise = np.random.normal(0, noise_level, img.shape).astype(np.float32)
                  noisy_img = np.clip(img.astype(np.float32) + noise, 0, 255).astype(np.uint8)

                  # Random perspective warp
                  h, w = noisy_img.shape[:2]
                  orig_corners = np.array([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype="float32")
                  shift_factor = random.uniform(0.02, 0.15) # Reduced max shift slightly
                  max_dx, max_dy = w * shift_factor, h * shift_factor

                  # Generate new corner positions with some randomness
                  warped_corners = np.array([
                      [random.uniform(0, max_dx), random.uniform(0, max_dy)], # Top-left
                      [w - 1 - random.uniform(0, max_dx), random.uniform(0, max_dy)], # Top-right
                      [w - 1 - random.uniform(0, max_dx), h - 1 - random.uniform(0, max_dy)], # Bottom-right
                      [random.uniform(0, max_dx), h - 1 - random.uniform(0, max_dy)], # Bottom-left
                  ], dtype="float32")

                  # Ensure corners maintain roughly the correct order (prevent extreme warps)
                  # Simple check: ensure TL x < TR x, BL x < BR x, TL y < BL y, TR y < BR y
                  if (warped_corners[0,0] >= warped_corners[1,0] or \
                      warped_corners[3,0] >= warped_corners[2,0] or \
                      warped_corners[0,1] >= warped_corners[3,1] or \
                      warped_corners[1,1] >= warped_corners[2,1]):
                       # If order is messed up, use less aggressive warp or skip warp
                       warped_corners = orig_corners # Fallback to no warp this time

                  M = cv2.getPerspectiveTransform(orig_corners, warped_corners)

                  # Calculate output bounds for warped image
                  out_w = int(np.max(warped_corners[:, 0])) + 1
                  out_h = int(np.max(warped_corners[:, 1])) + 1
                  out_w = max(out_w, 100) # Ensure minimum size
                  out_h = max(out_h, 100)

                  warped_img = cv2.warpPerspective(
                      noisy_img, M, (out_w, out_h),
                      flags=cv2.INTER_LINEAR, # Smoother interpolation
                      borderMode=cv2.BORDER_REPLICATE # Replicate border pixels
                  )

                  # Apply slight blur after warping
                  final_img = cv2.GaussianBlur(warped_img, (3, 3), 0)

                  # Return the final image, the puzzle grid (0 for empty), and the warped corners
                  return final_img, gt_puzzle, warped_corners

              except Exception as e:
                  print(f"[Renderer Error] Failed to render Sudoku: {e}")
                  import traceback
                  traceback.print_exc()
                  return None, None, None


      def generate_and_save_test_example(
          prefix: str = "epoch_test_sudoku",
          force: bool = False
      ) -> Tuple[Optional[str], Optional[np.ndarray]]:
          """
          Generate or load a fixed Sudoku test example for epoch callbacks.
          Returns (image_path, ground_truth_puzzle_grid).
          """
          img_path = Path(f"{prefix}.png")
          gt_path = Path(f"{prefix}_gt.npy")

          if not force and img_path.exists() and gt_path.exists():
              try:
                  gt = np.load(gt_path)
                  # Basic check if loaded files are valid
                  if cv2.imread(str(img_path)) is not None and gt.shape == (GRID_SIZE, GRID_SIZE):
                       print(f"Loaded existing test example: {img_path}, {gt_path}")
                       return str(img_path), gt
                  else:
                       print("Existing test example files corrupted, regenerating...")
              except Exception as e:
                  print(f"Error loading existing test example ({e}), regenerating...")

          print("Generating new test example...")
          renderer = SudokuRenderer()
          # Define a specific puzzle grid (0 for empty)
          # This puzzle should ideally be solvable and have a unique solution
          # Example puzzle (source: websudoku.com easy)
          test_puzzle_grid = np.array([
              [0, 0, 3, 0, 2, 0, 6, 0, 0],
              [9, 0, 0, 3, 0, 5, 0, 0, 1],
              [0, 0, 1, 8, 0, 6, 4, 0, 0],
              [0, 0, 8, 1, 0, 2, 9, 0, 0],
              [7, 0, 0, 0, 0, 0, 0, 0, 8],
              [0, 0, 6, 7, 0, 8, 2, 0, 0],
              [0, 0, 2, 6, 0, 9, 5, 0, 0],
              [8, 0, 0, 2, 0, 3, 0, 0, 9],
              [0, 0, 5, 0, 1, 0, 3, 0, 0]
          ], dtype=int)

          # Render this specific puzzle
          img, gt, _ = renderer.render_sudoku(grid_spec=test_puzzle_grid)

          if img is None or gt is None:
              print("[Error] Failed to generate test example image.")
              return None, None

          try:
              cv2.imwrite(str(img_path), img)
              np.save(gt_path, gt)
              print(f"Saved new test example: {img_path}, {gt_path}")
              return str(img_path), gt
          except Exception as e:
              print(f"[Error] Failed to save test example: {e}")
              return None, None

      # Example usage for debugging
      if __name__ == "__main__":
          print("Generating a sample Sudoku image...")
          renderer = SudokuRenderer()
          img, gt, corners = renderer.render_sudoku(allow_empty=True, difficulty=0.6)

          if img is not None:
              print("Generated Ground Truth Puzzle Grid:")
              print(gt)
              cv2.imwrite("sample_sudoku_generated.png", img)
              print("Saved sample image to sample_sudoku_generated.png")

              # Also generate the fixed test example if needed
              generate_and_save_test_example(force=True)
          else:
              print("Failed to generate sample image.")
      ```

      ```python 'digit_extractor.py'
      """
      Find and extract Sudoku grid cells from an image.
      """

      import os
      from pathlib import Path
      from typing import List, Tuple, Optional

      import cv2
      import numpy as np

      GRID_SIZE = 9
      # Changed default size to be divisible by common CNN strides (e.g., 2^3=8 or 3^3=27)
      # 252 = 9 * 28 -> divisible by 2, 3, 4, 6, 7, 9, 12, 14, 18, 21, 28...
      DEFAULT_RECTIFIED_SIZE = 252


      def _order_points(pts: np.ndarray) -> np.ndarray:
          """Order four points as top-left, top-right, bottom-right, bottom-left."""
          pts = pts.reshape(4, 2).astype("float32")
          rect = np.zeros((4, 2), dtype="float32")
          s = pts.sum(axis=1)
          rect[0] = pts[np.argmin(s)] # Top-left has smallest sum
          rect[2] = pts[np.argmax(s)] # Bottom-right has largest sum
          diff = np.diff(pts, axis=1) # diff = y - x
          rect[1] = pts[np.argmin(diff)] # Top-right has smallest diff
          rect[3] = pts[np.argmax(diff)] # Bottom-left has largest diff
          return rect


      def find_sudoku_grid_contour(
          img: np.ndarray,
          debug_dir: Optional[Path] = None
      ) -> Optional[np.ndarray]:
          """
          Find the largest 4-point contour approximating the Sudoku grid boundary.
          Returns the contour points (4, 2) or None if not found.
          """
          if img is None or img.size == 0:
              print("[Contour Finder] Invalid input image.")
              return None

          gray = (
              cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
              if img.ndim == 3 and img.shape[2] == 3 else img.copy()
          )
          if gray.ndim == 3: # Handle case like RGBA input
              gray = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)

          if debug_dir:
              debug_dir.mkdir(parents=True, exist_ok=True)
              cv2.imwrite(str(debug_dir / "00_gray.png"), gray)

          # Preprocessing: Blur and Threshold
          # GaussianBlur helps reduce noise before thresholding
          blur = cv2.GaussianBlur(gray, (7, 7), 0)
          if debug_dir: cv2.imwrite(str(debug_dir / "01_blur.png"), blur)

          # Adaptive thresholding is generally robust to lighting changes
          thresh = cv2.adaptiveThreshold(
              blur, 255,
              cv2.ADAPTIVE_THRESH_GAUSSIAN_C, # Method
              cv2.THRESH_BINARY_INV,         # Threshold type (invert to get black lines on white)
              15,                            # Block size (must be odd) - adjust based on image size/line thickness
              4                              # Constant C subtracted from mean
          )
          if debug_dir: cv2.imwrite(str(debug_dir / "02_thresh.png"), thresh)

          # Morphological closing to connect broken lines
          kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
          closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)
          if debug_dir: cv2.imwrite(str(debug_dir / "03_closed.png"), closed)

          # Find contours
          contours, _ = cv2.findContours(
              closed,
              cv2.RETR_EXTERNAL,        # Retrieve only outer contours
              cv2.CHAIN_APPROX_SIMPLE   # Compress horizontal/vertical segments
          )

          if not contours:
              print("[Contour Finder] No contours found.")
              return None

          # Sort contours by area (descending) and filter small ones
          contours = sorted(contours, key=cv2.contourArea, reverse=True)
          min_area = gray.size * 0.05 # Require contour to be at least 5% of image area

          if debug_dir:
              img_contours = img.copy() if img.ndim == 3 else cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
              cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 1) # Draw all contours found
              cv2.imwrite(str(debug_dir / "04_all_contours.png"), img_contours)


          # Find the largest quadrilateral contour that resembles a square
          for i, cnt in enumerate(contours):
              area = cv2.contourArea(cnt)
              if area < min_area:
                  # print(f"[Contour Finder] Remaining contours too small (area {area} < {min_area}).")
                  break # No need to check smaller contours

              peri = cv2.arcLength(cnt, True)
              # Approximate the contour shape to a polygon
              approx = cv2.approxPolyDP(cnt, 0.02 * peri, True) # Epsilon factor determines accuracy

              # Check if the approximation has 4 vertices and is convex
              if len(approx) == 4 and cv2.isContourConvex(approx):
                  # Check aspect ratio of the bounding box
                  x, y, w, h = cv2.boundingRect(approx)
                  aspect_ratio = w / float(h) if h > 0 else 0

                  # Allow some tolerance for perspective distortion
                  if 0.7 < aspect_ratio < 1.3:
                      if debug_dir:
                          img_found = img.copy() if img.ndim == 3 else cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
                          cv2.drawContours(img_found, [approx], -1, (0, 0, 255), 3)
                          cv2.imwrite(str(debug_dir / f"05_found_contour_{i}.png"), img_found)
                      # print(f"[Contour Finder] Found potential grid contour (index {i}, area {area:.0f}, aspect {aspect_ratio:.2f}).")
                      return approx.reshape(4, 2).astype("float32") # Return the corner points

          print("[Contour Finder] No suitable Sudoku grid contour found.")
          return None


      def rectify_grid(
          img: np.ndarray,
          contour: np.ndarray,
          size: int = DEFAULT_RECTIFIED_SIZE
      ) -> Optional[np.ndarray]:
          """Perspective-correct the Sudoku grid to a square of given size."""
          if contour is None or contour.shape != (4, 2):
              print("[Rectifier] Invalid contour provided.")
              return None
          if img is None or img.size == 0:
              print("[Rectifier] Invalid image provided.")
              return None

          try:
              # Order the contour points: TL, TR, BR, BL
              src_pts = _order_points(contour)

              # Define the destination points for the square image
              dst_pts = np.array([
                  [0, 0],             # Top-left
                  [size - 1, 0],      # Top-right
                  [size - 1, size - 1], # Bottom-right
                  [0, size - 1],      # Bottom-left
              ], dtype="float32")

              # Calculate the perspective transform matrix
              matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)

              # Apply the perspective warp
              warped = cv2.warpPerspective(img, matrix, (size, size))
              return warped
          except Exception as e:
              print(f"[Rectifier] Error during perspective warp: {e}")
              return None


      def split_into_cells(
          rectified: np.ndarray
      ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray]]:
          """
          Split the rectified grid into GRID_SIZE × GRID_SIZE cell images.
          Applies a small margin removal.
          Returns (cells, rectified_image) or (None, None) on failure.
          """
          if rectified is None or rectified.shape[0] != rectified.shape[1]:
              print("[Splitter] Invalid rectified image provided.")
              return None, None

          h, w = rectified.shape[:2]
          if h == 0 or w == 0:
              print("[Splitter] Rectified image has zero dimension.")
              return None, None

          cell_sz_h = h // GRID_SIZE
          cell_sz_w = w // GRID_SIZE
          if cell_sz_h == 0 or cell_sz_w == 0:
              print("[Splitter] Calculated cell size is zero.")
              return None, None

          # Calculate margin to remove grid lines (e.g., 4% of cell size)
          margin_y = max(1, int(cell_sz_h * 0.04))
          margin_x = max(1, int(cell_sz_w * 0.04))

          cells: List[np.ndarray] = []
          for row in range(GRID_SIZE):
              for col in range(GRID_SIZE):
                  # Calculate cell boundaries with margin
                  y0 = row * cell_sz_h + margin_y
                  x0 = col * cell_sz_w + margin_x
                  y1 = (row + 1) * cell_sz_h - margin_y
                  x1 = (col + 1) * cell_sz_w - margin_x

                  # Ensure coordinates are valid and extract cell
                  if y0 < y1 and x0 < x1:
                      cell = rectified[y0:y1, x0:x1]
                      cells.append(cell)
                  else:
                      # Handle cases where margin is too large for cell size (should be rare)
                      # Fallback: extract cell without margin
                      y0_nomargin = row * cell_sz_h
                      x0_nomargin = col * cell_sz_w
                      y1_nomargin = (row + 1) * cell_sz_h
                      x1_nomargin = (col + 1) * cell_sz_w
                      cell = rectified[y0_nomargin:y1_nomargin, x0_nomargin:x1_nomargin]
                      # Add a blank cell if even no-margin extraction fails
                      if cell is None or cell.size == 0:
                           cell_shape = (cell_sz_h, cell_sz_w) + rectified.shape[2:] if rectified.ndim > 2 else (cell_sz_h, cell_sz_w)
                           cell = np.zeros(cell_shape, rectified.dtype) # Create blank cell
                      cells.append(cell)


          if len(cells) != GRID_SIZE * GRID_SIZE:
              print(f"[Splitter] Incorrect number of cells extracted: {len(cells)}")
              return None, rectified # Return None for cells but keep rectified image

          return cells, rectified


      def extract_cells_from_image(
          img_or_path,
          size: int = DEFAULT_RECTIFIED_SIZE,
          debug: bool = False
      ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray], Optional[np.ndarray]]:
          """
          High-level function: read image, find grid, rectify, and split into cells.
          Returns (cells, rectified_image, contour) or (None, None, None) on failure.
          """
          if isinstance(img_or_path, (str, Path)):
              img_path = str(img_or_path)
              if not Path(img_path).exists():
                  print(f"[Extractor] Image file not found: {img_path}")
                  return None, None, None
              img = cv2.imread(img_path)
              if img is None:
                  print(f"[Extractor] Failed to read image: {img_path}")
                  return None, None, None
          elif isinstance(img_or_path, np.ndarray):
              img = img_or_path.copy()
          else:
              print("[Extractor] Invalid input type (must be path or numpy array).")
              return None, None, None

          if img.size == 0:
              print("[Extractor] Input image is empty.")
              return None, None, None

          try:
              debug_dir = Path(f"debug_extract_{Path(img_path).stem}_{os.getpid()}") if debug and isinstance(img_or_path, (str, Path)) else None
              if debug and not debug_dir: debug_dir = Path(f"debug_extract_np_{os.getpid()}")

              # 1. Find Grid Contour
              contour = find_sudoku_grid_contour(img, debug_dir)
              if contour is None:
                  print("[Extractor] Failed to find Sudoku contour.")
                  return None, None, None # Contour finding failed

              # 2. Rectify Grid
              rectified = rectify_grid(img, contour, size=size)
              if rectified is None:
                  print("[Extractor] Failed to rectify grid.")
                  return None, None, contour # Rectification failed, return contour found

              if debug_dir:
                  cv2.imwrite(str(debug_dir / "06_rectified.png"), rectified)

              # 3. Split into Cells
              cells, rectified_output = split_into_cells(rectified)
              if cells is None:
                  print("[Extractor] Failed to split rectified grid into cells.")
                  # Return rectified image even if splitting fails, maybe useful for debugging
                  return None, rectified_output, contour

              if debug_dir:
                  # Save a montage of extracted cells
                  cell_h, cell_w = cells[0].shape[:2]
                  montage = np.zeros((GRID_SIZE * cell_h, GRID_SIZE * cell_w) + cells[0].shape[2:], dtype=cells[0].dtype)
                  for i, cell_img in enumerate(cells):
                      r, c = divmod(i, GRID_SIZE)
                      if cell_img.shape[:2] == (cell_h, cell_w): # Ensure shape consistency
                          montage[r*cell_h:(r+1)*cell_h, c*cell_w:(c+1)*cell_w] = cell_img
                  cv2.imwrite(str(debug_dir / "07_cells_montage.png"), montage)


              # Success
              return cells, rectified_output, contour

          except Exception as e:
              print(f"[Extractor] Unexpected error: {e}")
              import traceback
              traceback.print_exc()
              return None, None, None
      ```

      ```python 'digit_classifier.py'
      """
      SudokuBot – Digit Classifier (Full Grid Prediction)
      Version 2025-04-22

      Major Changes:
      - Model predicts all 81 cells from the rectified grid image at once.
      - Uses a Fully Convolutional Network (FCN) based on ResNet blocks.
      - Data generator yields full grid images and corresponding label grids.
      - Training data uses puzzles derived from valid, solvable Sudoku solutions.
      - Preprocessing and augmentation apply to the full grid image.
      """

      # ------------------------------------------------------------------ #
      # 1.  choose backend BEFORE importing keras
      # ------------------------------------------------------------------ #
      import os
      os.environ["KERAS_BACKEND"] = "torch"  # must be first – do NOT move

      # ------------------------------------------------------------------ #
      # 2.  std‑lib & 3rd‑party imports
      # ------------------------------------------------------------------ #
      import gc
      import random
      from pathlib import Path
      from typing import Callable, Generator, Optional, Tuple

      import cv2
      import numpy as np
      import torch
      import keras
      from keras import callbacks, layers, models, activations, regularizers

      # ------------------------------------------------------------------ #
      # 3.  project‑local imports
      # ------------------------------------------------------------------ #
      try:
          # Use the updated renderer and extractor
          from sudoku_renderer import SudokuRenderer, generate_and_save_test_example
          from digit_extractor import (
              GRID_SIZE,
              DEFAULT_RECTIFIED_SIZE, # Use the size defined in extractor
              extract_cells_from_image,
              rectify_grid,
              # split_into_cells is not directly needed by the classifier anymore
          )
          import sudoku_recogniser # Needed for printing grids in callback
      except ImportError as e:
          print(f"Error importing local modules: {e}")
          print("Please ensure sudoku_renderer.py, digit_extractor.py, and sudoku_recogniser.py are available.")
          # Provide dummy implementations or raise error if essential
          GRID_SIZE = 9
          DEFAULT_RECTIFIED_SIZE = 252
          class SudokuRenderer:
              def render_sudoku(self, allow_empty=True, grid_spec=None): return None, None, None
          def generate_and_save_test_example(force=False): return Path("dummy_test.png"), np.zeros((9,9), dtype=int)
          def extract_cells_from_image(path, size=252, debug=False): return [], np.zeros((size,size), dtype=np.uint8), None
          class sudoku_recogniser:
              FINAL_CONFIDENCE_THRESHOLD = 0.8
              @staticmethod
              def print_sudoku_grid(grid, confs=None, threshold=0.0): pass


      # ------------------------------------------------------------------ #
      # 4.  constants
      # ------------------------------------------------------------------ #
      MODEL_FILENAME = "sudoku_full_grid_classifier_fcn.keras" # New filename for the new model type
      # Input shape based on the rectified grid size from digit_extractor
      MODEL_INPUT_SHAPE = (DEFAULT_RECTIFIED_SIZE, DEFAULT_RECTIFIED_SIZE, 1) # Grayscale input
      NUM_CLASSES = 11  # digits 0-9 + "empty"
      EMPTY_LABEL = 10  # Label used for empty cells in the target data (y)

      # Training parameters
      EPOCHS = 25 # Might need more epochs for a larger model/task
      STEPS_PER_EPOCH = 100 # Adjust based on data generation speed and dataset size
      BATCH_SIZE = 16 # Reduced batch size due to larger input images
      VALIDATION_STEPS = 30

      # Type alias for data batches
      DataBatch = Tuple[np.ndarray, np.ndarray] # (batch_of_grids, batch_of_labels)

      # ------------------------------------------------------------------ #
      # 5.  data generator (simplified for full grids)
      # ------------------------------------------------------------------ #
      def sudoku_data_generator(
          renderer: SudokuRenderer,
          batch_size: int,
          preprocess_func: Callable[[np.ndarray], Optional[np.ndarray]],
          augment_func: Optional[Callable[[np.ndarray], np.ndarray]], # Optional augmentation
          input_shape: Tuple[int, int, int], # e.g., (252, 252, 1)
      ) -> Generator[DataBatch, None, None]:
          """
          Yields batches of (preprocessed_grid_image, target_label_grid).
          Generates valid Sudoku puzzles on the fly.
          """
          target_h, target_w, target_c = input_shape
          is_grayscale = (target_c == 1)

          batch_counter = 0
          while True:
              batch_x = np.zeros((batch_size, target_h, target_w, target_c), dtype="float32")
              batch_y = np.zeros((batch_size, GRID_SIZE, GRID_SIZE), dtype="int64")
              
              items_in_batch = 0
              while items_in_batch < batch_size:
                  # Generate a rendered Sudoku image and its ground truth puzzle grid (0 for empty)
                  img, gt_puzzle_grid, corners = renderer.render_sudoku(allow_empty=True) # Let renderer handle difficulty

                  if img is None or gt_puzzle_grid is None or corners is None:
                      # print("[Generator] Renderer failed, skipping.")
                      time.sleep(0.1) # Avoid busy-looping if renderer fails consistently
                      continue

                  # Rectify the grid using the known corners
                  # Use the target input size for rectification directly
                  rectified = rectify_grid(img, corners, size=target_h) # Assuming target_h == target_w
                  if rectified is None:
                      # print("[Generator] Rectification failed, skipping.")
                      continue

                  # Preprocess the entire rectified grid image
                  processed_grid = preprocess_func(rectified)
                  if processed_grid is None:
                      # print("[Generator] Preprocessing failed, skipping.")
                      continue

                  # Apply augmentation if provided (usually only for training)
                  if augment_func:
                      processed_grid = augment_func(processed_grid)

                  # Ensure the processed grid has the correct shape (H, W, C)
                  if processed_grid.shape != (target_h, target_w, target_c):
                       print(f"[Generator Warning] Processed grid shape mismatch: expected {(target_h, target_w, target_c)}, got {processed_grid.shape}. Skipping.")
                       continue


                  # Convert the ground truth puzzle grid (0 for empty) to the target format
                  # where empty cells are represented by EMPTY_LABEL (10)
                  target_labels = gt_puzzle_grid.copy()
                  target_labels[target_labels == 0] = EMPTY_LABEL

                  # Add to batch
                  batch_x[items_in_batch] = processed_grid
                  batch_y[items_in_batch] = target_labels
                  items_in_batch += 1

              # Yield the complete batch
              batch_counter += 1
              # Optional debug print
              # if batch_counter % 10 == 0:
              #     print(f"[Generator] Yielding batch {batch_counter}. Example label counts: {np.bincount(batch_y[0].flatten(), minlength=NUM_CLASSES)}")

              yield batch_x, batch_y
              # No need for explicit gc.collect() here usually, Python handles it.


      # ------------------------------------------------------------------ #
      # 6.  classifier object (handles full grid model)
      # ------------------------------------------------------------------ #
      class DigitClassifier:
          """
          Handles loading, training and inference of the FCN Sudoku grid classifier.
          """

          # -------------------------------------------------------------- #
          # constructor
          # -------------------------------------------------------------- #
          def __init__(
              self,
              model_path: Optional[str | Path] = None,
              training_required: bool = False,
          ) -> None:
              self.model_path = Path(model_path) if model_path else Path(MODEL_FILENAME)
              self.model: Optional[keras.Model] = None
              self._model_input_shape = MODEL_INPUT_SHAPE # e.g., (252, 252, 1)

              if not training_required and self.model_path.exists():
                  print(f"Attempting to load model from {self.model_path}...")
                  try:
                      self.model = keras.models.load_model(self.model_path)
                      # Check if loaded model's input shape matches config
                      # Keras models sometimes store input shape as (None, H, W, C)
                      loaded_shape = self.model.input_shape[1:]
                      if loaded_shape != self._model_input_shape:
                          print(f"[Warning] Loaded model input shape {loaded_shape} "
                                f"differs from expected {self._model_input_shape}. Mismatch may cause errors.")
                      print(f"Full-grid classifier model loaded successfully.")
                  except Exception as e:
                      print(f"[Error] Failed to load model from {self.model_path}: {e}")
                      print("Will build and train a new model if training is enabled.")
                      self.model = None # Ensure model is None if loading failed

              # Handle training_required flag
              if training_required and self.model is not None:
                   print("Training required: Ignoring previously loaded model and building a new one.")
                   self.model = None
              elif training_required and self.model is None:
                   print("Training required: Model will be built.")
              elif not training_required and self.model is None:
                   print("Model not found or failed to load, and training not required. Classifier is inactive.")


          # -------------------------------------------------------------- #
          # ResNet-style building block (same as before)
          # -------------------------------------------------------------- #
          def _residual_block(self, x, filters, strides=1, activation="relu"):
              """Basic residual block."""
              shortcut = x
              # Downsample shortcut if needed
              if strides > 1 or shortcut.shape[-1] != filters:
                  shortcut = layers.Conv2D(
                      filters, 1, strides=strides, use_bias=False, kernel_initializer="he_normal",
                      kernel_regularizer=regularizers.l2(1e-5) # Added slight L2 regularization
                  )(shortcut)
                  shortcut = layers.BatchNormalization()(shortcut)

              # First convolution
              y = layers.Conv2D(
                  filters, 3, strides=strides, padding="same", use_bias=False, kernel_initializer="he_normal",
                  kernel_regularizer=regularizers.l2(1e-5)
              )(x)
              y = layers.BatchNormalization()(y)
              y = layers.Activation(activation)(y)

              # Second convolution
              y = layers.Conv2D(
                  filters, 3, padding="same", use_bias=False, kernel_initializer="he_normal",
                  kernel_regularizer=regularizers.l2(1e-5)
              )(y)
              y = layers.BatchNormalization()(y)

              # Add shortcut
              y = layers.Add()([shortcut, y])
              y = layers.Activation(activation)(y)
              return y

          # -------------------------------------------------------------- #
          # backbone (FCN for full grid prediction)
          # -------------------------------------------------------------- #
          def _build_cnn_model(self) -> keras.Model:
              """Builds a Fully Convolutional Network (FCN) for grid prediction."""
              activation_func = "relu" # Or 'gelu'

              x_in = keras.Input(shape=self._model_input_shape) # e.g., (252, 252, 1)

              # --- Encoder Path (Downsampling) ---
              # Initial Conv Layer (Stem)
              # Use stride 3 to quickly reduce dimensions: 252 -> 84
              filters = 32
              x = layers.Conv2D(filters, 7, strides=3, padding="same", use_bias=False, kernel_initializer="he_normal")(x_in)
              x = layers.BatchNormalization()(x)
              x = layers.Activation(activation_func)(x)
              # x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # Optional extra pooling

              # Residual Blocks with increasing filters and downsampling
              # Block 1: 84x84 -> 84x84 (filters=32)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 2: 84x84 -> 28x28 (filters=64, stride=3)
              filters *= 2 # 64
              x = self._residual_block(x, filters, strides=3, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 3: 28x28 -> 28x28 (filters=128) - Stride 1 here
              filters *= 2 # 128
              x = self._residual_block(x, filters, strides=1, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 4: 28x28 -> 14x14 (filters=256, stride=2) - Aiming for spatial dim > 9
              filters *= 2 # 256
              x = self._residual_block(x, filters, strides=2, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # --- Prediction Head ---
              # At this point, spatial dimension is 14x14. We need 9x9 output.
              # Option 1: Use a Conv layer with stride to reduce size (might lose info)
              # Option 2: Use Adaptive Pooling (if available/easy in Keras backend)
              # Option 3: Use Conv + Upsampling (more complex)
              # Option 4: Use a final Conv layer that implicitly handles the size reduction (less common)

              # Let's try a Conv2D layer designed to output the correct spatial dimensions.
              # We need to get closer to 9x9. Add another block?
              # Block 5: 14x14 -> 7x7 (filters=512, stride=2)
              # filters *= 2 # 512
              # x = self._residual_block(x, filters, strides=2, activation=activation_func)
              # x = self._residual_block(x, filters, strides=1, activation=activation_func)
              # Now spatial dim is 7x7. This is too small.

              # Backtrack: Let's stop at 14x14 (Block 4 output).
              # How to get to (9, 9, NUM_CLASSES)?
              # Use a 1x1 Conv to reduce filters, then maybe resize/crop or use specific conv?

              # Try a final Conv layer with appropriate kernel/padding to target 9x9.
              # Input to this layer is (None, 14, 14, 256)
              # Output needed is (None, 9, 9, NUM_CLASSES)

              # Use a 1x1 convolution to adjust the number of channels first
              x = layers.Conv2D(128, 1, padding='same', activation=activation_func, kernel_initializer='he_normal')(x)
              x = layers.BatchNormalization()(x)
              # Now (None, 14, 14, 128)

              # Use a final Conv2D layer to produce the output map.
              # A kernel size of 6 with valid padding on a 14x14 input gives (14-6+1) = 9x9 output.
              # Stride 1 is implicit.
              x = layers.Conv2D(
                  filters=NUM_CLASSES,
                  kernel_size=6, # Kernel size chosen to map 14x14 -> 9x9 with 'valid' padding
                  padding="valid", # 'valid' means no padding
                  activation=None, # Apply softmax separately across the class dimension
                  kernel_initializer='he_normal',
                  name="final_conv_logits"
              )(x)
              # Output shape should now be (None, 9, 9, NUM_CLASSES)

              # Apply Softmax activation across the last axis (classes)
              y_out = layers.Activation("softmax", name="output_softmax")(x)

              # Create the model
              model = models.Model(x_in, y_out, name="fcn_sudoku_grid")

              # Compile the model
              optimizer = keras.optimizers.Adam(learning_rate=5e-4) # Slightly higher LR?
              # Loss function suitable for integer targets and probability outputs
              loss = "sparse_categorical_crossentropy"
              # Metrics: Accuracy calculated per cell prediction
              metrics = ["accuracy"]

              model.compile(
                  optimizer=optimizer,
                  loss=loss,
                  metrics=metrics,
              )
              model.summary(line_length=120)
              return model

          # -------------------------------------------------------------- #
          # preprocessing (for full grid image)
          # -------------------------------------------------------------- #
          def _preprocess_grid_for_model(self, rectified_img: np.ndarray) -> Optional[np.ndarray]:
              """
              Prepares the rectified grid image for the FCN model.
              Resizes, converts to grayscale, normalizes to [0, 1], adds channel dim.
              """
              if rectified_img is None or rectified_img.size == 0:
                  return None

              target_h, target_w, target_c = self._model_input_shape
              is_grayscale = (target_c == 1)

              # Resize to target input size
              # Use INTER_AREA for shrinking, INTER_LINEAR for enlarging
              current_h, current_w = rectified_img.shape[:2]
              if current_h * current_w > target_h * target_w:
                  interp = cv2.INTER_AREA
              else:
                  interp = cv2.INTER_LINEAR
              resized = cv2.resize(rectified_img, (target_w, target_h), interpolation=interp)

              # Ensure correct number of channels (grayscale)
              if is_grayscale:
                  if resized.ndim == 3 and resized.shape[2] == 3:
                      processed = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)
                  elif resized.ndim == 3 and resized.shape[2] == 4:
                      processed = cv2.cvtColor(resized, cv2.COLOR_BGRA2GRAY)
                  elif resized.ndim == 2:
                      processed = resized
                  else:
                      print(f"[Preprocess Error] Unexpected image shape: {resized.shape}")
                      return None
                  # Add channel dimension: (H, W) -> (H, W, 1)
                  processed = processed[..., np.newaxis]
              else: # If model expected color input (target_c == 3)
                  if resized.ndim == 2: # Convert grayscale to BGR
                      processed = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)
                  elif resized.ndim == 3 and resized.shape[2] == 4: # Convert BGRA to BGR
                       processed = cv2.cvtColor(resized, cv2.COLOR_BGRA2BGR)
                  elif resized.ndim == 3 and resized.shape[2] == 3:
                       processed = resized # Already BGR
                  else:
                      print(f"[Preprocess Error] Unexpected image shape for color: {resized.shape}")
                      return None

              # Normalize to [0, 1] float32
              processed = processed.astype("float32") / 255.0

              return processed


          # ------------------------------------------------------------------ #
          # 7.1  augmentation (for full grid image)
          # ------------------------------------------------------------------ #
          def _augment_grid(self, grid_img: np.ndarray) -> np.ndarray:
              """Apply augmentations to the full grid image."""
              h, w = grid_img.shape[:2]
              augmented = grid_img.copy()

              # 1. Small Rotation
              if random.random() < 0.5:
                  angle = random.uniform(-8, 8) # Reduced angle for full grid
                  M_rot = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1.0)
                  augmented = cv2.warpAffine(augmented, M_rot, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0) # Black border

              # 2. Small Translation
              if random.random() < 0.5:
                  tx = random.uniform(-w * 0.03, w * 0.03) # Max 3% translation
                  ty = random.uniform(-h * 0.03, h * 0.03)
                  M_trans = np.float32([[1, 0, tx], [0, 1, ty]])
                  augmented = cv2.warpAffine(augmented, M_trans, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0)

              # 3. Brightness/Contrast Jitter
              if random.random() < 0.6:
                  alpha = random.uniform(0.85, 1.15) # Contrast
                  beta = random.uniform(-0.1, 0.1)   # Brightness
                  augmented = np.clip(augmented * alpha + beta, 0.0, 1.0)

              # 4. Gaussian Noise
              if random.random() < 0.3:
                  noise = np.random.normal(0, random.uniform(0.01, 0.05), augmented.shape)
                  augmented = np.clip(augmented + noise, 0.0, 1.0)

              # Ensure output is float32
              return augmented.astype("float32")


          # -------------------------------------------------------------- #
          # training
          # -------------------------------------------------------------- #
          def train(
              self,
              epochs: int = EPOCHS,
              steps_per_epoch: int = STEPS_PER_EPOCH,
              batch_size: int = BATCH_SIZE,
              validation_steps: int = VALIDATION_STEPS,
          ) -> None:
              """Trains the full-grid FCN model."""
              print(f"\n--- Training Full Grid Classifier ---")
              print(f"Epochs: {epochs}, Steps/Epoch: {steps_per_epoch}, Batch Size: {batch_size}")
              print(f"Input Shape: {self._model_input_shape}, Output: (9, 9, {NUM_CLASSES})")

              if self.model is None:
                  self.model = self._build_cnn_model()
              elif not isinstance(self.model, keras.Model):
                   print("[Error] self.model is not a valid Keras model. Cannot train.")
                   return

              # Prepare test example for callback
              try:
                  test_img_path, test_gt_grid = generate_and_save_test_example()
                  if test_img_path is None or test_gt_grid is None:
                       raise ValueError("Failed to generate/load test example.")
                  # Pass the classifier instance and the ground truth grid (0 for empty)
                  epoch_cb = EpochTestCallback(test_img_path, test_gt_grid, self)
              except Exception as e:
                  print(f"[Warning] Failed to set up EpochTestCallback: {e}. Callback disabled.")
                  epoch_cb = None

              # Create data generators
              # Training generator uses augmentation
              train_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  self._augment_grid, # Apply augmentation
                  self._model_input_shape,
              )
              # Validation generator does not use augmentation
              val_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  None, # No augmentation for validation
                  self._model_input_shape,
              )

              # Dump a batch of augmented training samples for visualization
              dump_dir = Path("dumped_training_grids")
              dump_dir.mkdir(exist_ok=True)
              try:
                  x_vis, y_vis = next(train_gen) # Get one batch from training gen
                  n_dump = min(4, x_vis.shape[0]) # Dump fewer, larger images
                  for i in range(n_dump):
                      # Convert float32 [0,1] -> uint8 [0,255]
                      img = (x_vis[i] * 255).astype(np.uint8)
                      # Maybe add label info to filename if needed, but grid is complex
                      cv2.imwrite(str(dump_dir / f"sample_grid_{i}.png"), img)
                  print(f"[Info] Dumped {n_dump} augmented training grid samples to {dump_dir}")
              except Exception as e:
                  print(f"[Warning] Could not dump training samples: {e}")


              # Callbacks
              cbs: list[callbacks.Callback] = [
                  callbacks.EarlyStopping(
                      monitor="val_accuracy", # Monitor validation accuracy (per-cell)
                      patience=10,          # Increased patience for larger model
                      restore_best_weights=True,
                      verbose=1,
                      mode='max'
                  ),
                  callbacks.ModelCheckpoint(
                      filepath=str(self.model_path), # Ensure path is string
                      monitor="val_accuracy",
                      save_best_only=True,
                      verbose=1,
                      mode='max'
                  ),
                  callbacks.ReduceLROnPlateau(
                      monitor="val_loss", # Reduce LR based on validation loss
                      factor=0.2,
                      patience=4,
                      min_lr=1e-7,
                      verbose=1,
                      mode='min' # Reduce LR when loss plateaus
                  ),
                  # Optional: TensorBoard
                  # callbacks.TensorBoard(log_dir='./logs_fcn', histogram_freq=1)
              ]
              if epoch_cb:
                  cbs.append(epoch_cb)

              # Start Training
              print("\nStarting model training...")
              history = self.model.fit(
                  train_gen,
                  epochs=epochs,
                  steps_per_epoch=steps_per_epoch,
                  validation_data=val_gen,
                  validation_steps=validation_steps,
                  callbacks=cbs,
                  verbose=1, # Use 1 for progress bar, 2 for one line per epoch
              )

              # Ensure the best model is loaded (EarlyStopping might restore, Checkpoint saves)
              if self.model_path.exists():
                   print(f"Reloading best weights from {self.model_path}...")
                   try:
                       # Use load_model if the whole architecture might change,
                       # or load_weights if only weights are saved/needed.
                       # ModelCheckpoint saves the whole model by default.
                       self.model = keras.models.load_model(self.model_path)
                       print("Best model reloaded.")
                   except Exception as e:
                       print(f"[Error] Failed to reload best model after training: {e}")
                       # The model instance might still hold the best weights if EarlyStopping restored them.

              print("\n--- Final Evaluation (using best weights) ---")
              # Use a fresh validation generator for final evaluation
              final_eval_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  None, # No augmentation
                  self._model_input_shape,
              )
              loss, acc = self.model.evaluate(
                  final_eval_gen,
                  steps=validation_steps * 2, # Evaluate on more validation steps
                  verbose=1,
              )
              print(f"Final Validation Loss: {loss:.5f}")
              print(f"Final Validation Accuracy (per cell): {acc:.5f}")

              # Explicitly save the final best model again (belt-and-suspenders)
              try:
                  print(f"Saving final best model to {self.model_path}")
                  self.model.save(self.model_path)
              except Exception as e:
                  print(f"[Error] Failed to save final model: {e}")

              del train_gen, val_gen, final_eval_gen, history
              gc.collect()
              print("--- Training Finished ---")


          # -------------------------------------------------------------- #
          # inference (for full grid)
          # -------------------------------------------------------------- #
          @torch.no_grad() # Keep decorator if using torch backend
          def recognise_grid(
              self,
              rectified_img: np.ndarray,
              confidence_threshold: float = 0.80, # Default threshold for accepting a digit
          ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
              """
              Recognises digits in a rectified Sudoku grid image using the FCN model.

              Args:
                  rectified_img: The (e.g., 252x252) rectified grid image (uint8 or float).
                  confidence_threshold: Minimum confidence to accept a digit prediction (1-9).

              Returns:
                  A tuple (predicted_grid, confidence_grid):
                  - predicted_grid: (9, 9) numpy array with recognised digits (1-9) or 0 for empty/uncertain.
                  - confidence_grid: (9, 9) numpy array with confidence scores for the predicted class in each cell.
                  Returns (None, None) if inference fails.
              """
              if self.model is None:
                  print("[Error] Recognise_grid called but model is not loaded.")
                  return None, None

              # 1. Preprocess the input grid image
              proc_grid = self._preprocess_grid_for_model(rectified_img)
              if proc_grid is None:
                  print("[Error] Preprocessing failed during recognition.")
                  return None, None # Indicate failure

              # 2. Add batch dimension: (H, W, C) -> (1, H, W, C)
              x = proc_grid[np.newaxis, ...]

              # 3. Predict using the Keras model
              try:
                  # Use training=False for inference (important for layers like BatchNorm, Dropout)
                  raw_output = self.model(x, training=False) # Shape: (1, 9, 9, NUM_CLASSES)
              except Exception as e:
                  print(f"[Error] Model prediction failed: {e}")
                  return None, None

              # 4. Convert to NumPy and remove batch dimension
              # Keras with torch backend might return torch tensors
              if hasattr(raw_output, 'cpu') and hasattr(raw_output, 'numpy'): # Check if it's a tensor with cpu/numpy methods
                   probs = raw_output.cpu().numpy()
              elif isinstance(raw_output, np.ndarray):
                   probs = raw_output
              else:
                   print(f"[Error] Unexpected model output type: {type(raw_output)}")
                   return None, None

              probs = probs[0] # Shape: (9, 9, NUM_CLASSES)

              # 5. Decode probabilities to predictions and confidences
              predicted_indices = np.argmax(probs, axis=-1) # Shape: (9, 9), contains indices 0-10
              confidences = np.max(probs, axis=-1)       # Shape: (9, 9), contains max probability

              # 6. Create the final output grid
              # Initialize with zeros (representing empty/uncertain)
              final_grid = np.zeros((GRID_SIZE, GRID_SIZE), dtype=int)

              # Iterate through each cell prediction
              for r in range(GRID_SIZE):
                  for c in range(GRID_SIZE):
                      pred_idx = predicted_indices[r, c]
                      conf = confidences[r, c]

                      # Check if the prediction is a digit (1-9), not EMPTY_LABEL (10),
                      # and if the confidence meets the threshold.
                      if pred_idx != EMPTY_LABEL and conf >= confidence_threshold:
                          final_grid[r, c] = pred_idx # Assign the predicted digit (1-9)
                      # Otherwise, leave it as 0 (empty/uncertain)

              return final_grid, confidences


      # ------------------------------------------------------------------ #
      # 8.  epoch‑end callback (adapted for full grid)
      # ------------------------------------------------------------------ #
      class EpochTestCallback(callbacks.Callback):
          def __init__(
              self,
              test_img_path: Path | str,
              gt_puzzle_grid: np.ndarray, # Ground truth puzzle (0 for empty)
              classifier: "DigitClassifier",
              frequency: int = 1,
          ) -> None:
              super().__init__()
              self.frequency = max(1, frequency)
              self.gt_puzzle_grid = gt_puzzle_grid # Shape (9, 9), 0 for empty
              self.classifier = classifier
              self.test_img_path = test_img_path
              self.preprocessed_test_grid = None # To store the single preprocessed grid

          def on_train_begin(self, logs=None):
              """Preprocess the test image once before training starts."""
              print("\n[Callback] Preprocessing test example for epoch-end evaluation...")
              try:
                  # Extract the rectified grid from the test image file
                  # We don't need the individual cells here, just the rectified image
                  _, rectified_test_img, _ = extract_cells_from_image(
                      self.test_img_path,
                      size=self.classifier._model_input_shape[0], # Use model's input size
                      debug=False
                  )

                  if rectified_test_img is None:
                      print("[Callback Error] Failed to extract rectified grid from test image.")
                      self.preprocessed_test_grid = None
                      return

                  # Preprocess the rectified grid using the classifier's method
                  self.preprocessed_test_grid = self.classifier._preprocess_grid_for_model(rectified_test_img)

                  if self.preprocessed_test_grid is None:
                      print("[Callback Error] Preprocessing of the test grid failed.")
                  else:
                      print(f"[Callback] Test grid preprocessed successfully ({self.preprocessed_test_grid.shape}).")

              except Exception as e:
                  print(f"[Callback Error] Failed during test example setup: {e}")
                  self.preprocessed_test_grid = None

          def on_epoch_end(self, epoch, logs=None):
              # Check if preprocessing was successful and if it's the right epoch
              if self.preprocessed_test_grid is None or (epoch + 1) % self.frequency != 0:
                  return

              if not hasattr(self.model, 'predict'):
                   print("[Callback Error] Model object in callback does not have predict method.")
                   return

              print(f"\n--- Epoch {epoch+1} Test Example Evaluation ---")
              try:
                  # Add batch dimension for prediction
                  x_test = self.preprocessed_test_grid[np.newaxis, ...]

                  # Predict using the model being trained
                  raw_output = self.model.predict(x_test, verbose=0) # Shape: (1, 9, 9, NUM_CLASSES)

                  # Decode the output (similar to recognise_grid)
                  probs = raw_output[0] # Remove batch dim -> (9, 9, NUM_CLASSES)
                  pred_indices = np.argmax(probs, axis=-1) # (9, 9) indices 0-10
                  confs = np.max(probs, axis=-1)       # (9, 9) confidences

                  # Apply thresholding for display (use a slightly lower threshold maybe)
                  display_threshold = 0.7 # Threshold for visualization purposes
                  display_grid = np.zeros_like(pred_indices, dtype=int)
                  for r in range(GRID_SIZE):
                      for c in range(GRID_SIZE):
                          idx = pred_indices[r, c]
                          cf = confs[r, c]
                          if idx != EMPTY_LABEL and cf >= display_threshold:
                              display_grid[r, c] = idx

                  print("Ground Truth Puzzle:")
                  # print_sudoku_grid expects 0 for empty
                  sudoku_recogniser.print_sudoku_grid(self.gt_puzzle_grid)

                  print(f"Prediction (Thresholded @ {display_threshold:.2f}):")
                  sudoku_recogniser.print_sudoku_grid(display_grid, confs, threshold=display_threshold)

                  # --- Calculate Accuracy ---
                  # Compare prediction indices directly with the GT grid converted to use EMPTY_LABEL
                  gt_labels = self.gt_puzzle_grid.copy()
                  gt_labels[gt_labels == 0] = EMPTY_LABEL # Convert GT to use 10 for empty

                  correct_cells = (pred_indices == gt_labels).sum()
                  total_cells = GRID_SIZE * GRID_SIZE
                  accuracy = correct_cells / total_cells
                  print(f"Test Example Accuracy (Raw Prediction vs GT Labels): {correct_cells}/{total_cells} = {accuracy:.4f}")
                  print("--- End Epoch Test ---\n")

              except Exception as e:
                  print(f"[Callback Error] Failed during prediction or display: {e}")
                  import traceback
                  traceback.print_exc()


      # ------------------------------------------------------------------ #
      # 9.  CLI helper
      # ------------------------------------------------------------------ #
      if __name__ == "__main__":
          # Set to True to force retraining even if a model file exists
          FORCE_TRAIN = False

          model_file = Path(MODEL_FILENAME)
          train_needed = FORCE_TRAIN or not model_file.exists()

          if FORCE_TRAIN and model_file.exists():
              print(f"FORCE_TRAIN is True. Deleting existing model: {model_file}")
              try:
                  model_file.unlink()
                  train_needed = True
              except OSError as e:
                  print(f"Error deleting existing model: {e}. Proceeding might use old model if loading works.")
                  # Decide whether to exit or continue
                  # exit(1)

          # Instantiate the classifier. It will try to load if train_needed is False.
          clf = DigitClassifier(model_path=model_file, training_required=train_needed)

          # Train if needed
          if train_needed:
              if clf.model is not None:
                   print("[Warning] Model was loaded despite train_needed=True? Retraining anyway.")
                   clf.model = None # Ensure model is rebuilt
              print("Starting training process...")
              clf.train(epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, batch_size=BATCH_SIZE)
              # After training, the best model should be saved and reloaded by the train method.
              if clf.model is None:
                   print("[Error] Training finished, but model is still None. Cannot proceed.")
                   exit(1)
          elif clf.model is None:
               print("[Error] Model loading failed, and training was not requested. Cannot proceed.")
               exit(1)
          else:
               print("Model loaded successfully. Skipping training.")


          # --- Perform Sanity Check using the Test Example ---
          if clf.model:
              print("\n--- Sanity Check: Recognising the Test Example ---")
              test_img_path_str, test_gt_grid = generate_and_save_test_example() # Get path and GT

              if test_img_path_str is None or test_gt_grid is None:
                  print("Failed to load test example for sanity check.")
              else:
                  test_img_path = Path(test_img_path_str)
                  print(f"Loading test image: {test_img_path}")
                  # Extract rectified grid from the test image
                  _, rectified_test, _ = extract_cells_from_image(
                      test_img_path,
                      size=clf._model_input_shape[0], # Use model's input size
                      debug=False
                  )

                  if rectified_test is None:
                      print("Failed to extract rectified grid from test image for sanity check.")
                  else:
                      print("Running recognise_grid on the test image...")
                      # Use a reasonable confidence threshold for the check
                      pred_grid, conf_grid = clf.recognise_grid(rectified_test, confidence_threshold=0.75)

                      if pred_grid is None:
                          print("Recognition failed during sanity check.")
                      else:
                          print("\nGround Truth Puzzle:")
                          sudoku_recogniser.print_sudoku_grid(test_gt_grid)

                          print("Recognised Grid (Thresholded @ 0.75):")
                          sudoku_recogniser.print_sudoku_grid(pred_grid, conf_grid, threshold=0.75)

                          # Calculate accuracy for the sanity check
                          correct_cells = (pred_grid == test_gt_grid).sum()
                          # Account for empty cells being 0 in both GT and prediction (correctly)
                          # Non-empty cells must match exactly
                          correct_non_empty = ((pred_grid == test_gt_grid) & (test_gt_grid != 0)).sum()
                          correct_empty = ((pred_grid == 0) & (test_gt_grid == 0)).sum()
                          total_correct = correct_non_empty + correct_empty

                          total_cells = GRID_SIZE * GRID_SIZE
                          accuracy = total_correct / total_cells
                          print(f"\nSanity Check Accuracy: {total_correct}/{total_cells} = {accuracy:.4f}")
          else:
              print("\nSanity check skipped: No model available.")

          print("\nScript finished.")
      ```

      ```python 'sudoku_recogniser.py'
      """
      Command-line utility to detect a Sudoku grid in an image and recognise its digits
      using the full-grid classifier.
      """

      from __future__ import annotations

      import sys
      import time
      from pathlib import Path
      from typing import Tuple, Optional

      import cv2
      import numpy as np

      # Import the updated classifier and extractor
      import digit_classifier
      from digit_extractor import GRID_SIZE, DEFAULT_RECTIFIED_SIZE, extract_cells_from_image

      # Confidence threshold for final acceptance of a recognised digit (1-9)
      # This can be tuned based on model performance.
      FINAL_CONFIDENCE_THRESHOLD = 0.75 # Adjusted slightly


      def print_sudoku_grid(
          grid: np.ndarray,
          conf: Optional[np.ndarray] = None,
          threshold: float = FINAL_CONFIDENCE_THRESHOLD
      ) -> None:
          """
          Nicely print a 9×9 Sudoku grid.
          Marks digits below the threshold with '?' if confidences are provided.
          Expects grid values 0-9, where 0 is empty.
          """
          grid = np.asarray(grid)
          if grid.shape != (GRID_SIZE, GRID_SIZE):
              print(f"[print_sudoku_grid] Invalid grid shape: {grid.shape}")
              return

          print("-" * 25) # Top border
          for r in range(GRID_SIZE):
              if r > 0 and r % 3 == 0:
                  print("|-------+-------+-------|") # Separator line

              line = ["|"] # Start of row
              for c in range(GRID_SIZE):
                  digit = grid[r, c]
                  token = ""
                  if digit == 0:
                      token = "." # Represent empty cell
                  else:
                      token = str(digit)
                      # If confidence is provided and below threshold, mark as uncertain
                      if conf is not None and conf.shape == (GRID_SIZE, GRID_SIZE) and conf[r, c] < threshold:
                          token = "?"

                  line.append(f" {token} ") # Add token with spacing

                  if (c + 1) % 3 == 0:
                      line.append("|") # Add column separator

              print("".join(line)) # Print the row
          print("-" * 25) # Bottom border
          print() # Add a blank line after the grid


      def display_results_on_image(
          rectified: Optional[np.ndarray],
          grid: np.ndarray,
          conf: Optional[np.ndarray] = None,
          threshold: float = FINAL_CONFIDENCE_THRESHOLD
      ) -> Optional[np.ndarray]:
          """
          Draw recognised digits (above threshold) onto the rectified grid image.
          """
          if rectified is None:
              print("[Display] No rectified image provided.")
              return None

          # Ensure image is BGR for drawing colors
          img_display = (
              cv2.cvtColor(rectified, cv2.COLOR_GRAY2BGR)
              if rectified.ndim == 2 else rectified.copy()
          )
          h, w = img_display.shape[:2]
          if h == 0 or w == 0: return None # Invalid image dimensions

          cell_h, cell_w = h // GRID_SIZE, w // GRID_SIZE
          if cell_h == 0 or cell_w == 0: return img_display # Cannot draw if cells are too small

          # Choose font properties
          font_face = cv2.FONT_HERSHEY_SIMPLEX
          font_scale_base = min(cell_h, cell_w) / 35.0 # Scale font based on cell size
          font_thickness = max(1, int(font_scale_base * 1.5))

          for r in range(GRID_SIZE):
              for c in range(GRID_SIZE):
                  digit = grid[r, c]
                  confidence = conf[r, c] if conf is not None else 1.0 # Assume high conf if not provided

                  # Only draw digits that are not empty and meet the confidence threshold
                  if digit != 0 and confidence >= threshold:
                      text = str(digit)

                      # Calculate text size to center it
                      (text_w, text_h), baseline = cv2.getTextSize(text, font_face, font_scale_base, font_thickness)

                      # Calculate center position of the cell
                      center_x = c * cell_w + cell_w // 2
                      center_y = r * cell_h + cell_h // 2

                      # Calculate bottom-left corner of the text for centering
                      text_x = center_x - text_w // 2
                      text_y = center_y + text_h // 2

                      # Draw the text
                      cv2.putText(
                          img_display,
                          text,
                          (text_x, text_y),
                          font_face,
                          font_scale_base,
                          (0, 200, 0), # Green color for recognised digits
                          font_thickness,
                          cv2.LINE_AA # Anti-aliased text
                      )
                  # Optional: Draw uncertain digits differently (e.g., red '?')
                  # elif digit != 0 and conf is not None and confidence < threshold:
                  #     text = "?"
                  #     (text_w, text_h), baseline = cv2.getTextSize(text, font_face, font_scale_base, font_thickness)
                  #     center_x = c * cell_w + cell_w // 2
                  #     center_y = r * cell_h + cell_h // 2
                  #     text_x = center_x - text_w // 2
                  #     text_y = center_y + text_h // 2
                  #     cv2.putText(img_display, text, (text_x, text_y), font_face, font_scale_base, (0, 0, 255), font_thickness, cv2.LINE_AA)


          return img_display


      def recognise_sudoku(
          img_path: Path,
          classifier: digit_classifier.DigitClassifier
      ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
          """
          Extract rectified grid and run the full-grid classifier.

          Returns:
              Tuple of (predicted_grid, confidence_grid, rectified_image).
              predicted_grid: (9, 9) int array, 0 for empty/uncertain.
              confidence_grid: (9, 9) float array of confidences.
              rectified_image: The (e.g., 252x252) rectified image.
              Returns (None, None, None) on failure.
          """
          print(f"Processing {img_path.name}...")
          start_time = time.time()

          # 1. Extract the rectified grid image
          # We don't need individual cells from the extractor anymore
          # Use the input size expected by the classifier model
          rectified_size = classifier._model_input_shape[0]
          _, rectified_img, _ = extract_cells_from_image(
              img_path,
              size=rectified_size,
              debug=False # Set to True for extraction debugging images
          )

          if rectified_img is None:
              print("❌ Failed to extract or rectify the Sudoku grid.")
              return None, None, None
          print(f"✅ Grid extracted and rectified ({time.time() - start_time:.2f}s)")
          extract_time = time.time()

          # 2. Recognise digits using the full-grid classifier
          print("🧠 Running grid recognition model...")
          predicted_grid, confidence_grid = classifier.recognise_grid(
              rectified_img,
              confidence_threshold=FINAL_CONFIDENCE_THRESHOLD
          )

          if predicted_grid is None or confidence_grid is None:
              print("❌ Model recognition failed.")
              return None, None, rectified_img # Return rectified image even if recognition fails

          elapsed_time = time.time() - start_time
          print(f"✅ Recognition complete ({time.time() - extract_time:.2f}s)")
          print(f"⏱️ Total time: {elapsed_time:.2f}s")

          return predicted_grid, confidence_grid, rectified_img


      def main() -> None:
          if len(sys.argv) < 2:
              print("Usage: python sudoku_recogniser.py <image_path> [--no-train]")
              print("  <image_path>: Path to the Sudoku image file.")
              print("  --no-train: Optional flag to prevent training if the model is missing.")
              sys.exit(0)

          img_path = Path(sys.argv[1])
          if not img_path.is_file():
              print(f"❌ Error: Image file not found at '{img_path}'")
              sys.exit(1)

          # Check for --no-train flag
          force_no_train = "--no-train" in sys.argv

          # Instantiate the classifier
          # It will try to load the model. Training is required if the model file
          # doesn't exist, unless --no-train is specified.
          model_exists = Path(digit_classifier.MODEL_FILENAME).exists()
          training_required = not model_exists

          if training_required and force_no_train:
              print("Model file not found, but --no-train specified. Exiting.")
              sys.exit(1)
          elif training_required:
              print(f"⚠️ Model file '{digit_classifier.MODEL_FILENAME}' not found.")
              print("Initiating training process...")
              classifier = digit_classifier.DigitClassifier(training_required=True)
              classifier.train() # Use default training parameters from classifier script
              # Check if model was successfully created after training
              if classifier.model is None:
                   print("❌ Training failed to produce a model. Exiting.")
                   sys.exit(1)
              print("✅ Training complete. Proceeding with recognition...")
          else:
              # Model exists or --no-train was used with existing model
              classifier = digit_classifier.DigitClassifier(training_required=False)
              if classifier.model is None:
                   print(f"❌ Failed to load existing model '{digit_classifier.MODEL_FILENAME}'. Exiting.")
                   sys.exit(1)
              print(f"✅ Model '{digit_classifier.MODEL_FILENAME}' loaded.")


          # Recognise the Sudoku in the input image
          try:
              grid, conf, rectified = recognise_sudoku(img_path, classifier)

              if grid is None or conf is None:
                  print("\n❌ Sudoku recognition process failed.")
                  # Rectified might still exist, show it if possible
                  if rectified is not None:
                       cv2.imshow("Failed Extraction/Rectification", rectified)
                       cv2.waitKey(0)
                  sys.exit(1)

              # Print the recognised grid to the console
              print("\n--- Recognised Sudoku Grid ---")
              print_sudoku_grid(grid, conf, threshold=FINAL_CONFIDENCE_THRESHOLD)

              # Display the rectified image with recognised digits overlaid
              result_img = display_results_on_image(rectified, grid, conf, threshold=FINAL_CONFIDENCE_THRESHOLD)
              if result_img is not None:
                  print("ℹ️ Displaying recognised grid on image. Press any key to close.")
                  cv2.imshow("Sudoku Recognition Result", result_img)
                  cv2.waitKey(0)
              else:
                  print("ℹ️ Could not generate result image.")

          except Exception as e:
              print(f"\n❌ An unexpected error occurred: {e}")
              import traceback
              traceback.print_exc()
              sys.exit(1)
          finally:
              cv2.destroyAllWindows() # Ensure any OpenCV windows are closed


      if __name__ == "__main__":
          main()
      ```
    metadata:
  - assistant: |-
      Okay, let's refactor the system to predict the entire Sudoku grid at once from the rectified image and ensure the generated training puzzles are based on valid, solvable Sudoku grids.

      **Key Changes:**

      1.  **`sudoku_renderer.py`:**
          *   Added helper functions (`_is_safe`, `_find_empty`, `_solve_sudoku`, `_generate_sudoku_solution`) to create valid, complete Sudoku solutions.
          *   Modified `render_sudoku` to:
              *   Generate a full solution using the helpers.
              *   Create a puzzle (the `ground_truth_grid`) by removing digits from the solution based on `allow_empty` or a target number of clues.
              *   Render the *puzzle* grid.
              *   Return the rendered image, the ground truth grid (with 0s for empty cells), and corners.
      2.  **`digit_classifier.py`:**
          *   **Model Input/Output:** Changed `MODEL_INPUT_SHAPE` to accept the whole rectified grid (resized to `(252, 252, 1)` for divisibility). The output shape is now `(9, 9, NUM_CLASSES)`.
          *   **Architecture (`_build_cnn_model`):** Replaced the single-cell CNN with a Fully Convolutional Network (FCN) using ResNet-style blocks, designed to process the larger input and produce a `(9, 9, 11)` output tensor representing the probabilities for each cell. Downsampling is carefully managed.
          *   **Preprocessing:** Removed `_preprocess_cell_for_model`. Added `_preprocess_grid_for_model` to resize and normalize the entire rectified grid image.
          *   **Augmentation:** Removed `_augment_cell*`. Added `_augment_grid` to apply augmentations to the full grid image.
          *   **Data Generator (`sudoku_data_generator`):** Modified to yield batches of `(preprocessed_grid_image, grid_labels)`. The complex balancing logic is removed as each sample is now a full grid. The `gt_grid` returned by the renderer (with 0s) is converted to use `EMPTY_LABEL` (10) for the model's target `y`.
          *   **Inference (`recognise` -> `recognise_grid`):** Takes a rectified grid image, preprocesses it, runs the model once, decodes the `(9, 9, 11)` output using `argmax` and confidence checks, and returns the predicted `(9, 9)` integer grid and the `(9, 9)` confidence grid.
          *   **Training:** Updated to use the new generator, preprocessing, and augmentation. Visualization dump saves input grid images.
          *   **Callbacks (`EpochTestCallback`):** Updated to preprocess the full test grid image and evaluate the model's full grid prediction against the ground truth.
          *   **Sanity Check:** Replaced single-cell checks with a check that processes the standard test image.
      3.  **`digit_extractor.py`:**
          *   Updated `DEFAULT_RECTIFIED_SIZE` to match the new model input size (252).
      4.  **`sudoku_recogniser.py`:**
          *   Modified `recognise_sudoku` to call the new `classifier.recognise_grid` method.
          *   Adjusted `FINAL_CONFIDENCE_THRESHOLD` slightly.

      ```python 'sudoku_renderer.py'
      """
      Synthetic Sudoku image generator for on‑the‑fly training data.
      Generates puzzles based on valid, solvable Sudoku grids.
      """

      import random
      import time
      from pathlib import Path
      from typing import Tuple, Optional, List

      import cv2
      import numpy as np
      import keras

      GRID_SIZE = 9
      BASE_IMAGE_SIZE = 1000 # Initial rendering size before warp
      CELL_SIZE = BASE_IMAGE_SIZE // GRID_SIZE
      # Ensure MNIST is loaded only once
      MNIST_BUCKETS: Optional[dict[int, list[np.ndarray]]] = None

      # --- Sudoku Generation Helpers ---

      def _is_safe(grid: np.ndarray, row: int, col: int, num: int) -> bool:
          """Check if it's safe to place 'num' at grid[row, col]."""
          # Check row
          if num in grid[row, :]:
              return False
          # Check column
          if num in grid[:, col]:
              return False
          # Check 3x3 box
          start_row, start_col = 3 * (row // 3), 3 * (col // 3)
          if num in grid[start_row:start_row + 3, start_col:start_col + 3]:
              return False
          return True

      def _find_empty(grid: np.ndarray) -> Optional[Tuple[int, int]]:
          """Find an empty cell (marked with 0)."""
          for r in range(GRID_SIZE):
              for c in range(GRID_SIZE):
                  if grid[r, c] == 0:
                      return (r, c)
          return None

      def _solve_sudoku(grid: np.ndarray) -> bool:
          """Solve the Sudoku grid in-place using backtracking."""
          find = _find_empty(grid)
          if not find:
              return True  # Solved
          else:
              row, col = find

          nums = list(range(1, GRID_SIZE + 1))
          random.shuffle(nums) # Introduce randomness for generation

          for num in nums:
              if _is_safe(grid, row, col, num):
                  grid[row, col] = num
                  if _solve_sudoku(grid):
                      return True
                  grid[row, col] = 0  # Backtrack

          return False

      def _generate_sudoku_solution() -> np.ndarray:
          """Generate a complete, valid Sudoku grid."""
          while True: # Keep trying until a valid solution is found
              grid = np.zeros((GRID_SIZE, GRID_SIZE), dtype=int)
              if _solve_sudoku(grid):
                  return grid
              # print("Failed to generate solution, retrying...") # Optional debug
              time.sleep(0.01) # Avoid busy-waiting if something goes wrong

      def _create_puzzle(solution: np.ndarray, difficulty: float = 0.5) -> np.ndarray:
          """
          Create a puzzle by removing cells from a solution.
          Difficulty: approx. fraction of cells to remove (0.1 easy, 0.5 medium, 0.7 hard).
          Note: This simple removal doesn't guarantee unique solvability, but ensures
                the underlying pattern is valid.
          """
          puzzle = solution.copy()
          num_cells = GRID_SIZE * GRID_SIZE
          num_remove = int(num_cells * difficulty)

          attempts = 0
          removed_count = 0
          while removed_count < num_remove and attempts < num_cells * 2:
              row, col = random.randint(0, GRID_SIZE - 1), random.randint(0, GRID_SIZE - 1)
              if puzzle[row, col] != 0:
                  puzzle[row, col] = 0
                  removed_count += 1
              attempts += 1
          # print(f"Removed {removed_count} cells for difficulty {difficulty}") # Optional debug
          return puzzle

      # --- MNIST Loading ---

      def _load_mnist_digits() -> dict[int, list[np.ndarray]]:
          """
          Download MNIST once and bucket images by label for rendering.
          """
          global MNIST_BUCKETS
          if MNIST_BUCKETS is not None:
              return MNIST_BUCKETS

          print("Loading MNIST dataset for rendering...")
          try:
              (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
              images = np.concatenate([x_train, x_test])
              labels = np.concatenate([y_train, y_test])

              buckets: dict[int, list[np.ndarray]] = {i: [] for i in range(10)}
              for img, lbl in zip(images, labels):
                  # Invert (black digit on white bg) and add padding
                  inv = cv2.bitwise_not(img)
                  padded = cv2.copyMakeBorder(
                      inv, 4, 4, 4, 4,
                      cv2.BORDER_CONSTANT, value=255 # White padding
                  )
                  buckets[int(lbl)].append(padded)
              print("MNIST loaded.")
              MNIST_BUCKETS = buckets
              return MNIST_BUCKETS
          except Exception as e:
              print(f"Error loading MNIST: {e}. Will only use font rendering.")
              MNIST_BUCKETS = {i: [] for i in range(10)} # Empty buckets
              return MNIST_BUCKETS


      # --- Renderer Class ---

      class SudokuRenderer:
          """
          Render a random Sudoku puzzle (based on a valid solution) to a synthetic image.
          """

          def __init__(self) -> None:
              self.mnist_buckets = _load_mnist_digits() # Ensure MNIST is loaded/attempted

          def _digit_source(self, digit: int) -> Tuple[Optional[np.ndarray], str]:
              """Choose between MNIST digit or font rendering."""
              sources = []
              # Only allow MNIST if buckets[digit] is not empty
              if self.mnist_buckets and self.mnist_buckets.get(digit):
                  sources.append("mnist")
              sources.append("font") # Always allow font as fallback
              choice = random.choice(sources)

              if choice == "mnist":
                  img = random.choice(self.mnist_buckets[digit])
                  # Ensure it's BGR for consistency
                  if img.ndim == 2:
                      img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                  return img, "mnist"
              # Fallback to font rendering if MNIST chosen but failed, or if font chosen
              return None, "font"

          def render_sudoku(
              self,
              grid_spec: Optional[np.ndarray] = None,
              *,
              allow_empty: bool = True, # If True, difficulty is random, otherwise uses grid_spec or full solution
              difficulty: float = 0.5 # Used if allow_empty=True and grid_spec=None
          ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
              """
              Generate a synthetic Sudoku image based on a valid grid.

              Args:
                  grid_spec: A specific (9, 9) puzzle grid (0 for empty). If None, generates randomly.
                  allow_empty: If True and grid_spec is None, generate a puzzle with random difficulty.
                               If False and grid_spec is None, render the full solution.
                  difficulty: Target fraction of empty cells if generating randomly (approx).

              Returns:
                  Tuple of (image, ground_truth_puzzle_grid, warped_corners).
                  Returns (None, None, None) on generation failure.
              """
              try:
                  if grid_spec is not None:
                      # Use the provided puzzle spec directly
                      gt_puzzle = grid_spec.copy()
                      # We don't have the full solution here, but the puzzle itself is the ground truth
                  else:
                      # Generate a full solution first
                      solution = _generate_sudoku_solution()
                      if not allow_empty:
                          # Render the full solution
                          gt_puzzle = solution.copy()
                      else:
                          # Create a puzzle by removing digits from the solution
                          rand_difficulty = random.uniform(0.3, 0.7) # Randomize difficulty
                          gt_puzzle = _create_puzzle(solution, difficulty=rand_difficulty)

                  # --- Start Rendering ---
                  bg_color = tuple(random.randint(200, 240) for _ in range(3))
                  img = np.full((BASE_IMAGE_SIZE, BASE_IMAGE_SIZE, 3), bg_color, np.uint8)

                  # Draw grid lines
                  for i in range(GRID_SIZE + 1):
                      major = (i % 3 == 0)
                      thickness = random.randint(3 if major else 1, 5 if major else 3)
                      color = (0, 0, 0) # Black lines
                      # Horizontal lines
                      cv2.line(img, (0, i * CELL_SIZE), (BASE_IMAGE_SIZE, i * CELL_SIZE), color, thickness)
                      # Vertical lines
                      cv2.line(img, (i * CELL_SIZE, 0), (i * CELL_SIZE, BASE_IMAGE_SIZE), color, thickness)

                  # Draw digits onto the grid based on gt_puzzle
                  for r in range(GRID_SIZE):
                      for c in range(GRID_SIZE):
                          digit_to_render = gt_puzzle[r, c]
                          if digit_to_render == 0:
                              continue # Skip empty cells

                          src_img, src_type = self._digit_source(digit_to_render)
                          scale = random.uniform(0.5, 0.8) # Size relative to cell
                          target_size = int(CELL_SIZE * scale)
                          if target_size < 10: continue # Skip if too small

                          # Calculate center position with jitter
                          center_x = c * CELL_SIZE + CELL_SIZE // 2
                          center_y = r * CELL_SIZE + CELL_SIZE // 2
                          dx = int(random.uniform(-0.1, 0.1) * CELL_SIZE)
                          dy = int(random.uniform(-0.1, 0.1) * CELL_SIZE)
                          cx, cy = center_x + dx, center_y + dy

                          if src_type == "mnist" and src_img is not None:
                              # Resize MNIST digit
                              digit_img = cv2.resize(src_img, (target_size, target_size), interpolation=cv2.INTER_AREA)

                              # Random rotation
                              angle = random.uniform(-10, 10)
                              M = cv2.getRotationMatrix2D((target_size / 2, target_size / 2), angle, 1)
                              digit_img = cv2.warpAffine(
                                  digit_img, M, (target_size, target_size),
                                  borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255) # Match padding
                              )

                              # Create mask (assuming black digit on white background from MNIST processing)
                              mask = cv2.cvtColor(digit_img, cv2.COLOR_BGR2GRAY)
                              _, mask = cv2.threshold(mask, 250, 255, cv2.THRESH_BINARY_INV) # Invert to get digit mask

                              # Calculate ROI in the main image
                              x0 = max(0, cx - target_size // 2)
                              y0 = max(0, cy - target_size // 2)
                              x1 = min(img.shape[1], x0 + target_size)
                              y1 = min(img.shape[0], y0 + target_size)
                              roi = img[y0:y1, x0:x1]

                              # Adjust digit image and mask if ROI is smaller (near edges)
                              digit_roi = digit_img[0:roi.shape[0], 0:roi.shape[1]]
                              mask_roi = mask[0:roi.shape[0], 0:roi.shape[1]]
                              mask_inv_roi = cv2.bitwise_not(mask_roi)

                              # Place digit using mask
                              bg_region = cv2.bitwise_and(roi, roi, mask=mask_inv_roi)
                              fg_region = cv2.bitwise_and(digit_roi, digit_roi, mask=mask_roi)
                              img[y0:y1, x0:x1] = cv2.add(bg_region, fg_region)

                          else: # Use font rendering
                              font = cv2.FONT_HERSHEY_SIMPLEX # Or try FONT_HERSHEY_DUPLEX etc.
                              thickness = random.randint(2, 4)
                              # Adjust font scale to fit target size
                              font_scale = cv2.getFontScaleFromHeight(font, target_size, thickness) * 0.8
                              text = str(digit_to_render)
                              (tw, th), _ = cv2.getTextSize(text, font, font_scale, thickness)

                              # Calculate position for font rendering
                              text_x = cx - tw // 2
                              text_y = cy + th // 2
                              cv2.putText(img, text, (text_x, text_y),
                                          font, font_scale, (0, 0, 0), thickness, cv2.LINE_AA)

                  # --- Post-processing ---
                  # Add noise
                  noise_level = random.uniform(5, 15)
                  noise = np.random.normal(0, noise_level, img.shape).astype(np.float32)
                  noisy_img = np.clip(img.astype(np.float32) + noise, 0, 255).astype(np.uint8)

                  # Random perspective warp
                  h, w = noisy_img.shape[:2]
                  orig_corners = np.array([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype="float32")
                  shift_factor = random.uniform(0.02, 0.15) # Reduced max shift slightly
                  max_dx, max_dy = w * shift_factor, h * shift_factor

                  # Generate new corner positions with some randomness
                  warped_corners = np.array([
                      [random.uniform(0, max_dx), random.uniform(0, max_dy)], # Top-left
                      [w - 1 - random.uniform(0, max_dx), random.uniform(0, max_dy)], # Top-right
                      [w - 1 - random.uniform(0, max_dx), h - 1 - random.uniform(0, max_dy)], # Bottom-right
                      [random.uniform(0, max_dx), h - 1 - random.uniform(0, max_dy)], # Bottom-left
                  ], dtype="float32")

                  # Ensure corners maintain roughly the correct order (prevent extreme warps)
                  # Simple check: ensure TL x < TR x, BL x < BR x, TL y < BL y, TR y < BR y
                  if (warped_corners[0,0] >= warped_corners[1,0] or \
                      warped_corners[3,0] >= warped_corners[2,0] or \
                      warped_corners[0,1] >= warped_corners[3,1] or \
                      warped_corners[1,1] >= warped_corners[2,1]):
                       # If order is messed up, use less aggressive warp or skip warp
                       warped_corners = orig_corners # Fallback to no warp this time

                  M = cv2.getPerspectiveTransform(orig_corners, warped_corners)

                  # Calculate output bounds for warped image
                  out_w = int(np.max(warped_corners[:, 0])) + 1
                  out_h = int(np.max(warped_corners[:, 1])) + 1
                  out_w = max(out_w, 100) # Ensure minimum size
                  out_h = max(out_h, 100)

                  warped_img = cv2.warpPerspective(
                      noisy_img, M, (out_w, out_h),
                      flags=cv2.INTER_LINEAR, # Smoother interpolation
                      borderMode=cv2.BORDER_REPLICATE # Replicate border pixels
                  )

                  # Apply slight blur after warping
                  final_img = cv2.GaussianBlur(warped_img, (3, 3), 0)

                  # Return the final image, the puzzle grid (0 for empty), and the warped corners
                  return final_img, gt_puzzle, warped_corners

              except Exception as e:
                  print(f"[Renderer Error] Failed to render Sudoku: {e}")
                  import traceback
                  traceback.print_exc()
                  return None, None, None


      def generate_and_save_test_example(
          prefix: str = "epoch_test_sudoku",
          force: bool = False
      ) -> Tuple[Optional[str], Optional[np.ndarray]]:
          """
          Generate or load a fixed Sudoku test example for epoch callbacks.
          Returns (image_path, ground_truth_puzzle_grid).
          """
          img_path = Path(f"{prefix}.png")
          gt_path = Path(f"{prefix}_gt.npy")

          if not force and img_path.exists() and gt_path.exists():
              try:
                  gt = np.load(gt_path)
                  # Basic check if loaded files are valid
                  if cv2.imread(str(img_path)) is not None and gt.shape == (GRID_SIZE, GRID_SIZE):
                       print(f"Loaded existing test example: {img_path}, {gt_path}")
                       return str(img_path), gt
                  else:
                       print("Existing test example files corrupted, regenerating...")
              except Exception as e:
                  print(f"Error loading existing test example ({e}), regenerating...")

          print("Generating new test example...")
          renderer = SudokuRenderer()
          # Define a specific puzzle grid (0 for empty)
          # This puzzle should ideally be solvable and have a unique solution
          # Example puzzle (source: websudoku.com easy)
          test_puzzle_grid = np.array([
              [0, 0, 3, 0, 2, 0, 6, 0, 0],
              [9, 0, 0, 3, 0, 5, 0, 0, 1],
              [0, 0, 1, 8, 0, 6, 4, 0, 0],
              [0, 0, 8, 1, 0, 2, 9, 0, 0],
              [7, 0, 0, 0, 0, 0, 0, 0, 8],
              [0, 0, 6, 7, 0, 8, 2, 0, 0],
              [0, 0, 2, 6, 0, 9, 5, 0, 0],
              [8, 0, 0, 2, 0, 3, 0, 0, 9],
              [0, 0, 5, 0, 1, 0, 3, 0, 0]
          ], dtype=int)

          # Render this specific puzzle
          img, gt, _ = renderer.render_sudoku(grid_spec=test_puzzle_grid)

          if img is None or gt is None:
              print("[Error] Failed to generate test example image.")
              return None, None

          try:
              cv2.imwrite(str(img_path), img)
              np.save(gt_path, gt)
              print(f"Saved new test example: {img_path}, {gt_path}")
              return str(img_path), gt
          except Exception as e:
              print(f"[Error] Failed to save test example: {e}")
              return None, None

      # Example usage for debugging
      if __name__ == "__main__":
          print("Generating a sample Sudoku image...")
          renderer = SudokuRenderer()
          img, gt, corners = renderer.render_sudoku(allow_empty=True, difficulty=0.6)

          if img is not None:
              print("Generated Ground Truth Puzzle Grid:")
              print(gt)
              cv2.imwrite("sample_sudoku_generated.png", img)
              print("Saved sample image to sample_sudoku_generated.png")

              # Also generate the fixed test example if needed
              generate_and_save_test_example(force=True)
          else:
              print("Failed to generate sample image.")
      ```

      ```python 'digit_extractor.py'
      """
      Find and extract Sudoku grid cells from an image.
      """

      import os
      from pathlib import Path
      from typing import List, Tuple, Optional

      import cv2
      import numpy as np

      GRID_SIZE = 9
      # Changed default size to be divisible by common CNN strides (e.g., 2^3=8 or 3^3=27)
      # 252 = 9 * 28 -> divisible by 2, 3, 4, 6, 7, 9, 12, 14, 18, 21, 28...
      DEFAULT_RECTIFIED_SIZE = 252


      def _order_points(pts: np.ndarray) -> np.ndarray:
          """Order four points as top-left, top-right, bottom-right, bottom-left."""
          pts = pts.reshape(4, 2).astype("float32")
          rect = np.zeros((4, 2), dtype="float32")
          s = pts.sum(axis=1)
          rect[0] = pts[np.argmin(s)] # Top-left has smallest sum
          rect[2] = pts[np.argmax(s)] # Bottom-right has largest sum
          diff = np.diff(pts, axis=1) # diff = y - x
          rect[1] = pts[np.argmin(diff)] # Top-right has smallest diff
          rect[3] = pts[np.argmax(diff)] # Bottom-left has largest diff
          return rect


      def find_sudoku_grid_contour(
          img: np.ndarray,
          debug_dir: Optional[Path] = None
      ) -> Optional[np.ndarray]:
          """
          Find the largest 4-point contour approximating the Sudoku grid boundary.
          Returns the contour points (4, 2) or None if not found.
          """
          if img is None or img.size == 0:
              print("[Contour Finder] Invalid input image.")
              return None

          gray = (
              cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
              if img.ndim == 3 and img.shape[2] == 3 else img.copy()
          )
          if gray.ndim == 3: # Handle case like RGBA input
              gray = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)

          if debug_dir:
              debug_dir.mkdir(parents=True, exist_ok=True)
              cv2.imwrite(str(debug_dir / "00_gray.png"), gray)

          # Preprocessing: Blur and Threshold
          # GaussianBlur helps reduce noise before thresholding
          blur = cv2.GaussianBlur(gray, (7, 7), 0)
          if debug_dir: cv2.imwrite(str(debug_dir / "01_blur.png"), blur)

          # Adaptive thresholding is generally robust to lighting changes
          thresh = cv2.adaptiveThreshold(
              blur, 255,
              cv2.ADAPTIVE_THRESH_GAUSSIAN_C, # Method
              cv2.THRESH_BINARY_INV,         # Threshold type (invert to get black lines on white)
              15,                            # Block size (must be odd) - adjust based on image size/line thickness
              4                              # Constant C subtracted from mean
          )
          if debug_dir: cv2.imwrite(str(debug_dir / "02_thresh.png"), thresh)

          # Morphological closing to connect broken lines
          kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
          closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)
          if debug_dir: cv2.imwrite(str(debug_dir / "03_closed.png"), closed)

          # Find contours
          contours, _ = cv2.findContours(
              closed,
              cv2.RETR_EXTERNAL,        # Retrieve only outer contours
              cv2.CHAIN_APPROX_SIMPLE   # Compress horizontal/vertical segments
          )

          if not contours:
              print("[Contour Finder] No contours found.")
              return None

          # Sort contours by area (descending) and filter small ones
          contours = sorted(contours, key=cv2.contourArea, reverse=True)
          min_area = gray.size * 0.05 # Require contour to be at least 5% of image area

          if debug_dir:
              img_contours = img.copy() if img.ndim == 3 else cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
              cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 1) # Draw all contours found
              cv2.imwrite(str(debug_dir / "04_all_contours.png"), img_contours)


          # Find the largest quadrilateral contour that resembles a square
          for i, cnt in enumerate(contours):
              area = cv2.contourArea(cnt)
              if area < min_area:
                  # print(f"[Contour Finder] Remaining contours too small (area {area} < {min_area}).")
                  break # No need to check smaller contours

              peri = cv2.arcLength(cnt, True)
              # Approximate the contour shape to a polygon
              approx = cv2.approxPolyDP(cnt, 0.02 * peri, True) # Epsilon factor determines accuracy

              # Check if the approximation has 4 vertices and is convex
              if len(approx) == 4 and cv2.isContourConvex(approx):
                  # Check aspect ratio of the bounding box
                  x, y, w, h = cv2.boundingRect(approx)
                  aspect_ratio = w / float(h) if h > 0 else 0

                  # Allow some tolerance for perspective distortion
                  if 0.7 < aspect_ratio < 1.3:
                      if debug_dir:
                          img_found = img.copy() if img.ndim == 3 else cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
                          cv2.drawContours(img_found, [approx], -1, (0, 0, 255), 3)
                          cv2.imwrite(str(debug_dir / f"05_found_contour_{i}.png"), img_found)
                      # print(f"[Contour Finder] Found potential grid contour (index {i}, area {area:.0f}, aspect {aspect_ratio:.2f}).")
                      return approx.reshape(4, 2).astype("float32") # Return the corner points

          print("[Contour Finder] No suitable Sudoku grid contour found.")
          return None


      def rectify_grid(
          img: np.ndarray,
          contour: np.ndarray,
          size: int = DEFAULT_RECTIFIED_SIZE
      ) -> Optional[np.ndarray]:
          """Perspective-correct the Sudoku grid to a square of given size."""
          if contour is None or contour.shape != (4, 2):
              print("[Rectifier] Invalid contour provided.")
              return None
          if img is None or img.size == 0:
              print("[Rectifier] Invalid image provided.")
              return None

          try:
              # Order the contour points: TL, TR, BR, BL
              src_pts = _order_points(contour)

              # Define the destination points for the square image
              dst_pts = np.array([
                  [0, 0],             # Top-left
                  [size - 1, 0],      # Top-right
                  [size - 1, size - 1], # Bottom-right
                  [0, size - 1],      # Bottom-left
              ], dtype="float32")

              # Calculate the perspective transform matrix
              matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)

              # Apply the perspective warp
              warped = cv2.warpPerspective(img, matrix, (size, size))
              return warped
          except Exception as e:
              print(f"[Rectifier] Error during perspective warp: {e}")
              return None


      def split_into_cells(
          rectified: np.ndarray
      ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray]]:
          """
          Split the rectified grid into GRID_SIZE × GRID_SIZE cell images.
          Applies a small margin removal.
          Returns (cells, rectified_image) or (None, None) on failure.
          """
          if rectified is None or rectified.shape[0] != rectified.shape[1]:
              print("[Splitter] Invalid rectified image provided.")
              return None, None

          h, w = rectified.shape[:2]
          if h == 0 or w == 0:
              print("[Splitter] Rectified image has zero dimension.")
              return None, None

          cell_sz_h = h // GRID_SIZE
          cell_sz_w = w // GRID_SIZE
          if cell_sz_h == 0 or cell_sz_w == 0:
              print("[Splitter] Calculated cell size is zero.")
              return None, None

          # Calculate margin to remove grid lines (e.g., 4% of cell size)
          margin_y = max(1, int(cell_sz_h * 0.04))
          margin_x = max(1, int(cell_sz_w * 0.04))

          cells: List[np.ndarray] = []
          for row in range(GRID_SIZE):
              for col in range(GRID_SIZE):
                  # Calculate cell boundaries with margin
                  y0 = row * cell_sz_h + margin_y
                  x0 = col * cell_sz_w + margin_x
                  y1 = (row + 1) * cell_sz_h - margin_y
                  x1 = (col + 1) * cell_sz_w - margin_x

                  # Ensure coordinates are valid and extract cell
                  if y0 < y1 and x0 < x1:
                      cell = rectified[y0:y1, x0:x1]
                      cells.append(cell)
                  else:
                      # Handle cases where margin is too large for cell size (should be rare)
                      # Fallback: extract cell without margin
                      y0_nomargin = row * cell_sz_h
                      x0_nomargin = col * cell_sz_w
                      y1_nomargin = (row + 1) * cell_sz_h
                      x1_nomargin = (col + 1) * cell_sz_w
                      cell = rectified[y0_nomargin:y1_nomargin, x0_nomargin:x1_nomargin]
                      # Add a blank cell if even no-margin extraction fails
                      if cell is None or cell.size == 0:
                           cell_shape = (cell_sz_h, cell_sz_w) + rectified.shape[2:] if rectified.ndim > 2 else (cell_sz_h, cell_sz_w)
                           cell = np.zeros(cell_shape, rectified.dtype) # Create blank cell
                      cells.append(cell)


          if len(cells) != GRID_SIZE * GRID_SIZE:
              print(f"[Splitter] Incorrect number of cells extracted: {len(cells)}")
              return None, rectified # Return None for cells but keep rectified image

          return cells, rectified


      def extract_cells_from_image(
          img_or_path,
          size: int = DEFAULT_RECTIFIED_SIZE,
          debug: bool = False
      ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray], Optional[np.ndarray]]:
          """
          High-level function: read image, find grid, rectify, and split into cells.
          Returns (cells, rectified_image, contour) or (None, None, None) on failure.
          """
          if isinstance(img_or_path, (str, Path)):
              img_path = str(img_or_path)
              if not Path(img_path).exists():
                  print(f"[Extractor] Image file not found: {img_path}")
                  return None, None, None
              img = cv2.imread(img_path)
              if img is None:
                  print(f"[Extractor] Failed to read image: {img_path}")
                  return None, None, None
          elif isinstance(img_or_path, np.ndarray):
              img = img_or_path.copy()
          else:
              print("[Extractor] Invalid input type (must be path or numpy array).")
              return None, None, None

          if img.size == 0:
              print("[Extractor] Input image is empty.")
              return None, None, None

          try:
              debug_dir = Path(f"debug_extract_{Path(img_path).stem}_{os.getpid()}") if debug and isinstance(img_or_path, (str, Path)) else None
              if debug and not debug_dir: debug_dir = Path(f"debug_extract_np_{os.getpid()}")

              # 1. Find Grid Contour
              contour = find_sudoku_grid_contour(img, debug_dir)
              if contour is None:
                  print("[Extractor] Failed to find Sudoku contour.")
                  return None, None, None # Contour finding failed

              # 2. Rectify Grid
              rectified = rectify_grid(img, contour, size=size)
              if rectified is None:
                  print("[Extractor] Failed to rectify grid.")
                  return None, None, contour # Rectification failed, return contour found

              if debug_dir:
                  cv2.imwrite(str(debug_dir / "06_rectified.png"), rectified)

              # 3. Split into Cells
              cells, rectified_output = split_into_cells(rectified)
              if cells is None:
                  print("[Extractor] Failed to split rectified grid into cells.")
                  # Return rectified image even if splitting fails, maybe useful for debugging
                  return None, rectified_output, contour

              if debug_dir:
                  # Save a montage of extracted cells
                  cell_h, cell_w = cells[0].shape[:2]
                  montage = np.zeros((GRID_SIZE * cell_h, GRID_SIZE * cell_w) + cells[0].shape[2:], dtype=cells[0].dtype)
                  for i, cell_img in enumerate(cells):
                      r, c = divmod(i, GRID_SIZE)
                      if cell_img.shape[:2] == (cell_h, cell_w): # Ensure shape consistency
                          montage[r*cell_h:(r+1)*cell_h, c*cell_w:(c+1)*cell_w] = cell_img
                  cv2.imwrite(str(debug_dir / "07_cells_montage.png"), montage)


              # Success
              return cells, rectified_output, contour

          except Exception as e:
              print(f"[Extractor] Unexpected error: {e}")
              import traceback
              traceback.print_exc()
              return None, None, None
      ```

      ```python 'digit_classifier.py'
      """
      SudokuBot – Digit Classifier (Full Grid Prediction)
      Version 2025-04-22

      Major Changes:
      - Model predicts all 81 cells from the rectified grid image at once.
      - Uses a Fully Convolutional Network (FCN) based on ResNet blocks.
      - Data generator yields full grid images and corresponding label grids.
      - Training data uses puzzles derived from valid, solvable Sudoku solutions.
      - Preprocessing and augmentation apply to the full grid image.
      """

      # ------------------------------------------------------------------ #
      # 1.  choose backend BEFORE importing keras
      # ------------------------------------------------------------------ #
      import os
      os.environ["KERAS_BACKEND"] = "torch"  # must be first – do NOT move

      # ------------------------------------------------------------------ #
      # 2.  std‑lib & 3rd‑party imports
      # ------------------------------------------------------------------ #
      import gc
      import random
      from pathlib import Path
      from typing import Callable, Generator, Optional, Tuple

      import cv2
      import numpy as np
      import torch
      import keras
      from keras import callbacks, layers, models, activations, regularizers

      # ------------------------------------------------------------------ #
      # 3.  project‑local imports
      # ------------------------------------------------------------------ #
      try:
          # Use the updated renderer and extractor
          from sudoku_renderer import SudokuRenderer, generate_and_save_test_example
          from digit_extractor import (
              GRID_SIZE,
              DEFAULT_RECTIFIED_SIZE, # Use the size defined in extractor
              extract_cells_from_image,
              rectify_grid,
              # split_into_cells is not directly needed by the classifier anymore
          )
          import sudoku_recogniser # Needed for printing grids in callback
      except ImportError as e:
          print(f"Error importing local modules: {e}")
          print("Please ensure sudoku_renderer.py, digit_extractor.py, and sudoku_recogniser.py are available.")
          # Provide dummy implementations or raise error if essential
          GRID_SIZE = 9
          DEFAULT_RECTIFIED_SIZE = 252
          class SudokuRenderer:
              def render_sudoku(self, allow_empty=True, grid_spec=None): return None, None, None
          def generate_and_save_test_example(force=False): return Path("dummy_test.png"), np.zeros((9,9), dtype=int)
          def extract_cells_from_image(path, size=252, debug=False): return [], np.zeros((size,size), dtype=np.uint8), None
          class sudoku_recogniser:
              FINAL_CONFIDENCE_THRESHOLD = 0.8
              @staticmethod
              def print_sudoku_grid(grid, confs=None, threshold=0.0): pass


      # ------------------------------------------------------------------ #
      # 4.  constants
      # ------------------------------------------------------------------ #
      MODEL_FILENAME = "sudoku_full_grid_classifier_fcn.keras" # New filename for the new model type
      # Input shape based on the rectified grid size from digit_extractor
      MODEL_INPUT_SHAPE = (DEFAULT_RECTIFIED_SIZE, DEFAULT_RECTIFIED_SIZE, 1) # Grayscale input
      NUM_CLASSES = 11  # digits 0-9 + "empty"
      EMPTY_LABEL = 10  # Label used for empty cells in the target data (y)

      # Training parameters
      EPOCHS = 25 # Might need more epochs for a larger model/task
      STEPS_PER_EPOCH = 100 # Adjust based on data generation speed and dataset size
      BATCH_SIZE = 16 # Reduced batch size due to larger input images
      VALIDATION_STEPS = 30

      # Type alias for data batches
      DataBatch = Tuple[np.ndarray, np.ndarray] # (batch_of_grids, batch_of_labels)

      # ------------------------------------------------------------------ #
      # 5.  data generator (simplified for full grids)
      # ------------------------------------------------------------------ #
      def sudoku_data_generator(
          renderer: SudokuRenderer,
          batch_size: int,
          preprocess_func: Callable[[np.ndarray], Optional[np.ndarray]],
          augment_func: Optional[Callable[[np.ndarray], np.ndarray]], # Optional augmentation
          input_shape: Tuple[int, int, int], # e.g., (252, 252, 1)
      ) -> Generator[DataBatch, None, None]:
          """
          Yields batches of (preprocessed_grid_image, target_label_grid).
          Generates valid Sudoku puzzles on the fly.
          """
          target_h, target_w, target_c = input_shape
          is_grayscale = (target_c == 1)

          batch_counter = 0
          while True:
              batch_x = np.zeros((batch_size, target_h, target_w, target_c), dtype="float32")
              batch_y = np.zeros((batch_size, GRID_SIZE, GRID_SIZE), dtype="int64")
              
              items_in_batch = 0
              while items_in_batch < batch_size:
                  # Generate a rendered Sudoku image and its ground truth puzzle grid (0 for empty)
                  img, gt_puzzle_grid, corners = renderer.render_sudoku(allow_empty=True) # Let renderer handle difficulty

                  if img is None or gt_puzzle_grid is None or corners is None:
                      # print("[Generator] Renderer failed, skipping.")
                      time.sleep(0.1) # Avoid busy-looping if renderer fails consistently
                      continue

                  # Rectify the grid using the known corners
                  # Use the target input size for rectification directly
                  rectified = rectify_grid(img, corners, size=target_h) # Assuming target_h == target_w
                  if rectified is None:
                      # print("[Generator] Rectification failed, skipping.")
                      continue

                  # Preprocess the entire rectified grid image
                  processed_grid = preprocess_func(rectified)
                  if processed_grid is None:
                      # print("[Generator] Preprocessing failed, skipping.")
                      continue

                  # Apply augmentation if provided (usually only for training)
                  if augment_func:
                      processed_grid = augment_func(processed_grid)

                  # Ensure the processed grid has the correct shape (H, W, C)
                  if processed_grid.shape != (target_h, target_w, target_c):
                       print(f"[Generator Warning] Processed grid shape mismatch: expected {(target_h, target_w, target_c)}, got {processed_grid.shape}. Skipping.")
                       continue


                  # Convert the ground truth puzzle grid (0 for empty) to the target format
                  # where empty cells are represented by EMPTY_LABEL (10)
                  target_labels = gt_puzzle_grid.copy()
                  target_labels[target_labels == 0] = EMPTY_LABEL

                  # Add to batch
                  batch_x[items_in_batch] = processed_grid
                  batch_y[items_in_batch] = target_labels
                  items_in_batch += 1

              # Yield the complete batch
              batch_counter += 1
              # Optional debug print
              # if batch_counter % 10 == 0:
              #     print(f"[Generator] Yielding batch {batch_counter}. Example label counts: {np.bincount(batch_y[0].flatten(), minlength=NUM_CLASSES)}")

              yield batch_x, batch_y
              # No need for explicit gc.collect() here usually, Python handles it.


      # ------------------------------------------------------------------ #
      # 6.  classifier object (handles full grid model)
      # ------------------------------------------------------------------ #
      class DigitClassifier:
          """
          Handles loading, training and inference of the FCN Sudoku grid classifier.
          """

          # -------------------------------------------------------------- #
          # constructor
          # -------------------------------------------------------------- #
          def __init__(
              self,
              model_path: Optional[str | Path] = None,
              training_required: bool = False,
          ) -> None:
              self.model_path = Path(model_path) if model_path else Path(MODEL_FILENAME)
              self.model: Optional[keras.Model] = None
              self._model_input_shape = MODEL_INPUT_SHAPE # e.g., (252, 252, 1)

              if not training_required and self.model_path.exists():
                  print(f"Attempting to load model from {self.model_path}...")
                  try:
                      self.model = keras.models.load_model(self.model_path)
                      # Check if loaded model's input shape matches config
                      # Keras models sometimes store input shape as (None, H, W, C)
                      loaded_shape = self.model.input_shape[1:]
                      if loaded_shape != self._model_input_shape:
                          print(f"[Warning] Loaded model input shape {loaded_shape} "
                                f"differs from expected {self._model_input_shape}. Mismatch may cause errors.")
                      print(f"Full-grid classifier model loaded successfully.")
                  except Exception as e:
                      print(f"[Error] Failed to load model from {self.model_path}: {e}")
                      print("Will build and train a new model if training is enabled.")
                      self.model = None # Ensure model is None if loading failed

              # Handle training_required flag
              if training_required and self.model is not None:
                   print("Training required: Ignoring previously loaded model and building a new one.")
                   self.model = None
              elif training_required and self.model is None:
                   print("Training required: Model will be built.")
              elif not training_required and self.model is None:
                   print("Model not found or failed to load, and training not required. Classifier is inactive.")


          # -------------------------------------------------------------- #
          # ResNet-style building block (same as before)
          # -------------------------------------------------------------- #
          def _residual_block(self, x, filters, strides=1, activation="relu"):
              """Basic residual block."""
              shortcut = x
              # Downsample shortcut if needed
              if strides > 1 or shortcut.shape[-1] != filters:
                  shortcut = layers.Conv2D(
                      filters, 1, strides=strides, use_bias=False, kernel_initializer="he_normal",
                      kernel_regularizer=regularizers.l2(1e-5) # Added slight L2 regularization
                  )(shortcut)
                  shortcut = layers.BatchNormalization()(shortcut)

              # First convolution
              y = layers.Conv2D(
                  filters, 3, strides=strides, padding="same", use_bias=False, kernel_initializer="he_normal",
                  kernel_regularizer=regularizers.l2(1e-5)
              )(x)
              y = layers.BatchNormalization()(y)
              y = layers.Activation(activation)(y)

              # Second convolution
              y = layers.Conv2D(
                  filters, 3, padding="same", use_bias=False, kernel_initializer="he_normal",
                  kernel_regularizer=regularizers.l2(1e-5)
              )(y)
              y = layers.BatchNormalization()(y)

              # Add shortcut
              y = layers.Add()([shortcut, y])
              y = layers.Activation(activation)(y)
              return y

          # -------------------------------------------------------------- #
          # backbone (FCN for full grid prediction)
          # -------------------------------------------------------------- #
          def _build_cnn_model(self) -> keras.Model:
              """Builds a Fully Convolutional Network (FCN) for grid prediction."""
              activation_func = "relu" # Or 'gelu'

              x_in = keras.Input(shape=self._model_input_shape) # e.g., (252, 252, 1)

              # --- Encoder Path (Downsampling) ---
              # Initial Conv Layer (Stem)
              # Use stride 3 to quickly reduce dimensions: 252 -> 84
              filters = 32
              x = layers.Conv2D(filters, 7, strides=3, padding="same", use_bias=False, kernel_initializer="he_normal")(x_in)
              x = layers.BatchNormalization()(x)
              x = layers.Activation(activation_func)(x)
              # x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # Optional extra pooling

              # Residual Blocks with increasing filters and downsampling
              # Block 1: 84x84 -> 84x84 (filters=32)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 2: 84x84 -> 28x28 (filters=64, stride=3)
              filters *= 2 # 64
              x = self._residual_block(x, filters, strides=3, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 3: 28x28 -> 28x28 (filters=128) - Stride 1 here
              filters *= 2 # 128
              x = self._residual_block(x, filters, strides=1, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # Block 4: 28x28 -> 14x14 (filters=256, stride=2) - Aiming for spatial dim > 9
              filters *= 2 # 256
              x = self._residual_block(x, filters, strides=2, activation=activation_func)
              x = self._residual_block(x, filters, strides=1, activation=activation_func)

              # --- Prediction Head ---
              # At this point, spatial dimension is 14x14. We need 9x9 output.
              # Option 1: Use a Conv layer with stride to reduce size (might lose info)
              # Option 2: Use Adaptive Pooling (if available/easy in Keras backend)
              # Option 3: Use Conv + Upsampling (more complex)
              # Option 4: Use a final Conv layer that implicitly handles the size reduction (less common)

              # Let's try a Conv2D layer designed to output the correct spatial dimensions.
              # We need to get closer to 9x9. Add another block?
              # Block 5: 14x14 -> 7x7 (filters=512, stride=2)
              # filters *= 2 # 512
              # x = self._residual_block(x, filters, strides=2, activation=activation_func)
              # x = self._residual_block(x, filters, strides=1, activation=activation_func)
              # Now spatial dim is 7x7. This is too small.

              # Backtrack: Let's stop at 14x14 (Block 4 output).
              # How to get to (9, 9, NUM_CLASSES)?
              # Use a 1x1 Conv to reduce filters, then maybe resize/crop or use specific conv?

              # Try a final Conv layer with appropriate kernel/padding to target 9x9.
              # Input to this layer is (None, 14, 14, 256)
              # Output needed is (None, 9, 9, NUM_CLASSES)

              # Use a 1x1 convolution to adjust the number of channels first
              x = layers.Conv2D(128, 1, padding='same', activation=activation_func, kernel_initializer='he_normal')(x)
              x = layers.BatchNormalization()(x)
              # Now (None, 14, 14, 128)

              # Use a final Conv2D layer to produce the output map.
              # A kernel size of 6 with valid padding on a 14x14 input gives (14-6+1) = 9x9 output.
              # Stride 1 is implicit.
              x = layers.Conv2D(
                  filters=NUM_CLASSES,
                  kernel_size=6, # Kernel size chosen to map 14x14 -> 9x9 with 'valid' padding
                  padding="valid", # 'valid' means no padding
                  activation=None, # Apply softmax separately across the class dimension
                  kernel_initializer='he_normal',
                  name="final_conv_logits"
              )(x)
              # Output shape should now be (None, 9, 9, NUM_CLASSES)

              # Apply Softmax activation across the last axis (classes)
              y_out = layers.Activation("softmax", name="output_softmax")(x)

              # Create the model
              model = models.Model(x_in, y_out, name="fcn_sudoku_grid")

              # Compile the model
              optimizer = keras.optimizers.Adam(learning_rate=5e-4) # Slightly higher LR?
              # Loss function suitable for integer targets and probability outputs
              loss = "sparse_categorical_crossentropy"
              # Metrics: Accuracy calculated per cell prediction
              metrics = ["accuracy"]

              model.compile(
                  optimizer=optimizer,
                  loss=loss,
                  metrics=metrics,
              )
              model.summary(line_length=120)
              return model

          # -------------------------------------------------------------- #
          # preprocessing (for full grid image)
          # -------------------------------------------------------------- #
          def _preprocess_grid_for_model(self, rectified_img: np.ndarray) -> Optional[np.ndarray]:
              """
              Prepares the rectified grid image for the FCN model.
              Resizes, converts to grayscale, normalizes to [0, 1], adds channel dim.
              """
              if rectified_img is None or rectified_img.size == 0:
                  return None

              target_h, target_w, target_c = self._model_input_shape
              is_grayscale = (target_c == 1)

              # Resize to target input size
              # Use INTER_AREA for shrinking, INTER_LINEAR for enlarging
              current_h, current_w = rectified_img.shape[:2]
              if current_h * current_w > target_h * target_w:
                  interp = cv2.INTER_AREA
              else:
                  interp = cv2.INTER_LINEAR
              resized = cv2.resize(rectified_img, (target_w, target_h), interpolation=interp)

              # Ensure correct number of channels (grayscale)
              if is_grayscale:
                  if resized.ndim == 3 and resized.shape[2] == 3:
                      processed = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)
                  elif resized.ndim == 3 and resized.shape[2] == 4:
                      processed = cv2.cvtColor(resized, cv2.COLOR_BGRA2GRAY)
                  elif resized.ndim == 2:
                      processed = resized
                  else:
                      print(f"[Preprocess Error] Unexpected image shape: {resized.shape}")
                      return None
                  # Add channel dimension: (H, W) -> (H, W, 1)
                  processed = processed[..., np.newaxis]
              else: # If model expected color input (target_c == 3)
                  if resized.ndim == 2: # Convert grayscale to BGR
                      processed = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)
                  elif resized.ndim == 3 and resized.shape[2] == 4: # Convert BGRA to BGR
                       processed = cv2.cvtColor(resized, cv2.COLOR_BGRA2BGR)
                  elif resized.ndim == 3 and resized.shape[2] == 3:
                       processed = resized # Already BGR
                  else:
                      print(f"[Preprocess Error] Unexpected image shape for color: {resized.shape}")
                      return None

              # Normalize to [0, 1] float32
              processed = processed.astype("float32") / 255.0

              return processed


          # ------------------------------------------------------------------ #
          # 7.1  augmentation (for full grid image)
          # ------------------------------------------------------------------ #
          def _augment_grid(self, grid_img: np.ndarray) -> np.ndarray:
              """Apply augmentations to the full grid image."""
              h, w = grid_img.shape[:2]
              augmented = grid_img.copy()

              # 1. Small Rotation
              if random.random() < 0.5:
                  angle = random.uniform(-8, 8) # Reduced angle for full grid
                  M_rot = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1.0)
                  augmented = cv2.warpAffine(augmented, M_rot, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0) # Black border

              # 2. Small Translation
              if random.random() < 0.5:
                  tx = random.uniform(-w * 0.03, w * 0.03) # Max 3% translation
                  ty = random.uniform(-h * 0.03, h * 0.03)
                  M_trans = np.float32([[1, 0, tx], [0, 1, ty]])
                  augmented = cv2.warpAffine(augmented, M_trans, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0)

              # 3. Brightness/Contrast Jitter
              if random.random() < 0.6:
                  alpha = random.uniform(0.85, 1.15) # Contrast
                  beta = random.uniform(-0.1, 0.1)   # Brightness
                  augmented = np.clip(augmented * alpha + beta, 0.0, 1.0)

              # 4. Gaussian Noise
              if random.random() < 0.3:
                  noise = np.random.normal(0, random.uniform(0.01, 0.05), augmented.shape)
                  augmented = np.clip(augmented + noise, 0.0, 1.0)

              # Ensure output is float32
              return augmented.astype("float32")


          # -------------------------------------------------------------- #
          # training
          # -------------------------------------------------------------- #
          def train(
              self,
              epochs: int = EPOCHS,
              steps_per_epoch: int = STEPS_PER_EPOCH,
              batch_size: int = BATCH_SIZE,
              validation_steps: int = VALIDATION_STEPS,
          ) -> None:
              """Trains the full-grid FCN model."""
              print(f"\n--- Training Full Grid Classifier ---")
              print(f"Epochs: {epochs}, Steps/Epoch: {steps_per_epoch}, Batch Size: {batch_size}")
              print(f"Input Shape: {self._model_input_shape}, Output: (9, 9, {NUM_CLASSES})")

              if self.model is None:
                  self.model = self._build_cnn_model()
              elif not isinstance(self.model, keras.Model):
                   print("[Error] self.model is not a valid Keras model. Cannot train.")
                   return

              # Prepare test example for callback
              try:
                  test_img_path, test_gt_grid = generate_and_save_test_example()
                  if test_img_path is None or test_gt_grid is None:
                       raise ValueError("Failed to generate/load test example.")
                  # Pass the classifier instance and the ground truth grid (0 for empty)
                  epoch_cb = EpochTestCallback(test_img_path, test_gt_grid, self)
              except Exception as e:
                  print(f"[Warning] Failed to set up EpochTestCallback: {e}. Callback disabled.")
                  epoch_cb = None

              # Create data generators
              # Training generator uses augmentation
              train_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  self._augment_grid, # Apply augmentation
                  self._model_input_shape,
              )
              # Validation generator does not use augmentation
              val_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  None, # No augmentation for validation
                  self._model_input_shape,
              )

              # Dump a batch of augmented training samples for visualization
              dump_dir = Path("dumped_training_grids")
              dump_dir.mkdir(exist_ok=True)
              try:
                  x_vis, y_vis = next(train_gen) # Get one batch from training gen
                  n_dump = min(4, x_vis.shape[0]) # Dump fewer, larger images
                  for i in range(n_dump):
                      # Convert float32 [0,1] -> uint8 [0,255]
                      img = (x_vis[i] * 255).astype(np.uint8)
                      # Maybe add label info to filename if needed, but grid is complex
                      cv2.imwrite(str(dump_dir / f"sample_grid_{i}.png"), img)
                  print(f"[Info] Dumped {n_dump} augmented training grid samples to {dump_dir}")
              except Exception as e:
                  print(f"[Warning] Could not dump training samples: {e}")


              # Callbacks
              cbs: list[callbacks.Callback] = [
                  callbacks.EarlyStopping(
                      monitor="val_accuracy", # Monitor validation accuracy (per-cell)
                      patience=10,          # Increased patience for larger model
                      restore_best_weights=True,
                      verbose=1,
                      mode='max'
                  ),
                  callbacks.ModelCheckpoint(
                      filepath=str(self.model_path), # Ensure path is string
                      monitor="val_accuracy",
                      save_best_only=True,
                      verbose=1,
                      mode='max'
                  ),
                  callbacks.ReduceLROnPlateau(
                      monitor="val_loss", # Reduce LR based on validation loss
                      factor=0.2,
                      patience=4,
                      min_lr=1e-7,
                      verbose=1,
                      mode='min' # Reduce LR when loss plateaus
                  ),
                  # Optional: TensorBoard
                  # callbacks.TensorBoard(log_dir='./logs_fcn', histogram_freq=1)
              ]
              if epoch_cb:
                  cbs.append(epoch_cb)

              # Start Training
              print("\nStarting model training...")
              history = self.model.fit(
                  train_gen,
                  epochs=epochs,
                  steps_per_epoch=steps_per_epoch,
                  validation_data=val_gen,
                  validation_steps=validation_steps,
                  callbacks=cbs,
                  verbose=1, # Use 1 for progress bar, 2 for one line per epoch
              )

              # Ensure the best model is loaded (EarlyStopping might restore, Checkpoint saves)
              if self.model_path.exists():
                   print(f"Reloading best weights from {self.model_path}...")
                   try:
                       # Use load_model if the whole architecture might change,
                       # or load_weights if only weights are saved/needed.
                       # ModelCheckpoint saves the whole model by default.
                       self.model = keras.models.load_model(self.model_path)
                       print("Best model reloaded.")
                   except Exception as e:
                       print(f"[Error] Failed to reload best model after training: {e}")
                       # The model instance might still hold the best weights if EarlyStopping restored them.

              print("\n--- Final Evaluation (using best weights) ---")
              # Use a fresh validation generator for final evaluation
              final_eval_gen = sudoku_data_generator(
                  SudokuRenderer(),
                  batch_size,
                  self._preprocess_grid_for_model,
                  None, # No augmentation
                  self._model_input_shape,
              )
              loss, acc = self.model.evaluate(
                  final_eval_gen,
                  steps=validation_steps * 2, # Evaluate on more validation steps
                  verbose=1,
              )
              print(f"Final Validation Loss: {loss:.5f}")
              print(f"Final Validation Accuracy (per cell): {acc:.5f}")

              # Explicitly save the final best model again (belt-and-suspenders)
              try:
                  print(f"Saving final best model to {self.model_path}")
                  self.model.save(self.model_path)
              except Exception as e:
                  print(f"[Error] Failed to save final model: {e}")

              del train_gen, val_gen, final_eval_gen, history
              gc.collect()
              print("--- Training Finished ---")


          # -------------------------------------------------------------- #
          # inference (for full grid)
          # -------------------------------------------------------------- #
          @torch.no_grad() # Keep decorator if using torch backend
          def recognise_grid(
              self,
              rectified_img: np.ndarray,
              confidence_threshold: float = 0.80, # Default threshold for accepting a digit
          ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
              """
              Recognises digits in a rectified Sudoku grid image using the FCN model.

              Args:
                  rectified_img: The (e.g., 252x252) rectified grid image (uint8 or float).
                  confidence_threshold: Minimum confidence to accept a digit prediction (1-9).

              Returns:
                  A tuple (predicted_grid, confidence_grid):
                  - predicted_grid: (9, 9) numpy array with recognised digits (1-9) or 0 for empty/uncertain.
                  - confidence_grid: (9, 9) numpy array with confidence scores for the predicted class in each cell.
                  Returns (None, None) if inference fails.
              """
              if self.model is None:
                  print("[Error] Recognise_grid called but model is not loaded.")
                  return None, None

              # 1. Preprocess the input grid image
              proc_grid = self._preprocess_grid_for_model(rectified_img)
              if proc_grid is None:
                  print("[Error] Preprocessing failed during recognition.")
                  return None, None # Indicate failure

              # 2. Add batch dimension: (H, W, C) -> (1, H, W, C)
              x = proc_grid[np.newaxis, ...]

              # 3. Predict using the Keras model
              try:
                  # Use training=False for inference (important for layers like BatchNorm, Dropout)
                  raw_output = self.model(x, training=False) # Shape: (1, 9, 9, NUM_CLASSES)
              except Exception as e:
                  print(f"[Error] Model prediction failed: {e}")
                  return None, None

              # 4. Convert to NumPy and remove batch dimension
              # Keras with torch backend might return torch tensors
              if hasattr(raw_output, 'cpu') and hasattr(raw_output, 'numpy'): # Check if it's a tensor with cpu/numpy methods
                   probs = raw_output.cpu().numpy()
              elif isinstance(raw_output, np.ndarray):
                   probs = raw_output
              else:
                   print(f"[Error] Unexpected model output type: {type(raw_output)}")
                   return None, None

              probs = probs[0] # Shape: (9, 9, NUM_CLASSES)

              # 5. Decode probabilities to predictions and confidences
              predicted_indices = np.argmax(probs, axis=-1) # Shape: (9, 9), contains indices 0-10
              confidences = np.max(probs, axis=-1)       # Shape: (9, 9), contains max probability

              # 6. Create the final output grid
              # Initialize with zeros (representing empty/uncertain)
              final_grid = np.zeros((GRID_SIZE, GRID_SIZE), dtype=int)

              # Iterate through each cell prediction
              for r in range(GRID_SIZE):
                  for c in range(GRID_SIZE):
                      pred_idx = predicted_indices[r, c]
                      conf = confidences[r, c]

                      # Check if the prediction is a digit (1-9), not EMPTY_LABEL (10),
                      # and if the confidence meets the threshold.
                      if pred_idx != EMPTY_LABEL and conf >= confidence_threshold:
                          final_grid[r, c] = pred_idx # Assign the predicted digit (1-9)
                      # Otherwise, leave it as 0 (empty/uncertain)

              return final_grid, confidences


      # ------------------------------------------------------------------ #
      # 8.  epoch‑end callback (adapted for full grid)
      # ------------------------------------------------------------------ #
      class EpochTestCallback(callbacks.Callback):
          def __init__(
              self,
              test_img_path: Path | str,
              gt_puzzle_grid: np.ndarray, # Ground truth puzzle (0 for empty)
              classifier: "DigitClassifier",
              frequency: int = 1,
          ) -> None:
              super().__init__()
              self.frequency = max(1, frequency)
              self.gt_puzzle_grid = gt_puzzle_grid # Shape (9, 9), 0 for empty
              self.classifier = classifier
              self.test_img_path = test_img_path
              self.preprocessed_test_grid = None # To store the single preprocessed grid

          def on_train_begin(self, logs=None):
              """Preprocess the test image once before training starts."""
              print("\n[Callback] Preprocessing test example for epoch-end evaluation...")
              try:
                  # Extract the rectified grid from the test image file
                  # We don't need the individual cells here, just the rectified image
                  _, rectified_test_img, _ = extract_cells_from_image(
                      self.test_img_path,
                      size=self.classifier._model_input_shape[0], # Use model's input size
                      debug=False
                  )

                  if rectified_test_img is None:
                      print("[Callback Error] Failed to extract rectified grid from test image.")
                      self.preprocessed_test_grid = None
                      return

                  # Preprocess the rectified grid using the classifier's method
                  self.preprocessed_test_grid = self.classifier._preprocess_grid_for_model(rectified_test_img)

                  if self.preprocessed_test_grid is None:
                      print("[Callback Error] Preprocessing of the test grid failed.")
                  else:
                      print(f"[Callback] Test grid preprocessed successfully ({self.preprocessed_test_grid.shape}).")

              except Exception as e:
                  print(f"[Callback Error] Failed during test example setup: {e}")
                  self.preprocessed_test_grid = None

          def on_epoch_end(self, epoch, logs=None):
              # Check if preprocessing was successful and if it's the right epoch
              if self.preprocessed_test_grid is None or (epoch + 1) % self.frequency != 0:
                  return

              if not hasattr(self.model, 'predict'):
                   print("[Callback Error] Model object in callback does not have predict method.")
                   return

              print(f"\n--- Epoch {epoch+1} Test Example Evaluation ---")
              try:
                  # Add batch dimension for prediction
                  x_test = self.preprocessed_test_grid[np.newaxis, ...]

                  # Predict using the model being trained
                  raw_output = self.model.predict(x_test, verbose=0) # Shape: (1, 9, 9, NUM_CLASSES)

                  # Decode the output (similar to recognise_grid)
                  probs = raw_output[0] # Remove batch dim -> (9, 9, NUM_CLASSES)
                  pred_indices = np.argmax(probs, axis=-1) # (9, 9) indices 0-10
                  confs = np.max(probs, axis=-1)       # (9, 9) confidences

                  # Apply thresholding for display (use a slightly lower threshold maybe)
                  display_threshold = 0.7 # Threshold for visualization purposes
                  display_grid = np.zeros_like(pred_indices, dtype=int)
                  for r in range(GRID_SIZE):
                      for c in range(GRID_SIZE):
                          idx = pred_indices[r, c]
                          cf = confs[r, c]
                          if idx != EMPTY_LABEL and cf >= display_threshold:
                              display_grid[r, c] = idx

                  print("Ground Truth Puzzle:")
                  # print_sudoku_grid expects 0 for empty
                  sudoku_recogniser.print_sudoku_grid(self.gt_puzzle_grid)

                  print(f"Prediction (Thresholded @ {display_threshold:.2f}):")
                  sudoku_recogniser.print_sudoku_grid(display_grid, confs, threshold=display_threshold)

                  # --- Calculate Accuracy ---
                  # Compare prediction indices directly with the GT grid converted to use EMPTY_LABEL
                  gt_labels = self.gt_puzzle_grid.copy()
                  gt_labels[gt_labels == 0] = EMPTY_LABEL # Convert GT to use 10 for empty

                  correct_cells = (pred_indices == gt_labels).sum()
                  total_cells = GRID_SIZE * GRID_SIZE
                  accuracy = correct_cells / total_cells
                  print(f"Test Example Accuracy (Raw Prediction vs GT Labels): {correct_cells}/{total_cells} = {accuracy:.4f}")
                  print("--- End Epoch Test ---\n")

              except Exception as e:
                  print(f"[Callback Error] Failed during prediction or display: {e}")
                  import traceback
                  traceback.print_exc()


      # ------------------------------------------------------------------ #
      # 9.  CLI helper
      # ------------------------------------------------------------------ #
      if __name__ == "__main__":
          # Set to True to force retraining even if a model file exists
          FORCE_TRAIN = False

          model_file = Path(MODEL_FILENAME)
          train_needed = FORCE_TRAIN or not model_file.exists()

          if FORCE_TRAIN and model_file.exists():
              print(f"FORCE_TRAIN is True. Deleting existing model: {model_file}")
              try:
                  model_file.unlink()
                  train_needed = True
              except OSError as e:
                  print(f"Error deleting existing model: {e}. Proceeding might use old model if loading works.")
                  # Decide whether to exit or continue
                  # exit(1)

          # Instantiate the classifier. It will try to load if train_needed is False.
          clf = DigitClassifier(model_path=model_file, training_required=train_needed)

          # Train if needed
          if train_needed:
              if clf.model is not None:
                   print("[Warning] Model was loaded despite train_needed=True? Retraining anyway.")
                   clf.model = None # Ensure model is rebuilt
              print("Starting training process...")
              clf.train(epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, batch_size=BATCH_SIZE)
              # After training, the best model should be saved and reloaded by the train method.
              if clf.model is None:
                   print("[Error] Training finished, but model is still None. Cannot proceed.")
                   exit(1)
          elif clf.model is None:
               print("[Error] Model loading failed, and training was not requested. Cannot proceed.")
               exit(1)
          else:
               print("Model loaded successfully. Skipping training.")


          # --- Perform Sanity Check using the Test Example ---
          if clf.model:
              print("\n--- Sanity Check: Recognising the Test Example ---")
              test_img_path_str, test_gt_grid = generate_and_save_test_example() # Get path and GT

              if test_img_path_str is None or test_gt_grid is None:
                  print("Failed to load test example for sanity check.")
              else:
                  test_img_path = Path(test_img_path_str)
                  print(f"Loading test image: {test_img_path}")
                  # Extract rectified grid from the test image
                  _, rectified_test, _ = extract_cells_from_image(
                      test_img_path,
                      size=clf._model_input_shape[0], # Use model's input size
                      debug=False
                  )

                  if rectified_test is None:
                      print("Failed to extract rectified grid from test image for sanity check.")
                  else:
                      print("Running recognise_grid on the test image...")
                      # Use a reasonable confidence threshold for the check
                      pred_grid, conf_grid = clf.recognise_grid(rectified_test, confidence_threshold=0.75)

                      if pred_grid is None:
                          print("Recognition failed during sanity check.")
                      else:
                          print("\nGround Truth Puzzle:")
                          sudoku_recogniser.print_sudoku_grid(test_gt_grid)

                          print("Recognised Grid (Thresholded @ 0.75):")
                          sudoku_recogniser.print_sudoku_grid(pred_grid, conf_grid, threshold=0.75)

                          # Calculate accuracy for the sanity check
                          correct_cells = (pred_grid == test_gt_grid).sum()
                          # Account for empty cells being 0 in both GT and prediction (correctly)
                          # Non-empty cells must match exactly
                          correct_non_empty = ((pred_grid == test_gt_grid) & (test_gt_grid != 0)).sum()
                          correct_empty = ((pred_grid == 0) & (test_gt_grid == 0)).sum()
                          total_correct = correct_non_empty + correct_empty

                          total_cells = GRID_SIZE * GRID_SIZE
                          accuracy = total_correct / total_cells
                          print(f"\nSanity Check Accuracy: {total_correct}/{total_cells} = {accuracy:.4f}")
          else:
              print("\nSanity check skipped: No model available.")

          print("\nScript finished.")
      ```

      ```python 'sudoku_recogniser.py'
      """
      Command-line utility to detect a Sudoku grid in an image and recognise its digits
      using the full-grid classifier.
      """

      from __future__ import annotations

      import sys
      import time
      from pathlib import Path
      from typing import Tuple, Optional

      import cv2
      import numpy as np

      # Import the updated classifier and extractor
      import digit_classifier
      from digit_extractor import GRID_SIZE, DEFAULT_RECTIFIED_SIZE, extract_cells_from_image

      # Confidence threshold for final acceptance of a recognised digit (1-9)
      # This can be tuned based on model performance.
      FINAL_CONFIDENCE_THRESHOLD = 0.75 # Adjusted slightly


      def print_sudoku_grid(
          grid: np.ndarray,
          conf: Optional[np.ndarray] = None,
          threshold: float = FINAL_CONFIDENCE_THRESHOLD
      ) -> None:
          """
          Nicely print a 9×9 Sudoku grid.
          Marks digits below the threshold with '?' if confidences are provided.
          Expects grid values 0-9, where 0 is empty.
          """
          grid = np.asarray(grid)
          if grid.shape != (GRID_SIZE, GRID_SIZE):
              print(f"[print_sudoku_grid] Invalid grid shape: {grid.shape}")
              return

          print("-" * 25) # Top border
          for r in range(GRID_SIZE):
              if r > 0 and r % 3 == 0:
                  print("|-------+-------+-------|") # Separator line

              line = ["|"] # Start of row
              for c in range(GRID_SIZE):
                  digit = grid[r, c]
                  token = ""
                  if digit == 0:
                      token = "." # Represent empty cell
                  else:
                      token = str(digit)
                      # If confidence is provided and below threshold, mark as uncertain
                      if conf is not None and conf.shape == (GRID_SIZE, GRID_SIZE) and conf[r, c] < threshold:
                          token = "?"

                  line.append(f" {token} ") # Add token with spacing

                  if (c + 1) % 3 == 0:
                      line.append("|") # Add column separator

              print("".join(line)) # Print the row
          print("-" * 25) # Bottom border
          print() # Add a blank line after the grid


      def display_results_on_image(
          rectified: Optional[np.ndarray],
          grid: np.ndarray,
          conf: Optional[np.ndarray] = None,
          threshold: float = FINAL_CONFIDENCE_THRESHOLD
      ) -> Optional[np.ndarray]:
          """
          Draw recognised digits (above threshold) onto the rectified grid image.
          """
          if rectified is None:
              print("[Display] No rectified image provided.")
              return None

          # Ensure image is BGR for drawing colors
          img_display = (
              cv2.cvtColor(rectified, cv2.COLOR_GRAY2BGR)
              if rectified.ndim == 2 else rectified.copy()
          )
          h, w = img_display.shape[:2]
          if h == 0 or w == 0: return None # Invalid image dimensions

          cell_h, cell_w = h // GRID_SIZE, w // GRID_SIZE
          if cell_h == 0 or cell_w == 0: return img_display # Cannot draw if cells are too small

          # Choose font properties
          font_face = cv2.FONT_HERSHEY_SIMPLEX
          font_scale_base = min(cell_h, cell_w) / 35.0 # Scale font based on cell size
          font_thickness = max(1, int(font_scale_base * 1.5))

          for r in range(GRID_SIZE):
              for c in range(GRID_SIZE):
                  digit = grid[r, c]
                  confidence = conf[r, c] if conf is not None else 1.0 # Assume high conf if not provided

                  # Only draw digits that are not empty and meet the confidence threshold
                  if digit != 0 and confidence >= threshold:
                      text = str(digit)

                      # Calculate text size to center it
                      (text_w, text_h), baseline = cv2.getTextSize(text, font_face, font_scale_base, font_thickness)

                      # Calculate center position of the cell
                      center_x = c * cell_w + cell_w // 2
                      center_y = r * cell_h + cell_h // 2

                      # Calculate bottom-left corner of the text for centering
                      text_x = center_x - text_w // 2
                      text_y = center_y + text_h // 2

                      # Draw the text
                      cv2.putText(
                          img_display,
                          text,
                          (text_x, text_y),
                          font_face,
                          font_scale_base,
                          (0, 200, 0), # Green color for recognised digits
                          font_thickness,
                          cv2.LINE_AA # Anti-aliased text
                      )
                  # Optional: Draw uncertain digits differently (e.g., red '?')
                  # elif digit != 0 and conf is not None and confidence < threshold:
                  #     text = "?"
                  #     (text_w, text_h), baseline = cv2.getTextSize(text, font_face, font_scale_base, font_thickness)
                  #     center_x = c * cell_w + cell_w // 2
                  #     center_y = r * cell_h + cell_h // 2
                  #     text_x = center_x - text_w // 2
                  #     text_y = center_y + text_h // 2
                  #     cv2.putText(img_display, text, (text_x, text_y), font_face, font_scale_base, (0, 0, 255), font_thickness, cv2.LINE_AA)


          return img_display


      def recognise_sudoku(
          img_path: Path,
          classifier: digit_classifier.DigitClassifier
      ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:
          """
          Extract rectified grid and run the full-grid classifier.

          Returns:
              Tuple of (predicted_grid, confidence_grid, rectified_image).
              predicted_grid: (9, 9) int array, 0 for empty/uncertain.
              confidence_grid: (9, 9) float array of confidences.
              rectified_image: The (e.g., 252x252) rectified image.
              Returns (None, None, None) on failure.
          """
          print(f"Processing {img_path.name}...")
          start_time = time.time()

          # 1. Extract the rectified grid image
          # We don't need individual cells from the extractor anymore
          # Use the input size expected by the classifier model
          rectified_size = classifier._model_input_shape[0]
          _, rectified_img, _ = extract_cells_from_image(
              img_path,
              size=rectified_size,
              debug=False # Set to True for extraction debugging images
          )

          if rectified_img is None:
              print("❌ Failed to extract or rectify the Sudoku grid.")
              return None, None, None
          print(f"✅ Grid extracted and rectified ({time.time() - start_time:.2f}s)")
          extract_time = time.time()

          # 2. Recognise digits using the full-grid classifier
          print("🧠 Running grid recognition model...")
          predicted_grid, confidence_grid = classifier.recognise_grid(
              rectified_img,
              confidence_threshold=FINAL_CONFIDENCE_THRESHOLD
          )

          if predicted_grid is None or confidence_grid is None:
              print("❌ Model recognition failed.")
              return None, None, rectified_img # Return rectified image even if recognition fails

          elapsed_time = time.time() - start_time
          print(f"✅ Recognition complete ({time.time() - extract_time:.2f}s)")
          print(f"⏱️ Total time: {elapsed_time:.2f}s")

          return predicted_grid, confidence_grid, rectified_img


      def main() -> None:
          if len(sys.argv) < 2:
              print("Usage: python sudoku_recogniser.py <image_path> [--no-train]")
              print("  <image_path>: Path to the Sudoku image file.")
              print("  --no-train: Optional flag to prevent training if the model is missing.")
              sys.exit(0)

          img_path = Path(sys.argv[1])
          if not img_path.is_file():
              print(f"❌ Error: Image file not found at '{img_path}'")
              sys.exit(1)

          # Check for --no-train flag
          force_no_train = "--no-train" in sys.argv

          # Instantiate the classifier
          # It will try to load the model. Training is required if the model file
          # doesn't exist, unless --no-train is specified.
          model_exists = Path(digit_classifier.MODEL_FILENAME).exists()
          training_required = not model_exists

          if training_required and force_no_train:
              print("Model file not found, but --no-train specified. Exiting.")
              sys.exit(1)
          elif training_required:
              print(f"⚠️ Model file '{digit_classifier.MODEL_FILENAME}' not found.")
              print("Initiating training process...")
              classifier = digit_classifier.DigitClassifier(training_required=True)
              classifier.train() # Use default training parameters from classifier script
              # Check if model was successfully created after training
              if classifier.model is None:
                   print("❌ Training failed to produce a model. Exiting.")
                   sys.exit(1)
              print("✅ Training complete. Proceeding with recognition...")
          else:
              # Model exists or --no-train was used with existing model
              classifier = digit_classifier.DigitClassifier(training_required=False)
              if classifier.model is None:
                   print(f"❌ Failed to load existing model '{digit_classifier.MODEL_FILENAME}'. Exiting.")
                   sys.exit(1)
              print(f"✅ Model '{digit_classifier.MODEL_FILENAME}' loaded.")


          # Recognise the Sudoku in the input image
          try:
              grid, conf, rectified = recognise_sudoku(img_path, classifier)

              if grid is None or conf is None:
                  print("\n❌ Sudoku recognition process failed.")
                  # Rectified might still exist, show it if possible
                  if rectified is not None:
                       cv2.imshow("Failed Extraction/Rectification", rectified)
                       cv2.waitKey(0)
                  sys.exit(1)

              # Print the recognised grid to the console
              print("\n--- Recognised Sudoku Grid ---")
              print_sudoku_grid(grid, conf, threshold=FINAL_CONFIDENCE_THRESHOLD)

              # Display the rectified image with recognised digits overlaid
              result_img = display_results_on_image(rectified, grid, conf, threshold=FINAL_CONFIDENCE_THRESHOLD)
              if result_img is not None:
                  print("ℹ️ Displaying recognised grid on image. Press any key to close.")
                  cv2.imshow("Sudoku Recognition Result", result_img)
                  cv2.waitKey(0)
              else:
                  print("ℹ️ Could not generate result image.")

          except Exception as e:
              print(f"\n❌ An unexpected error occurred: {e}")
              import traceback
              traceback.print_exc()
              sys.exit(1)
          finally:
              cv2.destroyAllWindows() # Ensure any OpenCV windows are closed


      if __name__ == "__main__":
          main()
      ```
    metadata:
  - user: |
      Identified target file 'sudoku_renderer.py' on fence open line 1:
      ```python 'sudoku_renderer.py'
      Identified target file 'digit_extractor.py' on fence open line 2:
      ```python 'digit_extractor.py'
      Identified target file 'digit_classifier.py' on fence open line 3:
      ```python 'digit_classifier.py'
      Identified target file 'sudoku_recogniser.py' on fence open line 4:
      ```python 'sudoku_recogniser.py'
      Found 4 code blocks.
      Matching against available files:
        1: sudoku_renderer.py
        2: digit_classifier.py
        3: digit_extractor.py
        4: sudoku_recogniser.py
      --- Phase 1: Processing explicit file paths in fences ---
      Assigned block to sudoku_renderer.py based on explicit fence path.
      Assigned block to digit_extractor.py based on explicit fence path.
      Assigned block to digit_classifier.py based on explicit fence path.
      Assigned block to sudoku_recogniser.py based on explicit fence path.
      Remaining unassigned blocks: 0, Available files: 0
      --- Phase 6: Applying changes to assigned files ---
      Successfully updated file: sudoku_renderer.py
      Successfully updated file: digit_extractor.py
      Successfully updated file: digit_classifier.py
      Successfully updated file: sudoku_recogniser.py
    metadata:
...
