local_system:
    attached_files:
        - digit_classifier.py
    conversation_file:
    compile_command:
    initial_file_contents:
        digit_classifier.py:
            > """
            > SudokuBot – digit classifier
            > Fixed version 2025‑04‑20
            >
            > Major fixes
            > • data generator now really yields balanced batches
            > • preprocessing is tolerant – almost never rejects a cell
            > """
            >
            > # ------------------------------------------------------------------ #
            > # 1.  choose backend BEFORE importing keras
            > # ------------------------------------------------------------------ #
            > import os
            >
            > os.environ["KERAS_BACKEND"] = "torch"  # must be first – do NOT move
            >
            > # ------------------------------------------------------------------ #
            > # 2.  std‑lib & 3rd‑party imports
            > # ------------------------------------------------------------------ #
            > import gc
            > import random
            > from pathlib import Path
            > from typing import Callable, Generator, Optional, Tuple
            >
            > import cv2
            > import numpy as np
            > import torch
            > import keras
            > from keras import callbacks, layers, models, activations
            >
            > # ------------------------------------------------------------------ #
            > # 3.  project‑local imports
            > # ------------------------------------------------------------------ #
            > from sudoku_renderer import SudokuRenderer, generate_and_save_test_example
            > from digit_extractor import (
            >     GRID_SIZE,
            >     extract_cells_from_image,
            >     rectify_grid,
            >     split_into_cells,
            > )
            > import sudoku_recogniser
            >
            > # ------------------------------------------------------------------ #
            > # 4.  constants
            > # ------------------------------------------------------------------ #
            > MODEL_FILENAME = "sudoku_digit_classifier_cnn.keras"
            >
            > MODEL_INPUT_SHAPE = (28, 28, 1)
            > NUM_CLASSES = 11  # digits 0‑9 + “empty”
            > EMPTY_LABEL = 10
            >
            > TARGET_CELL_CONTENT_SIZE = 24          # preprocessing
            > TARGET_DIGIT_RATIO = 1.5               # 60 % digits / 40 % empty
            >
            > EPOCHS = 10
            > STEPS_PER_EPOCH = 100
            > BATCH_SIZE = 256
            > VALIDATION_STEPS = 50
            >
            > DataBatch = Tuple[np.ndarray, np.ndarray]
            >
            > # ------------------------------------------------------------------ #
            > # 5.  balanced data generator (fixed)
            > # ------------------------------------------------------------------ #
            > def sudoku_data_generator(
            >     renderer: SudokuRenderer,
            >     batch_size: int,
            >     preprocess_func: Callable[[np.ndarray], Optional[np.ndarray]],
            >     input_size: Tuple[int, int, int],
            >     target_digit_ratio: float = TARGET_DIGIT_RATIO,
            > ) -> Generator[DataBatch, None, None]:
            >     """
            >     Yield *balanced* batches of (cell, label).
            >
            >     The function never gives up early – it keeps sampling Sudokus until the
            >     required number of digit and empty cells has been collected.
            >     """
            >     total_cells = GRID_SIZE * GRID_SIZE
            >     want_digits = int(batch_size * target_digit_ratio / (1 + target_digit_ratio))
            >     want_empty = batch_size - want_digits
            >     in_h, in_w = input_size[:2]
            >
            >     batch_counter = 0
            >     while True:
            >         xs, ys = [], []
            >         n_dig = n_emp = 0
            >
            >         while n_dig < want_digits or n_emp < want_empty:
            >             img, gt_grid, corners = renderer.render_sudoku(allow_empty=True)
            >             if img is None or corners is None:
            >                 continue
            >             rectified = rectify_grid(img, corners)
            >             if rectified is None:
            >                 continue
            >             cells, _ = split_into_cells(rectified)
            >             if len(cells) != total_cells:
            >                 continue
            >
            >             # iterate shuffled cell indices
            >             idxs = list(range(total_cells))
            >             random.shuffle(idxs)
            >
            >             for idx in idxs:
            >                 if n_dig >= want_digits and n_emp >= want_empty:
            >                     break
            >
            >                 cell = cells[idx]
            >                 label = EMPTY_LABEL if gt_grid.flatten()[idx] == 0 else gt_grid.flatten()[idx]
            >                 proc = preprocess_func(cell)
            >                 if proc is None:                       # should be rare now
            >                     continue
            >
            >                 # balance bookkeeping
            >                 if label == EMPTY_LABEL:
            >                     if n_emp >= want_empty:
            >                         continue
            >                     n_emp += 1
            >                 else:
            >                     if n_dig >= want_digits:
            >                         continue
            >                     n_dig += 1
            >
            >                 xs.append(proc)
            >                 ys.append(label)
            >
            >         # at this point we have a perfectly balanced batch
            >         x_arr = np.asarray(xs, dtype="float32")[..., np.newaxis]
            >         y_arr = np.asarray(ys, dtype="int64")
            >         p = np.random.permutation(batch_size)
            >         batch_counter += 1
            >
            >         # optional histo print for debugging
            >         if (
            >             os.environ.get("SUDOKU_DEBUG_GENERATOR", "0") == "1"
            >             and batch_counter % 500 == 0
            >         ):
            >             print("label histogram:", np.bincount(y_arr, minlength=NUM_CLASSES))
            >
            >         yield x_arr[p], y_arr[p]
            >         del xs, ys, x_arr, y_arr
            >         gc.collect()
            >
            >
            > # ------------------------------------------------------------------ #
            > # 6.  layer helpers
            > # ------------------------------------------------------------------ #
            > def _norm():
            >     return layers.GroupNormalization()
            >
            >
            > def activation(x):
            >     return activations.gelu(x, approximate=True)
            >
            >
            > # ------------------------------------------------------------------ #
            > # 7.  classifier object
            > # ------------------------------------------------------------------ #
            > class DigitClassifier:
            >     """
            >     Handles loading, training and inference of the CNN digit classifier.
            >     """
            >
            >     # -------------------------------------------------------------- #
            >     # constructor
            >     # -------------------------------------------------------------- #
            >     def __init__(
            >         self,
            >         model_path: Optional[str | Path] = None,
            >         training_required: bool = False,
            >     ) -> None:
            >         self.model_path = Path(model_path) if model_path else Path(MODEL_FILENAME)
            >         self.model: Optional[keras.Model] = None
            >         self._model_input_size = MODEL_INPUT_SHAPE[:2]
            >
            >         if not training_required and self.model_path.exists():
            >             try:
            >                 self.model = keras.models.load_model(self.model_path)
            >                 if self.model.input_shape[1:3] != self._model_input_size:
            >                     print("[Warning] stored model input size differs from expected")
            >                 print("Digit‑classifier model loaded from disk.")
            >             except Exception as e:
            >                 print(f"[Error] failed to load model – will train from scratch ({e})")
            >
            >     # -------------------------------------------------------------- #
            >     # backbone
            >     # -------------------------------------------------------------- #
            >     def _build_cnn_model(self) -> keras.Model:
            >         """Simple CNN."""
            >         cfg = [32, 32, 64, 64, 96, 96, 96, 128, 128, 128, 128, 192, 192]
            >         pool_at = {1, 3, 6, 10}
            >
            >         x_in = keras.Input(shape=MODEL_INPUT_SHAPE)
            >         x = x_in
            >         for i, f in enumerate(cfg):
            >             x = layers.Conv2D(f, 3, padding="same", use_bias=False)(x)
            >             x = layers.Activation(activation)(x)
            >             x = _norm()(x)
            >             if i in pool_at:
            >                 x = layers.MaxPooling2D(2)(x)
            >
            >         # 1×1 bottleneck
            >         x = layers.Conv2D(256, 1, use_bias=False)(x)
            >         x = layers.Activation(activation)(x)
            >         x = _norm()(x)
            >
            >         # classifier head
            >         x = layers.GlobalAveragePooling2D()(x)
            >         x = layers.Dense(128, activation=activation)(x)
            >         x = layers.Dense(64, activation=activation)(x)
            >         y_out = layers.Dense(NUM_CLASSES, activation="softmax")(x)
            >
            >         model = models.Model(x_in, y_out, name="simplenet_digits_ln")
            >         model.compile(
            >             optimizer=keras.optimizers.Adam(3e-4),
            >             loss="sparse_categorical_crossentropy",
            >             metrics=["accuracy"],
            >         )
            >         model.summary()
            >         return model
            >
            >     # -------------------------------------------------------------- #
            >     # preprocessing (fixed – tolerant)
            >     # -------------------------------------------------------------- #
            >     def _preprocess_cell_for_model(self, cell: np.ndarray) -> Optional[np.ndarray]:
            >         """
            >         Convert raw cell → 28×28 float32 in [0,1].
            >         Never raises; returns None only if `cell` itself is invalid.
            >         """
            >         if cell is None or cell.size < 10:
            >             return None
            >
            >         gray = (
            >             cv2.cvtColor(cell, cv2.COLOR_BGR2GRAY).astype("uint8")
            >             if cell.ndim == 3
            >             else cell.astype("uint8")
            >         )
            >
            >         # adaptive threshold, fall back to simple Otsu if OpenCV complains
            >         try:
            >             blk = max(3, min(gray.shape) // 4) | 1
            >             thresh = cv2.adaptiveThreshold(
            >                 gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, blk, 7
            >             )
            >         except cv2.error:
            >             _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            >
            >         pts = cv2.findNonZero(thresh)
            >         if pts is None:  # looks empty – return black canvas
            >             return np.zeros(self._model_input_size, dtype="float32")
            >
            >         x, y, w, h = cv2.boundingRect(pts)
            >         if w == 0 or h == 0:
            >             return np.zeros(self._model_input_size, dtype="float32")
            >
            >         roi = thresh[y : y + h, x : x + w]
            >
            >         scale = min(
            >             TARGET_CELL_CONTENT_SIZE / max(1, w),
            >             TARGET_CELL_CONTENT_SIZE / max(1, h),
            >         )
            >         new_w = max(1, int(round(w * scale)))
            >         new_h = max(1, int(round(h * scale)))
            >         resized = cv2.resize(roi, (new_w, new_h), interpolation=cv2.INTER_AREA)
            >
            >         canvas = np.zeros(self._model_input_size, np.uint8)
            >         top = (self._model_input_size[0] - new_h) // 2
            >         left = (self._model_input_size[1] - new_w) // 2
            >         canvas[top : top + new_h, left : left + new_w] = resized
            >
            >         return canvas.astype("float32") / 255.0
            >
            >     # -------------------------------------------------------------- #
            >     # training
            >     # -------------------------------------------------------------- #
            >     def train(
            >         self,
            >         epochs: int = EPOCHS,
            >         steps_per_epoch: int = STEPS_PER_EPOCH,
            >         batch_size: int = BATCH_SIZE,
            >         validation_steps: int = VALIDATION_STEPS,
            >     ) -> None:
            >         print(f"\nTraining: epochs={epochs}  batch={batch_size}")
            >         try:
            >             test_img, test_gt = generate_and_save_test_example()
            >             epoch_cb = EpochTestCallback(test_img, test_gt, self)
            >         except Exception as e:
            >             print(f"[Warning] epoch‑callback disabled ({e})")
            >             epoch_cb = None
            >
            >         train_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >         val_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >
            >         if self.model is None:
            >             self.model = self._build_cnn_model()
            >
            >         cbs: list[callbacks.Callback] = [
            >             callbacks.EarlyStopping(
            >                 monitor="val_loss",
            >                 patience=5,
            >                 restore_best_weights=True,
            >                 verbose=1,
            >             ),
            >             callbacks.ModelCheckpoint(
            >                 filepath=self.model_path,
            >                 monitor="val_loss",
            >                 save_best_only=True,
            >                 verbose=1,
            >             ),
            >             callbacks.ReduceLROnPlateau(
            >                 monitor="val_loss",
            >                 factor=0.2,
            >                 patience=3,
            >                 min_lr=1e-6,
            >                 verbose=1,
            >             ),
            >         ]
            >         if epoch_cb and epoch_cb.preprocessed is not None:
            >             cbs.append(epoch_cb)
            >
            >         self.model.fit(
            >             train_gen,
            >             epochs=epochs,
            >             steps_per_epoch=steps_per_epoch,
            >             validation_data=val_gen,
            >             validation_steps=validation_steps,
            >             callbacks=cbs,
            >             verbose=1,
            >         )
            >
            >         print("\nFinal evaluation:")
            >         loss, acc = self.model.evaluate(
            >             sudoku_data_generator(
            >                 SudokuRenderer(),
            >                 batch_size,
            >                 self._preprocess_cell_for_model,
            >                 MODEL_INPUT_SHAPE,
            >             ),
            >             steps=validation_steps,
            >             verbose=1,
            >         )
            >         print(f"val_loss={loss:.4f}  val_acc={acc:.4f}")
            >
            >         self.model.save(self.model_path)
            >         del train_gen, val_gen
            >         gc.collect()
            >
            >     # -------------------------------------------------------------- #
            >     # inference
            >     # -------------------------------------------------------------- #
            >     @torch.no_grad()
            >     def recognise(
            >         self,
            >         cell: np.ndarray,
            >         confidence_threshold: float = 0.7,
            >     ) -> Tuple[int, float]:
            >         if self.model is None:
            >             return 0, 0.0
            >
            >         proc = self._preprocess_cell_for_model(cell)
            >         if proc is None:
            >             return 0, 0.0
            >
            >         x = torch.from_numpy(proc[np.newaxis, ..., np.newaxis]).float()
            >         probs = self.model(x, training=False)[0]
            >         if isinstance(probs, torch.Tensor):
            >             probs = probs.cpu().numpy()
            >
            >         idx = int(np.argmax(probs))
            >         conf = float(probs[idx])
            >         if idx == EMPTY_LABEL or conf < confidence_threshold:
            >             return 0, conf
            >         return idx, conf
            >
            >
            > # ------------------------------------------------------------------ #
            > # 8.  epoch‑end callback (unchanged, except imports at top)
            > # ------------------------------------------------------------------ #
            > class EpochTestCallback(callbacks.Callback):
            >     def __init__(
            >         self,
            >         test_img_path: Path | str,
            >         gt_grid: np.ndarray,
            >         classifier: "DigitClassifier",
            >         frequency: int = 1,
            >     ) -> None:
            >         super().__init__()
            >         self.frequency = max(1, frequency)
            >         self.gt_grid = gt_grid
            >         self.classifier = classifier
            >
            >         cells, _, _ = extract_cells_from_image(test_img_path, debug=False)
            >         if not cells or len(cells) != GRID_SIZE * GRID_SIZE:
            >             self.preprocessed = None
            >             print("[Callback] could not prepare test example – disabled")
            >             return
            >
            >         buf = []
            >         for cell in cells:
            >             proc = classifier._preprocess_cell_for_model(cell)
            >             if proc is None:
            >                 proc = np.zeros(classifier._model_input_size, dtype="float32")
            >             buf.append(proc)
            >         self.preprocessed = np.asarray(buf, dtype="float32")[..., np.newaxis]
            >
            >     def on_epoch_end(self, epoch, logs=None):
            >         if self.preprocessed is None or (epoch + 1) % self.frequency:
            >             return
            >
            >         probs = self.model.predict(self.preprocessed, verbose=0)
            >         idxs = np.argmax(probs, axis=1)
            >         confs = np.max(probs, axis=1)
            >
            >         final = [
            >             i
            >             if (i != EMPTY_LABEL and c >= sudoku_recogniser.FINAL_CONFIDENCE_THRESHOLD)
            >             else 0
            >             for i, c in zip(idxs, confs)
            >         ]
            >         pred_grid = np.asarray(final).reshape(GRID_SIZE, GRID_SIZE)
            >         conf_grid = confs.reshape(GRID_SIZE, GRID_SIZE)
            >
            >         print(f"\n--- Epoch {epoch+1} test example ---")
            >         print("Ground truth:")
            >         sudoku_recogniser.print_sudoku_grid(self.gt_grid, threshold=1.1)
            >         print("Prediction:")
            >         sudoku_recogniser.print_sudoku_grid(pred_grid, conf_grid)
            >         ok = (pred_grid == self.gt_grid).sum()
            >         print(f"Accuracy {ok}/81 = {ok/81:.4f}\n---\n")
            >
            >
            > # ------------------------------------------------------------------ #
            > # 9.  CLI helper
            > # ------------------------------------------------------------------ #
            > if __name__ == "__main__":
            >     FORCE_TRAIN = True
            >     if FORCE_TRAIN and Path(MODEL_FILENAME).exists():
            >         Path(MODEL_FILENAME).unlink()
            >
            >     clf = DigitClassifier(training_required=FORCE_TRAIN)
            >     if clf.model is None:
            >         clf.train()
            >
            >     if clf.model:
            >         print("\nQuick sanity check:")
            >         dummy = np.zeros((50, 50), np.uint8)
            >         cv2.line(dummy, (25, 10), (25, 40), 255, 3)
            >         d, c = clf.recognise(dummy, 0.5)
            >         print(f"Vertical stroke → {d}  (conf {c:.3f})")
            >         blank = np.zeros((50, 50), np.uint8)
            >         d, c = clf.recognise(blank, 0.5)
            >         print(f"Blank cell     → {d}  (conf {c:.3f})")
    prev_file_contents:
        digit_classifier.py:
            > """
            > SudokuBot – digit classifier
            > Fixed version 2025‑04‑20
            >
            > Major fixes
            > • data generator now really yields balanced batches
            > • preprocessing is tolerant – almost never rejects a cell
            > """
            >
            > # ------------------------------------------------------------------ #
            > # 1.  choose backend BEFORE importing keras
            > # ------------------------------------------------------------------ #
            > import os
            >
            > os.environ["KERAS_BACKEND"] = "torch"  # must be first – do NOT move
            >
            > # ------------------------------------------------------------------ #
            > # 2.  std‑lib & 3rd‑party imports
            > # ------------------------------------------------------------------ #
            > import gc
            > import random
            > from pathlib import Path
            > from typing import Callable, Generator, Optional, Tuple
            >
            > import cv2
            > import numpy as np
            > import torch
            > import keras
            > from keras import callbacks, layers, models, activations
            >
            > # ------------------------------------------------------------------ #
            > # 3.  project‑local imports
            > # ------------------------------------------------------------------ #
            > from sudoku_renderer import SudokuRenderer, generate_and_save_test_example
            > from digit_extractor import (
            >     GRID_SIZE,
            >     extract_cells_from_image,
            >     rectify_grid,
            >     split_into_cells,
            > )
            > import sudoku_recogniser
            >
            > # ------------------------------------------------------------------ #
            > # 4.  constants
            > # ------------------------------------------------------------------ #
            > MODEL_FILENAME = "sudoku_digit_classifier_cnn.keras"
            >
            > MODEL_INPUT_SHAPE = (28, 28, 1)
            > NUM_CLASSES = 11  # digits 0‑9 + “empty”
            > EMPTY_LABEL = 10
            >
            > TARGET_CELL_CONTENT_SIZE = 24          # preprocessing
            > TARGET_DIGIT_RATIO = 1.5               # 60 % digits / 40 % empty
            >
            > EPOCHS = 10
            > STEPS_PER_EPOCH = 100
            > BATCH_SIZE = 256
            > VALIDATION_STEPS = 50
            >
            > DataBatch = Tuple[np.ndarray, np.ndarray]
            >
            > # ------------------------------------------------------------------ #
            > # 5.  balanced data generator (fixed)
            > # ------------------------------------------------------------------ #
            > def sudoku_data_generator(
            >     renderer: SudokuRenderer,
            >     batch_size: int,
            >     preprocess_func: Callable[[np.ndarray], Optional[np.ndarray]],
            >     input_size: Tuple[int, int, int],
            >     target_digit_ratio: float = TARGET_DIGIT_RATIO,
            > ) -> Generator[DataBatch, None, None]:
            >     """
            >     Yield *balanced* batches of (cell, label).
            >
            >     The function never gives up early – it keeps sampling Sudokus until the
            >     required number of digit and empty cells has been collected.
            >     """
            >     total_cells = GRID_SIZE * GRID_SIZE
            >     want_digits = int(batch_size * target_digit_ratio / (1 + target_digit_ratio))
            >     want_empty = batch_size - want_digits
            >     in_h, in_w = input_size[:2]
            >
            >     batch_counter = 0
            >     while True:
            >         xs, ys = [], []
            >         n_dig = n_emp = 0
            >
            >         while n_dig < want_digits or n_emp < want_empty:
            >             img, gt_grid, corners = renderer.render_sudoku(allow_empty=True)
            >             if img is None or corners is None:
            >                 continue
            >             rectified = rectify_grid(img, corners)
            >             if rectified is None:
            >                 continue
            >             cells, _ = split_into_cells(rectified)
            >             if len(cells) != total_cells:
            >                 continue
            >
            >             # iterate shuffled cell indices
            >             idxs = list(range(total_cells))
            >             random.shuffle(idxs)
            >
            >             for idx in idxs:
            >                 if n_dig >= want_digits and n_emp >= want_empty:
            >                     break
            >
            >                 cell = cells[idx]
            >                 label = EMPTY_LABEL if gt_grid.flatten()[idx] == 0 else gt_grid.flatten()[idx]
            >                 proc = preprocess_func(cell)
            >                 if proc is None:                       # should be rare now
            >                     continue
            >
            >                 # balance bookkeeping
            >                 if label == EMPTY_LABEL:
            >                     if n_emp >= want_empty:
            >                         continue
            >                     n_emp += 1
            >                 else:
            >                     if n_dig >= want_digits:
            >                         continue
            >                     n_dig += 1
            >
            >                 xs.append(proc)
            >                 ys.append(label)
            >
            >         # at this point we have a perfectly balanced batch
            >         x_arr = np.asarray(xs, dtype="float32")[..., np.newaxis]
            >         y_arr = np.asarray(ys, dtype="int64")
            >         p = np.random.permutation(batch_size)
            >         batch_counter += 1
            >
            >         # optional histo print for debugging
            >         if (
            >             os.environ.get("SUDOKU_DEBUG_GENERATOR", "0") == "1"
            >             and batch_counter % 500 == 0
            >         ):
            >             print("label histogram:", np.bincount(y_arr, minlength=NUM_CLASSES))
            >
            >         yield x_arr[p], y_arr[p]
            >         del xs, ys, x_arr, y_arr
            >         gc.collect()
            >
            >
            > # ------------------------------------------------------------------ #
            > # 6.  layer helpers
            > # ------------------------------------------------------------------ #
            > def _norm():
            >     return layers.GroupNormalization()
            >
            >
            > def activation(x):
            >     return activations.gelu(x, approximate=True)
            >
            >
            > # ------------------------------------------------------------------ #
            > # 7.  classifier object
            > # ------------------------------------------------------------------ #
            > class DigitClassifier:
            >     """
            >     Handles loading, training and inference of the CNN digit classifier.
            >     """
            >
            >     # -------------------------------------------------------------- #
            >     # constructor
            >     # -------------------------------------------------------------- #
            >     def __init__(
            >         self,
            >         model_path: Optional[str | Path] = None,
            >         training_required: bool = False,
            >     ) -> None:
            >         self.model_path = Path(model_path) if model_path else Path(MODEL_FILENAME)
            >         self.model: Optional[keras.Model] = None
            >         self._model_input_size = MODEL_INPUT_SHAPE[:2]
            >
            >         if not training_required and self.model_path.exists():
            >             try:
            >                 self.model = keras.models.load_model(self.model_path)
            >                 if self.model.input_shape[1:3] != self._model_input_size:
            >                     print("[Warning] stored model input size differs from expected")
            >                 print("Digit‑classifier model loaded from disk.")
            >             except Exception as e:
            >                 print(f"[Error] failed to load model – will train from scratch ({e})")
            >
            >     # -------------------------------------------------------------- #
            >     # backbone
            >     # -------------------------------------------------------------- #
            >     def _build_cnn_model(self) -> keras.Model:
            >         """Simple CNN."""
            >         cfg = [32, 32, 64, 64, 96, 96, 96, 128, 128, 128, 128, 192, 192]
            >         pool_at = {1, 3, 6, 10}
            >
            >         x_in = keras.Input(shape=MODEL_INPUT_SHAPE)
            >         x = x_in
            >         for i, f in enumerate(cfg):
            >             x = layers.Conv2D(f, 3, padding="same", use_bias=False)(x)
            >             x = layers.Activation(activation)(x)
            >             x = _norm()(x)
            >             if i in pool_at:
            >                 x = layers.MaxPooling2D(2)(x)
            >
            >         # 1×1 bottleneck
            >         x = layers.Conv2D(256, 1, use_bias=False)(x)
            >         x = layers.Activation(activation)(x)
            >         x = _norm()(x)
            >
            >         # classifier head
            >         x = layers.GlobalAveragePooling2D()(x)
            >         x = layers.Dense(128, activation=activation)(x)
            >         x = layers.Dense(64, activation=activation)(x)
            >         y_out = layers.Dense(NUM_CLASSES, activation="softmax")(x)
            >
            >         model = models.Model(x_in, y_out, name="simplenet_digits_ln")
            >         model.compile(
            >             optimizer=keras.optimizers.Adam(3e-4),
            >             loss="sparse_categorical_crossentropy",
            >             metrics=["accuracy"],
            >         )
            >         model.summary()
            >         return model
            >
            >     # -------------------------------------------------------------- #
            >     # preprocessing (fixed – tolerant)
            >     # -------------------------------------------------------------- #
            >     def _preprocess_cell_for_model(self, cell: np.ndarray) -> Optional[np.ndarray]:
            >         """
            >         Convert raw cell → 28×28 float32 in [0,1].
            >         Never raises; returns None only if `cell` itself is invalid.
            >         """
            >         if cell is None or cell.size < 10:
            >             return None
            >
            >         gray = (
            >             cv2.cvtColor(cell, cv2.COLOR_BGR2GRAY).astype("uint8")
            >             if cell.ndim == 3
            >             else cell.astype("uint8")
            >         )
            >
            >         # adaptive threshold, fall back to simple Otsu if OpenCV complains
            >         try:
            >             blk = max(3, min(gray.shape) // 4) | 1
            >             thresh = cv2.adaptiveThreshold(
            >                 gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, blk, 7
            >             )
            >         except cv2.error:
            >             _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            >
            >         pts = cv2.findNonZero(thresh)
            >         if pts is None:  # looks empty – return black canvas
            >             return np.zeros(self._model_input_size, dtype="float32")
            >
            >         x, y, w, h = cv2.boundingRect(pts)
            >         if w == 0 or h == 0:
            >             return np.zeros(self._model_input_size, dtype="float32")
            >
            >         roi = thresh[y : y + h, x : x + w]
            >
            >         scale = min(
            >             TARGET_CELL_CONTENT_SIZE / max(1, w),
            >             TARGET_CELL_CONTENT_SIZE / max(1, h),
            >         )
            >         new_w = max(1, int(round(w * scale)))
            >         new_h = max(1, int(round(h * scale)))
            >         resized = cv2.resize(roi, (new_w, new_h), interpolation=cv2.INTER_AREA)
            >
            >         canvas = np.zeros(self._model_input_size, np.uint8)
            >         top = (self._model_input_size[0] - new_h) // 2
            >         left = (self._model_input_size[1] - new_w) // 2
            >         canvas[top : top + new_h, left : left + new_w] = resized
            >
            >         return canvas.astype("float32") / 255.0
            >
            >     # -------------------------------------------------------------- #
            >     # training
            >     # -------------------------------------------------------------- #
            >     def train(
            >         self,
            >         epochs: int = EPOCHS,
            >         steps_per_epoch: int = STEPS_PER_EPOCH,
            >         batch_size: int = BATCH_SIZE,
            >         validation_steps: int = VALIDATION_STEPS,
            >     ) -> None:
            >         print(f"\nTraining: epochs={epochs}  batch={batch_size}")
            >         try:
            >             test_img, test_gt = generate_and_save_test_example()
            >             epoch_cb = EpochTestCallback(test_img, test_gt, self)
            >         except Exception as e:
            >             print(f"[Warning] epoch‑callback disabled ({e})")
            >             epoch_cb = None
            >
            >         train_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >         val_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >
            >         if self.model is None:
            >             self.model = self._build_cnn_model()
            >
            >         cbs: list[callbacks.Callback] = [
            >             callbacks.EarlyStopping(
            >                 monitor="val_loss",
            >                 patience=5,
            >                 restore_best_weights=True,
            >                 verbose=1,
            >             ),
            >             callbacks.ModelCheckpoint(
            >                 filepath=self.model_path,
            >                 monitor="val_loss",
            >                 save_best_only=True,
            >                 verbose=1,
            >             ),
            >             callbacks.ReduceLROnPlateau(
            >                 monitor="val_loss",
            >                 factor=0.2,
            >                 patience=3,
            >                 min_lr=1e-6,
            >                 verbose=1,
            >             ),
            >         ]
            >         if epoch_cb and epoch_cb.preprocessed is not None:
            >             cbs.append(epoch_cb)
            >
            >         self.model.fit(
            >             train_gen,
            >             epochs=epochs,
            >             steps_per_epoch=steps_per_epoch,
            >             validation_data=val_gen,
            >             validation_steps=validation_steps,
            >             callbacks=cbs,
            >             verbose=1,
            >         )
            >
            >         print("\nFinal evaluation:")
            >         loss, acc = self.model.evaluate(
            >             sudoku_data_generator(
            >                 SudokuRenderer(),
            >                 batch_size,
            >                 self._preprocess_cell_for_model,
            >                 MODEL_INPUT_SHAPE,
            >             ),
            >             steps=validation_steps,
            >             verbose=1,
            >         )
            >         print(f"val_loss={loss:.4f}  val_acc={acc:.4f}")
            >
            >         self.model.save(self.model_path)
            >         del train_gen, val_gen
            >         gc.collect()
            >
            >     # -------------------------------------------------------------- #
            >     # inference
            >     # -------------------------------------------------------------- #
            >     @torch.no_grad()
            >     def recognise(
            >         self,
            >         cell: np.ndarray,
            >         confidence_threshold: float = 0.7,
            >     ) -> Tuple[int, float]:
            >         if self.model is None:
            >             return 0, 0.0
            >
            >         proc = self._preprocess_cell_for_model(cell)
            >         if proc is None:
            >             return 0, 0.0
            >
            >         x = torch.from_numpy(proc[np.newaxis, ..., np.newaxis]).float()
            >         probs = self.model(x, training=False)[0]
            >         if isinstance(probs, torch.Tensor):
            >             probs = probs.cpu().numpy()
            >
            >         idx = int(np.argmax(probs))
            >         conf = float(probs[idx])
            >         if idx == EMPTY_LABEL or conf < confidence_threshold:
            >             return 0, conf
            >         return idx, conf
            >
            >
            > # ------------------------------------------------------------------ #
            > # 8.  epoch‑end callback (unchanged, except imports at top)
            > # ------------------------------------------------------------------ #
            > class EpochTestCallback(callbacks.Callback):
            >     def __init__(
            >         self,
            >         test_img_path: Path | str,
            >         gt_grid: np.ndarray,
            >         classifier: "DigitClassifier",
            >         frequency: int = 1,
            >     ) -> None:
            >         super().__init__()
            >         self.frequency = max(1, frequency)
            >         self.gt_grid = gt_grid
            >         self.classifier = classifier
            >
            >         cells, _, _ = extract_cells_from_image(test_img_path, debug=False)
            >         if not cells or len(cells) != GRID_SIZE * GRID_SIZE:
            >             self.preprocessed = None
            >             print("[Callback] could not prepare test example – disabled")
            >             return
            >
            >         buf = []
            >         for cell in cells:
            >             proc = classifier._preprocess_cell_for_model(cell)
            >             if proc is None:
            >                 proc = np.zeros(classifier._model_input_size, dtype="float32")
            >             buf.append(proc)
            >         self.preprocessed = np.asarray(buf, dtype="float32")[..., np.newaxis]
            >
            >     def on_epoch_end(self, epoch, logs=None):
            >         if self.preprocessed is None or (epoch + 1) % self.frequency:
            >             return
            >
            >         probs = self.model.predict(self.preprocessed, verbose=0)
            >         idxs = np.argmax(probs, axis=1)
            >         confs = np.max(probs, axis=1)
            >
            >         final = [
            >             i
            >             if (i != EMPTY_LABEL and c >= sudoku_recogniser.FINAL_CONFIDENCE_THRESHOLD)
            >             else 0
            >             for i, c in zip(idxs, confs)
            >         ]
            >         pred_grid = np.asarray(final).reshape(GRID_SIZE, GRID_SIZE)
            >         conf_grid = confs.reshape(GRID_SIZE, GRID_SIZE)
            >
            >         print(f"\n--- Epoch {epoch+1} test example ---")
            >         print("Ground truth:")
            >         sudoku_recogniser.print_sudoku_grid(self.gt_grid, threshold=1.1)
            >         print("Prediction:")
            >         sudoku_recogniser.print_sudoku_grid(pred_grid, conf_grid)
            >         ok = (pred_grid == self.gt_grid).sum()
            >         print(f"Accuracy {ok}/81 = {ok/81:.4f}\n---\n")
            >
            >
            > # ------------------------------------------------------------------ #
            > # 9.  CLI helper
            > # ------------------------------------------------------------------ #
            > if __name__ == "__main__":
            >     FORCE_TRAIN = True
            >     if FORCE_TRAIN and Path(MODEL_FILENAME).exists():
            >         Path(MODEL_FILENAME).unlink()
            >
            >     clf = DigitClassifier(training_required=FORCE_TRAIN)
            >     if clf.model is None:
            >         clf.train()
            >
            >     if clf.model:
            >         print("\nQuick sanity check:")
            >         dummy = np.zeros((50, 50), np.uint8)
            >         cv2.line(dummy, (25, 10), (25, 40), 255, 3)
            >         d, c = clf.recognise(dummy, 0.5)
            >         print(f"Vertical stroke → {d}  (conf {c:.3f})")
            >         blank = np.zeros((50, 50), np.uint8)
            >         d, c = clf.recognise(blank, 0.5)
            >         print(f"Blank cell     → {d}  (conf {c:.3f})")
    diffs_applied_this_send: True
system:
    message:
        >
        > You are a helpful assistant.
        > Respond in markdown format.
        > Respond with a git diff patch for any modified or added files. Use the ```diff markdown code block.
        > Avoid asking the user to clear their caches or do local configuration related stuff. That's rarely the cause of errors.
        > If you ask them, and they reply with a compilation error, assume they've already done everything you suggested and move on.
        > But try to avoid such suggestions. It's a cop out. It's like when tech support says 'Have you tried turning it off and on again?'.
        > Try to actually fix the error instead.
        >
    model:
        - o4-mini
    code_completion_model:
        - gemini/gemini-2.0-flash-thinking-exp-01-21
    commit_message_model:
        - gemini/gemini-2.0-flash-thinking-exp-01-21
    max_completion_tokens:
    temperature: 0.0
    apply_mode: git
messages:
    -
        user:
            > ```python 'digit_classifier.py'
            > """
            > SudokuBot – digit classifier
            > Fixed version 2025‑04‑20
            >
            > Major fixes
            > • data generator now really yields balanced batches
            > • preprocessing is tolerant – almost never rejects a cell
            > """
            >
            > # ------------------------------------------------------------------ #
            > # 1.  choose backend BEFORE importing keras
            > # ------------------------------------------------------------------ #
            > import os
            >
            > os.environ["KERAS_BACKEND"] = "torch"  # must be first – do NOT move
            >
            > # ------------------------------------------------------------------ #
            > # 2.  std‑lib & 3rd‑party imports
            > # ------------------------------------------------------------------ #
            > import gc
            > import random
            > from pathlib import Path
            > from typing import Callable, Generator, Optional, Tuple
            >
            > import cv2
            > import numpy as np
            > import torch
            > import keras
            > from keras import callbacks, layers, models, activations
            >
            > # ------------------------------------------------------------------ #
            > # 3.  project‑local imports
            > # ------------------------------------------------------------------ #
            > from sudoku_renderer import SudokuRenderer, generate_and_save_test_example
            > from digit_extractor import (
            >     GRID_SIZE,
            >     extract_cells_from_image,
            >     rectify_grid,
            >     split_into_cells,
            > )
            > import sudoku_recogniser
            >
            > # ------------------------------------------------------------------ #
            > # 4.  constants
            > # ------------------------------------------------------------------ #
            > MODEL_FILENAME = "sudoku_digit_classifier_cnn.keras"
            >
            > MODEL_INPUT_SHAPE = (28, 28, 1)
            > NUM_CLASSES = 11  # digits 0‑9 + “empty”
            > EMPTY_LABEL = 10
            >
            > TARGET_CELL_CONTENT_SIZE = 24          # preprocessing
            > TARGET_DIGIT_RATIO = 1.5               # 60 % digits / 40 % empty
            >
            > EPOCHS = 10
            > STEPS_PER_EPOCH = 100
            > BATCH_SIZE = 256
            > VALIDATION_STEPS = 50
            >
            > DataBatch = Tuple[np.ndarray, np.ndarray]
            >
            > # ------------------------------------------------------------------ #
            > # 5.  balanced data generator (fixed)
            > # ------------------------------------------------------------------ #
            > def sudoku_data_generator(
            >     renderer: SudokuRenderer,
            >     batch_size: int,
            >     preprocess_func: Callable[[np.ndarray], Optional[np.ndarray]],
            >     input_size: Tuple[int, int, int],
            >     target_digit_ratio: float = TARGET_DIGIT_RATIO,
            > ) -> Generator[DataBatch, None, None]:
            >     """
            >     Yield *balanced* batches of (cell, label).
            >
            >     The function never gives up early – it keeps sampling Sudokus until the
            >     required number of digit and empty cells has been collected.
            >     """
            >     total_cells = GRID_SIZE * GRID_SIZE
            >     want_digits = int(batch_size * target_digit_ratio / (1 + target_digit_ratio))
            >     want_empty = batch_size - want_digits
            >     in_h, in_w = input_size[:2]
            >
            >     batch_counter = 0
            >     while True:
            >         xs, ys = [], []
            >         n_dig = n_emp = 0
            >
            >         while n_dig < want_digits or n_emp < want_empty:
            >             img, gt_grid, corners = renderer.render_sudoku(allow_empty=True)
            >             if img is None or corners is None:
            >                 continue
            >             rectified = rectify_grid(img, corners)
            >             if rectified is None:
            >                 continue
            >             cells, _ = split_into_cells(rectified)
            >             if len(cells) != total_cells:
            >                 continue
            >
            >             # iterate shuffled cell indices
            >             idxs = list(range(total_cells))
            >             random.shuffle(idxs)
            >
            >             for idx in idxs:
            >                 if n_dig >= want_digits and n_emp >= want_empty:
            >                     break
            >
            >                 cell = cells[idx]
            >                 label = EMPTY_LABEL if gt_grid.flatten()[idx] == 0 else gt_grid.flatten()[idx]
            >                 proc = preprocess_func(cell)
            >                 if proc is None:                       # should be rare now
            >                     continue
            >
            >                 # balance bookkeeping
            >                 if label == EMPTY_LABEL:
            >                     if n_emp >= want_empty:
            >                         continue
            >                     n_emp += 1
            >                 else:
            >                     if n_dig >= want_digits:
            >                         continue
            >                     n_dig += 1
            >
            >                 xs.append(proc)
            >                 ys.append(label)
            >
            >         # at this point we have a perfectly balanced batch
            >         x_arr = np.asarray(xs, dtype="float32")[..., np.newaxis]
            >         y_arr = np.asarray(ys, dtype="int64")
            >         p = np.random.permutation(batch_size)
            >         batch_counter += 1
            >
            >         # optional histo print for debugging
            >         if (
            >             os.environ.get("SUDOKU_DEBUG_GENERATOR", "0") == "1"
            >             and batch_counter % 500 == 0
            >         ):
            >             print("label histogram:", np.bincount(y_arr, minlength=NUM_CLASSES))
            >
            >         yield x_arr[p], y_arr[p]
            >         del xs, ys, x_arr, y_arr
            >         gc.collect()
            >
            >
            > # ------------------------------------------------------------------ #
            > # 6.  layer helpers
            > # ------------------------------------------------------------------ #
            > def _norm():
            >     return layers.GroupNormalization()
            >
            >
            > def activation(x):
            >     return activations.gelu(x, approximate=True)
            >
            >
            > # ------------------------------------------------------------------ #
            > # 7.  classifier object
            > # ------------------------------------------------------------------ #
            > class DigitClassifier:
            >     """
            >     Handles loading, training and inference of the CNN digit classifier.
            >     """
            >
            >     # -------------------------------------------------------------- #
            >     # constructor
            >     # -------------------------------------------------------------- #
            >     def __init__(
            >         self,
            >         model_path: Optional[str | Path] = None,
            >         training_required: bool = False,
            >     ) -> None:
            >         self.model_path = Path(model_path) if model_path else Path(MODEL_FILENAME)
            >         self.model: Optional[keras.Model] = None
            >         self._model_input_size = MODEL_INPUT_SHAPE[:2]
            >
            >         if not training_required and self.model_path.exists():
            >             try:
            >                 self.model = keras.models.load_model(self.model_path)
            >                 if self.model.input_shape[1:3] != self._model_input_size:
            >                     print("[Warning] stored model input size differs from expected")
            >                 print("Digit‑classifier model loaded from disk.")
            >             except Exception as e:
            >                 print(f"[Error] failed to load model – will train from scratch ({e})")
            >
            >     # -------------------------------------------------------------- #
            >     # backbone
            >     # -------------------------------------------------------------- #
            >     def _build_cnn_model(self) -> keras.Model:
            >         """Simple CNN."""
            >         cfg = [32, 32, 64, 64, 96, 96, 96, 128, 128, 128, 128, 192, 192]
            >         pool_at = {1, 3, 6, 10}
            >
            >         x_in = keras.Input(shape=MODEL_INPUT_SHAPE)
            >         x = x_in
            >         for i, f in enumerate(cfg):
            >             x = layers.Conv2D(f, 3, padding="same", use_bias=False)(x)
            >             x = layers.Activation(activation)(x)
            >             x = _norm()(x)
            >             if i in pool_at:
            >                 x = layers.MaxPooling2D(2)(x)
            >
            >         # 1×1 bottleneck
            >         x = layers.Conv2D(256, 1, use_bias=False)(x)
            >         x = layers.Activation(activation)(x)
            >         x = _norm()(x)
            >
            >         # classifier head
            >         x = layers.GlobalAveragePooling2D()(x)
            >         x = layers.Dense(128, activation=activation)(x)
            >         x = layers.Dense(64, activation=activation)(x)
            >         y_out = layers.Dense(NUM_CLASSES, activation="softmax")(x)
            >
            >         model = models.Model(x_in, y_out, name="simplenet_digits_ln")
            >         model.compile(
            >             optimizer=keras.optimizers.Adam(3e-4),
            >             loss="sparse_categorical_crossentropy",
            >             metrics=["accuracy"],
            >         )
            >         model.summary()
            >         return model
            >
            >     # -------------------------------------------------------------- #
            >     # preprocessing (fixed – tolerant)
            >     # -------------------------------------------------------------- #
            >     def _preprocess_cell_for_model(self, cell: np.ndarray) -> Optional[np.ndarray]:
            >         """
            >         Convert raw cell → 28×28 float32 in [0,1].
            >         Never raises; returns None only if `cell` itself is invalid.
            >         """
            >         if cell is None or cell.size < 10:
            >             return None
            >
            >         gray = (
            >             cv2.cvtColor(cell, cv2.COLOR_BGR2GRAY).astype("uint8")
            >             if cell.ndim == 3
            >             else cell.astype("uint8")
            >         )
            >
            >         # adaptive threshold, fall back to simple Otsu if OpenCV complains
            >         try:
            >             blk = max(3, min(gray.shape) // 4) | 1
            >             thresh = cv2.adaptiveThreshold(
            >                 gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, blk, 7
            >             )
            >         except cv2.error:
            >             _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            >
            >         pts = cv2.findNonZero(thresh)
            >         if pts is None:  # looks empty – return black canvas
            >             return np.zeros(self._model_input_size, dtype="float32")
            >
            >         x, y, w, h = cv2.boundingRect(pts)
            >         if w == 0 or h == 0:
            >             return np.zeros(self._model_input_size, dtype="float32")
            >
            >         roi = thresh[y : y + h, x : x + w]
            >
            >         scale = min(
            >             TARGET_CELL_CONTENT_SIZE / max(1, w),
            >             TARGET_CELL_CONTENT_SIZE / max(1, h),
            >         )
            >         new_w = max(1, int(round(w * scale)))
            >         new_h = max(1, int(round(h * scale)))
            >         resized = cv2.resize(roi, (new_w, new_h), interpolation=cv2.INTER_AREA)
            >
            >         canvas = np.zeros(self._model_input_size, np.uint8)
            >         top = (self._model_input_size[0] - new_h) // 2
            >         left = (self._model_input_size[1] - new_w) // 2
            >         canvas[top : top + new_h, left : left + new_w] = resized
            >
            >         return canvas.astype("float32") / 255.0
            >
            >     # -------------------------------------------------------------- #
            >     # training
            >     # -------------------------------------------------------------- #
            >     def train(
            >         self,
            >         epochs: int = EPOCHS,
            >         steps_per_epoch: int = STEPS_PER_EPOCH,
            >         batch_size: int = BATCH_SIZE,
            >         validation_steps: int = VALIDATION_STEPS,
            >     ) -> None:
            >         print(f"\nTraining: epochs={epochs}  batch={batch_size}")
            >         try:
            >             test_img, test_gt = generate_and_save_test_example()
            >             epoch_cb = EpochTestCallback(test_img, test_gt, self)
            >         except Exception as e:
            >             print(f"[Warning] epoch‑callback disabled ({e})")
            >             epoch_cb = None
            >
            >         train_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >         val_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >
            >         if self.model is None:
            >             self.model = self._build_cnn_model()
            >
            >         cbs: list[callbacks.Callback] = [
            >             callbacks.EarlyStopping(
            >                 monitor="val_loss",
            >                 patience=5,
            >                 restore_best_weights=True,
            >                 verbose=1,
            >             ),
            >             callbacks.ModelCheckpoint(
            >                 filepath=self.model_path,
            >                 monitor="val_loss",
            >                 save_best_only=True,
            >                 verbose=1,
            >             ),
            >             callbacks.ReduceLROnPlateau(
            >                 monitor="val_loss",
            >                 factor=0.2,
            >                 patience=3,
            >                 min_lr=1e-6,
            >                 verbose=1,
            >             ),
            >         ]
            >         if epoch_cb and epoch_cb.preprocessed is not None:
            >             cbs.append(epoch_cb)
            >
            >         self.model.fit(
            >             train_gen,
            >             epochs=epochs,
            >             steps_per_epoch=steps_per_epoch,
            >             validation_data=val_gen,
            >             validation_steps=validation_steps,
            >             callbacks=cbs,
            >             verbose=1,
            >         )
            >
            >         print("\nFinal evaluation:")
            >         loss, acc = self.model.evaluate(
            >             sudoku_data_generator(
            >                 SudokuRenderer(),
            >                 batch_size,
            >                 self._preprocess_cell_for_model,
            >                 MODEL_INPUT_SHAPE,
            >             ),
            >             steps=validation_steps,
            >             verbose=1,
            >         )
            >         print(f"val_loss={loss:.4f}  val_acc={acc:.4f}")
            >
            >         self.model.save(self.model_path)
            >         del train_gen, val_gen
            >         gc.collect()
            >
            >     # -------------------------------------------------------------- #
            >     # inference
            >     # -------------------------------------------------------------- #
            >     @torch.no_grad()
            >     def recognise(
            >         self,
            >         cell: np.ndarray,
            >         confidence_threshold: float = 0.7,
            >     ) -> Tuple[int, float]:
            >         if self.model is None:
            >             return 0, 0.0
            >
            >         proc = self._preprocess_cell_for_model(cell)
            >         if proc is None:
            >             return 0, 0.0
            >
            >         x = torch.from_numpy(proc[np.newaxis, ..., np.newaxis]).float()
            >         probs = self.model(x, training=False)[0]
            >         if isinstance(probs, torch.Tensor):
            >             probs = probs.cpu().numpy()
            >
            >         idx = int(np.argmax(probs))
            >         conf = float(probs[idx])
            >         if idx == EMPTY_LABEL or conf < confidence_threshold:
            >             return 0, conf
            >         return idx, conf
            >
            >
            > # ------------------------------------------------------------------ #
            > # 8.  epoch‑end callback (unchanged, except imports at top)
            > # ------------------------------------------------------------------ #
            > class EpochTestCallback(callbacks.Callback):
            >     def __init__(
            >         self,
            >         test_img_path: Path | str,
            >         gt_grid: np.ndarray,
            >         classifier: "DigitClassifier",
            >         frequency: int = 1,
            >     ) -> None:
            >         super().__init__()
            >         self.frequency = max(1, frequency)
            >         self.gt_grid = gt_grid
            >         self.classifier = classifier
            >
            >         cells, _, _ = extract_cells_from_image(test_img_path, debug=False)
            >         if not cells or len(cells) != GRID_SIZE * GRID_SIZE:
            >             self.preprocessed = None
            >             print("[Callback] could not prepare test example – disabled")
            >             return
            >
            >         buf = []
            >         for cell in cells:
            >             proc = classifier._preprocess_cell_for_model(cell)
            >             if proc is None:
            >                 proc = np.zeros(classifier._model_input_size, dtype="float32")
            >             buf.append(proc)
            >         self.preprocessed = np.asarray(buf, dtype="float32")[..., np.newaxis]
            >
            >     def on_epoch_end(self, epoch, logs=None):
            >         if self.preprocessed is None or (epoch + 1) % self.frequency:
            >             return
            >
            >         probs = self.model.predict(self.preprocessed, verbose=0)
            >         idxs = np.argmax(probs, axis=1)
            >         confs = np.max(probs, axis=1)
            >
            >         final = [
            >             i
            >             if (i != EMPTY_LABEL and c >= sudoku_recogniser.FINAL_CONFIDENCE_THRESHOLD)
            >             else 0
            >             for i, c in zip(idxs, confs)
            >         ]
            >         pred_grid = np.asarray(final).reshape(GRID_SIZE, GRID_SIZE)
            >         conf_grid = confs.reshape(GRID_SIZE, GRID_SIZE)
            >
            >         print(f"\n--- Epoch {epoch+1} test example ---")
            >         print("Ground truth:")
            >         sudoku_recogniser.print_sudoku_grid(self.gt_grid, threshold=1.1)
            >         print("Prediction:")
            >         sudoku_recogniser.print_sudoku_grid(pred_grid, conf_grid)
            >         ok = (pred_grid == self.gt_grid).sum()
            >         print(f"Accuracy {ok}/81 = {ok/81:.4f}\n---\n")
            >
            >
            > # ------------------------------------------------------------------ #
            > # 9.  CLI helper
            > # ------------------------------------------------------------------ #
            > if __name__ == "__main__":
            >     FORCE_TRAIN = True
            >     if FORCE_TRAIN and Path(MODEL_FILENAME).exists():
            >         Path(MODEL_FILENAME).unlink()
            >
            >     clf = DigitClassifier(training_required=FORCE_TRAIN)
            >     if clf.model is None:
            >         clf.train()
            >
            >     if clf.model:
            >         print("\nQuick sanity check:")
            >         dummy = np.zeros((50, 50), np.uint8)
            >         cv2.line(dummy, (25, 10), (25, 40), 255, 3)
            >         d, c = clf.recognise(dummy, 0.5)
            >         print(f"Vertical stroke → {d}  (conf {c:.3f})")
            >         blank = np.zeros((50, 50), np.uint8)
            >         d, c = clf.recognise(blank, 0.5)
            >         print(f"Blank cell     → {d}  (conf {c:.3f})")
            > ```
        metadata:
            filename: digit_classifier.py
    -
        user: Make this so the data generator buffers asynchronously, so that the next batch is always ready to go.
        metadata:
    -
        assistant:
            > ```diff
            > diff --git a/digit_classifier.py b/digit_classifier.py
            > index e3a1f2b..4b5c6d7 100644
            > --- a/digit_classifier.py
            > +++ b/digit_classifier.py
            > @@
            >  import cv2
            >  import numpy as np
            >  import torch
            > -import keras
            > +import keras
            > +import threading
            > +import queue
            >  from keras import callbacks, layers, models, activations
            > @@
            >  # ------------------------------------------------------------------ #
            >  # 5.  balanced data generator (fixed)
            >  # ------------------------------------------------------------------ #
            > @@
            >      yield x_arr[p], y_arr[p]
            >      del xs, ys, x_arr, y_arr
            >      gc.collect()
            > +
            > +# ------------------------------------------------------------------ #
            > +# Async prefetching wrapper
            > +# ------------------------------------------------------------------ #
            > +class ThreadedGenerator:
            > +    """
            > +    Wrap a Python generator in a background thread with a fixed-size queue,
            > +    so that the next batch is prefetched asynchronously.
            > +    """
            > +    def __init__(self, gen, max_prefetch: int = 1):
            > +        self._gen = gen
            > +        self._queue: "queue.Queue[object]" = queue.Queue(max_prefetch)
            > +        self._sentinel = object()
            > +        self._thread = threading.Thread(target=self._run, daemon=True)
            > +        self._thread.start()
            > +
            > +    def _run(self):
            > +        for item in self._gen:
            > +            self._queue.put(item)
            > +        # signal end-of-stream
            > +        self._queue.put(self._sentinel)
            > +
            > +    def __iter__(self):
            > +        return self
            > +
            > +    def __next__(self):
            > +        item = self._queue.get()
            > +        if item is self._sentinel:
            > +            raise StopIteration
            > +        return item
            > +
            >  # ------------------------------------------------------------------ #
            >  # 6.  layer helpers
            >  # ------------------------------------------------------------------ #
            > @@ class DigitClassifier:
            >      def train(
            > @@
            >          try:
            >              test_img, test_gt = generate_and_save_test_example()
            >              epoch_cb = EpochTestCallback(test_img, test_gt, self)
            > @@
            > -        train_gen = sudoku_data_generator(
            > -            SudokuRenderer(),
            > -            batch_size,
            > -            self._preprocess_cell_for_model,
            > -            MODEL_INPUT_SHAPE,
            > -        )
            > -        val_gen = sudoku_data_generator(
            > -            SudokuRenderer(),
            > -            batch_size,
            > -            self._preprocess_cell_for_model,
            > -            MODEL_INPUT_SHAPE,
            > -        )
            > +        # wrap generators to prefetch batches asynchronously
            > +        train_gen = ThreadedGenerator(
            > +            sudoku_data_generator(
            > +                SudokuRenderer(),
            > +                batch_size,
            > +                self._preprocess_cell_for_model,
            > +                MODEL_INPUT_SHAPE,
            > +            ),
            > +            max_prefetch=1,
            > +        )
            > +        val_gen = ThreadedGenerator(
            > +            sudoku_data_generator(
            > +                SudokuRenderer(),
            > +                batch_size,
            > +                self._preprocess_cell_for_model,
            > +                MODEL_INPUT_SHAPE,
            > +            ),
            > +            max_prefetch=1,
            > +        )
            > @@
            >          self.model.fit(
            >              train_gen,
            >              epochs=epochs,
            >              steps_per_epoch=steps_per_epoch,
            >              validation_data=val_gen,
            >              validation_steps=validation_steps,
            >              callbacks=cbs,
            >              verbose=1,
            >          )
            > @@
            >          print("\nFinal evaluation:")
            > -        loss, acc = self.model.evaluate(
            > -            sudoku_data_generator(
            > -                SudokuRenderer(),
            > -                batch_size,
            > -                self._preprocess_cell_for_model,
            > -                MODEL_INPUT_SHAPE,
            > -            ),
            > -            steps=validation_steps,
            > -            verbose=1,
            > -        )
            > +        # evaluate with prefetched validation data
            > +        loss, acc = self.model.evaluate(
            > +            ThreadedGenerator(
            > +                sudoku_data_generator(
            > +                    SudokuRenderer(),
            > +                    batch_size,
            > +                    self._preprocess_cell_for_model,
            > +                    MODEL_INPUT_SHAPE,
            > +                ),
            > +                max_prefetch=1,
            > +            ),
            > +            steps=validation_steps,
            > +            verbose=1,
            > +        )
            >          print(f"val_loss={loss:.4f}  val_acc={acc:.4f}")
            >  
            >          self.model.save(self.model_path)
            > ```
        metadata:
    -
        user:
            > Git apply result:
            > Found 1 diff block(s) to process using custom patcher.
            >
            > --- Processing Diff Block 1 ---
            > Identified target file: digit_classifier.py
            > Applying patch to 'digit_classifier.py' using custom patcher...
            > Error applying patch to digit_classifier.py:
            > Hunk #3 (header: @@) failed: context not found (matching done ignoring trailing whitespace).
            >
            > --- Expected Context (from patch): ---
            >     yield x_arr[p], y_arr[p]
            >     del xs, ys, x_arr, y_arr
            >     gc.collect()
            > # ------------------------------------------------------------------ #
            > # 6.  layer helpers
            > # ------------------------------------------------------------------ #
            >
            >
            > --- JSON (Expected Context): ---
            > [
            >   "    yield x_arr[p], y_arr[p]\n",
            >   "    del xs, ys, x_arr, y_arr\n",
            >   "    gc.collect()\n",
            >   "# ------------------------------------------------------------------ #\n",
            >   "# 6.  layer helpers\n",
            >   "# ------------------------------------------------------------------ #\n"
            > ]
            > --- End Expected Context ---
            >
            > --- Actual Content Analysis ---
            > No close match found in the current content.
            > --- Current Content (Around Approximate Location ~3 (based on offset, header lacked line numbers)): ---
            >        1: """
            >        2: SudokuBot – digit classifier
            >  ~>    3: Fixed version 2025‑04‑20
            >        4: 
            >        5: Major fixes
            >        6: • data generator now really yields balanced batches
            >        7: • preprocessing is tolerant – almost never rejects a cell
            >        8: """
            >        9: 
            >       10: # ------------------------------------------------------------------ #
            >       11: # 1.  choose backend BEFORE importing keras
            >       12: # ------------------------------------------------------------------ #
            > Problematic diff content:
            > ---
            > diff --git a/digit_classifier.py b/digit_classifier.py
            > index e3a1f2b..4b5c6d7 100644
            > --- a/digit_classifier.py
            > +++ b/digit_classifier.py
            > @@
            >  import cv2
            >  import numpy as np
            >  import torch
            > -import keras
            > +import keras
            > +import threading
            > +import queue
            >  from keras import callbacks, layers, models, activations
            > @@
            >  # ------------------------------------------------------------------ #
            >  # 5.  balanced data generator (fixed)
            >  # ------------------------------------------------------------------ #
            > @@
            >      yield x_arr[p], y_arr[p]
            >      del xs, ys, x_arr, y_arr
            >      gc.collect()
            > +
            > +# ------------------------------------------------------------------ #
            > +# Async prefetching wrapper
            > +# ------------------------------------------------------------------ #
            > +class ThreadedGenerator:
            > +    """
            > +    Wrap a Python generator in a background thread with a fixed-size queue,
            > +    so that the next batch is prefetched asynchronously.
            > +    """
            > +    def __init__(self, gen, max_prefetch: int = 1):
            > +        self._gen = gen
            > +        self._queue: "queue.Queue[object]" = queue.Queue(max_prefetch)
            > +        self._sentinel = object()
            > +        self._thread = threading.Thread(target=self._run, daemon=True)
            > +        self._thread.start()
            > +
            > +    def _run(self):
            > +        for item in self._gen:
            > +            self._queue.put(item)
            > +        # signal end-of-stream
            > +        self._queue.put(self._sentinel)
            > +
            > +    def __iter__(self):
            > +        return self
            > +
            > +    def __next__(self):
            > +        item = self._queue.get()
            > +        if item is self._sentinel:
            > +            raise StopIteration
            > +        return item
            > +
            >  # ------------------------------------------------------------------ #
            >  # 6.  layer helpers
            >  # ------------------------------------------------------------------ #
            > @@ class DigitClassifier:
            >      def train(
            > @@
            >          try:
            >              test_img, test_gt = generate_and_save_test_example()
            >              epoch_cb = EpochTestCallback(test_img, test_gt, self)
            > @@
            > -        train_gen = sudoku_data_generator(
            > -            SudokuRenderer(),
            > -            batch_size,
            > -            self._preprocess_cell_for_model,
            > -            MODEL_INPUT_SHAPE,
            > -        )
            > -        val_gen = sudoku_data_generator(
            > -            SudokuRenderer(),
            > -            batch_size,
            > -            self._preprocess_cell_for_model,
            > -            MODEL_INPUT_SHAPE,
            > -        )
            > +        # wrap generators to prefetch batches asynchronously
            > +        train_gen = ThreadedGenerator(
            > +            sudoku_data_generator(
            > +                SudokuRenderer(),
            > +                batch_size,
            > +                self._preprocess_cell_for_model,
            > +                MODEL_INPUT_SHAPE,
            > +            ),
            > +            max_prefetch=1,
            > +        )
            > +        val_gen = ThreadedGenerator(
            > +            sudoku_data_generator(
            > +                SudokuRenderer(),
            > +                batch_size,
            > +                self._preprocess_cell_for_model,
            > +                MODEL_INPUT_SHAPE,
            > +            ),
            > +            max_prefetch=1,
            > +        )
            > @@
            >          self.model.fit(
            >              train_gen,
            >              epochs=epochs,
            >              steps_per_epoch=steps_per_epoch,
            >              validation_data=val_gen,
            >              validation_steps=validation_steps,
            >              callbacks=cbs,
            >              verbose=1,
            >          )
            > @@
            >          print("\nFinal evaluation:")
            > -        loss, acc = self.model.evaluate(
            > -            sudoku_data_generator(
            > -                SudokuRenderer(),
            > -                batch_size,
            > -                self._preprocess_cell_for_model,
            > -                MODEL_INPUT_SHAPE,
            > -            ),
            > -            steps=validation_steps,
            > -            verbose=1,
            > -        )
            > +        # evaluate with prefetched validation data
            > +        loss, acc = self.model.evaluate(
            > +            ThreadedGenerator(
            > +                sudoku_data_generator(
            > +                    SudokuRenderer(),
            > +                    batch_size,
            > +                    self._preprocess_cell_for_model,
            > +                    MODEL_INPUT_SHAPE,
            > +                ),
            > +                max_prefetch=1,
            > +            ),
            > +            steps=validation_steps,
            > +            verbose=1,
            > +        )
            >          print(f"val_loss={loss:.4f}  val_acc={acc:.4f}")
            >  
            >          self.model.save(self.model_path)
            > ---
            >
        metadata:
    -
        user: There was an error applying the git patch. Please review the errors above and provide a corrected patch or instructions.
        metadata:
    -
        assistant:
            > ```diff
            > diff --git a/digit_classifier.py b/digit_classifier.py
            > --- a/digit_classifier.py
            > +++ b/digit_classifier.py
            > @@
            > -import keras
            > +import keras
            > +import threading
            > +import queue
            > @@ def sudoku_data_generator(
            > -        gc.collect()
            > +        gc.collect()
            > +
            > +# ------------------------------------------------------------------ #
            > +# Async prefetching wrapper
            > +# ------------------------------------------------------------------ #
            > +class ThreadedGenerator:
            > +    """
            > +    Wrap a Python generator in a background thread with a fixed-size queue,
            > +    so that the next batch is prefetched asynchronously.
            > +    """
            > +    def __init__(self, gen, max_prefetch: int = 1):
            > +        self._gen = gen
            > +        self._queue: "queue.Queue[object]" = queue.Queue(max_prefetch)
            > +        self._sentinel = object()
            > +        self._thread = threading.Thread(target=self._run, daemon=True)
            > +        self._thread.start()
            > +
            > +    def _run(self):
            > +        for item in self._gen:
            > +            self._queue.put(item)
            > +        # signal end-of-stream
            > +        self._queue.put(self._sentinel)
            > +
            > +    def __iter__(self):
            > +        return self
            > +
            > +    def __next__(self):
            > +        item = self._queue.get()
            > +        if item is self._sentinel:
            > +            raise StopIteration
            > +        return item
            > @@ class DigitClassifier:
            >      def train(
            > @@
            > -        train_gen = sudoku_data_generator(
            > -            SudokuRenderer(),
            > -            batch_size,
            > -            self._preprocess_cell_for_model,
            > -            MODEL_INPUT_SHAPE,
            > -        )
            > -        val_gen = sudoku_data_generator(
            > -            SudokuRenderer(),
            > -            batch_size,
            > -            self._preprocess_cell_for_model,
            > -            MODEL_INPUT_SHAPE,
            > -        )
            > +        # wrap generators to prefetch batches asynchronously
            > +        train_gen = ThreadedGenerator(
            > +            sudoku_data_generator(
            > +                SudokuRenderer(),
            > +                batch_size,
            > +                self._preprocess_cell_for_model,
            > +                MODEL_INPUT_SHAPE,
            > +            ),
            > +            max_prefetch=1,
            > +        )
            > +        val_gen = ThreadedGenerator(
            > +            sudoku_data_generator(
            > +                SudokuRenderer(),
            > +                batch_size,
            > +                self._preprocess_cell_for_model,
            > +                MODEL_INPUT_SHAPE,
            > +            ),
            > +            max_prefetch=1,
            > +        )
            > @@
            > -        loss, acc = self.model.evaluate(
            > -            sudoku_data_generator(
            > -                SudokuRenderer(),
            > -                batch_size,
            > -                self._preprocess_cell_for_model,
            > -                MODEL_INPUT_SHAPE,
            > -            ),
            > -            steps=validation_steps,
            > -            verbose=1,
            > -        )
            > +        # evaluate with prefetched validation data
            > +        loss, acc = self.model.evaluate(
            > +            ThreadedGenerator(
            > +                sudoku_data_generator(
            > +                    SudokuRenderer(),
            > +                    batch_size,
            > +                    self._preprocess_cell_for_model,
            > +                    MODEL_INPUT_SHAPE,
            > +                ),
            > +                max_prefetch=1,
            > +            ),
            > +            steps=validation_steps,
            > +            verbose=1,
            > +        )
            > ```
        metadata:
    -
        user:
            > Git apply result:
            > Found 1 diff block(s) to process using custom patcher.
            >
            > --- Processing Diff Block 1 ---
            > Identified target file: digit_classifier.py
            > Applying patch to 'digit_classifier.py' using custom patcher...
            > Successfully applied patch and wrote to digit_classifier.py.
            >
        metadata: