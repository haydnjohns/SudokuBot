local_system:
    attached_files:
        - digit_classifier.py
        - digit_extractor.py
        - sudoku_recogniser.py
        - sudoku_renderer.py
    conversation_file:
    compile_command:
    initial_file_contents:
        digit_classifier.py:
            > """
            > SudokuBot – digit classifier
            > Improved version 2025‑04‑21
            >
            > Major fixes
            > • data generator now really yields balanced batches
            > • preprocessing is tolerant – almost never rejects a cell
            > • **Improved CNN architecture (ResNet-style) for higher accuracy**
            > """
            >
            > # ------------------------------------------------------------------ #
            > # 1.  choose backend BEFORE importing keras
            > # ------------------------------------------------------------------ #
            > import os
            >
            > os.environ["KERAS_BACKEND"] = "torch"  # must be first – do NOT move
            >
            > # ------------------------------------------------------------------ #
            > # 2.  std‑lib & 3rd‑party imports
            > # ------------------------------------------------------------------ #
            > import gc
            > import random
            > from pathlib import Path
            > from typing import Callable, Generator, Optional, Tuple
            >
            > import cv2
            > import numpy as np
            > import torch
            > import keras
            > from keras import callbacks, layers, models, activations, regularizers
            >
            > # ------------------------------------------------------------------ #
            > # 3.  project‑local imports
            > # ------------------------------------------------------------------ #
            > # Assume these exist in the same directory or are installable
            > try:
            >     from sudoku_renderer import SudokuRenderer, generate_and_save_test_example
            >     from digit_extractor import (
            >         GRID_SIZE,
            >         extract_cells_from_image,
            >         rectify_grid,
            >         split_into_cells,
            >     )
            >     import sudoku_recogniser
            > except ImportError as e:
            >     print(f"Error importing local modules: {e}")
            >     print("Please ensure sudoku_renderer.py, digit_extractor.py, and sudoku_recogniser.py are available.")
            >     # Provide dummy implementations or raise error if essential
            >     GRID_SIZE = 9
            >     class SudokuRenderer:
            >         def render_sudoku(self, allow_empty=True): return None, None, None
            >     def generate_and_save_test_example(): return Path("dummy_test.png"), np.zeros((9,9), dtype=int)
            >     def extract_cells_from_image(path, debug=False): return [], None, None
            >     class sudoku_recogniser:
            >         FINAL_CONFIDENCE_THRESHOLD = 0.9
            >         @staticmethod
            >         def print_sudoku_grid(grid, confs=None, threshold=0.0): pass
            >
            >
            > # ------------------------------------------------------------------ #
            > # 4.  constants
            > # ------------------------------------------------------------------ #
            > MODEL_FILENAME = "sudoku_digit_classifier_resnet.keras" # Changed filename
            >
            > MODEL_INPUT_SHAPE = (28, 28, 1)
            > NUM_CLASSES = 11  # digits 0‑9 + “empty”
            > EMPTY_LABEL = 10
            >
            > TARGET_CELL_CONTENT_SIZE = 26          # preprocessing (Increased slightly)
            > TARGET_DIGIT_RATIO = 1.5               # 60 % digits / 40 % empty
            >
            > EPOCHS = 15 # Increased epochs slightly, EarlyStopping will handle it
            > STEPS_PER_EPOCH = 150 # Increased steps slightly
            > BATCH_SIZE = 256
            > VALIDATION_STEPS = 50
            >
            > DataBatch = Tuple[np.ndarray, np.ndarray]
            >
            > # ------------------------------------------------------------------ #
            > # 5.  balanced data generator (fixed) - unchanged
            > # ------------------------------------------------------------------ #
            > def sudoku_data_generator(
            >     renderer: SudokuRenderer,
            >     batch_size: int,
            >     preprocess_func: Callable[[np.ndarray], Optional[np.ndarray]],
            >     input_size: Tuple[int, int, int],
            >     target_digit_ratio: float = TARGET_DIGIT_RATIO,
            > ) -> Generator[DataBatch, None, None]:
            >     """
            >     Yield *balanced* batches of (cell, label).
            >
            >     The function never gives up early – it keeps sampling Sudokus until the
            >     required number of digit and empty cells has been collected.
            >     """
            >     total_cells = GRID_SIZE * GRID_SIZE
            >     # Calculate exact numbers needed for balance
            >     num_digits_float = batch_size * target_digit_ratio / (1 + target_digit_ratio)
            >     want_digits = int(round(num_digits_float))
            >     want_empty = batch_size - want_digits
            >
            >     # Ensure the sum is exactly batch_size after rounding
            >     if want_digits + want_empty != batch_size:
            >          # Adjust the one closer to its float representation's rounding direction
            >          if num_digits_float - int(num_digits_float) >= 0.5: # Rounded up
            >              want_digits = batch_size - want_empty
            >          else: # Rounded down
            >              want_empty = batch_size - want_digits
            >
            >     in_h, in_w = input_size[:2]
            >
            >     batch_counter = 0
            >     while True:
            >         xs, ys = [], []
            >         n_dig = n_emp = 0
            >
            >         needed_digits = want_digits
            >         needed_empty = want_empty
            >
            >         while needed_digits > 0 or needed_empty > 0:
            >             img, gt_grid, corners = renderer.render_sudoku(allow_empty=True)
            >             if img is None or corners is None:
            >                 continue
            >             rectified = rectify_grid(img, corners)
            >             if rectified is None:
            >                 continue
            >             cells, _ = split_into_cells(rectified)
            >             if len(cells) != total_cells:
            >                 continue
            >
            >             # iterate shuffled cell indices
            >             idxs = list(range(total_cells))
            >             random.shuffle(idxs)
            >
            >             for idx in idxs:
            >                 if needed_digits <= 0 and needed_empty <= 0:
            >                     break # Batch full
            >
            >                 cell = cells[idx]
            >                 # Handle potential None from gt_grid (though unlikely with allow_empty=True)
            >                 gt_val = gt_grid.flat[idx] if gt_grid is not None else 0
            >                 label = EMPTY_LABEL if gt_val == 0 else gt_val
            >
            >                 # Check if we still need this type of label
            >                 is_empty = (label == EMPTY_LABEL)
            >                 if is_empty and needed_empty <= 0:
            >                     continue
            >                 if not is_empty and needed_digits <= 0:
            >                     continue
            >
            >                 proc = preprocess_func(cell)
            >                 if proc is None:                       # should be rare now
            >                     continue
            >
            >                 # Add to batch and decrement needed count
            >                 xs.append(proc)
            >                 ys.append(label)
            >                 if is_empty:
            >                     needed_empty -= 1
            >                 else:
            >                     needed_digits -= 1
            >
            >
            >         # at this point we have a perfectly balanced batch
            >         x_arr = np.asarray(xs, dtype="float32")[..., np.newaxis]
            >         y_arr = np.asarray(ys, dtype="int64")
            >
            >         # Sanity check batch size and balance (optional)
            >         # assert len(xs) == batch_size, f"Batch size mismatch: expected {batch_size}, got {len(xs)}"
            >         # counts = np.bincount(y_arr, minlength=NUM_CLASSES)
            >         # assert counts[EMPTY_LABEL] == want_empty, f"Empty count mismatch: expected {want_empty}, got {counts[EMPTY_LABEL]}"
            >         # assert np.sum(counts[:EMPTY_LABEL]) == want_digits, f"Digit count mismatch: expected {want_digits}, got {np.sum(counts[:EMPTY_LABEL])}"
            >
            >
            >         p = np.random.permutation(batch_size) # Shuffle within the batch
            >         batch_counter += 1
            >
            >         # optional histo print for debugging
            >         if (
            >             os.environ.get("SUDOKU_DEBUG_GENERATOR", "0") == "1"
            >             and batch_counter % 500 == 0
            >         ):
            >             print(f"Batch {batch_counter} label histogram:", np.bincount(y_arr, minlength=NUM_CLASSES))
            >
            >         yield x_arr[p], y_arr[p]
            >         del xs, ys, x_arr, y_arr
            >         gc.collect()
            >
            >
            > # ------------------------------------------------------------------ #
            > # 6.  layer helpers (Removed _norm, using BN directly)
            > # ------------------------------------------------------------------ #
            > # Using ReLU directly in layers or via layers.Activation('relu')
            >
            > # ------------------------------------------------------------------ #
            > # 7.  classifier object
            > # ------------------------------------------------------------------ #
            > class DigitClassifier:
            >     """
            >     Handles loading, training and inference of the CNN digit classifier.
            >     Uses an improved ResNet-style architecture.
            >     """
            >
            >     # -------------------------------------------------------------- #
            >     # constructor
            >     # -------------------------------------------------------------- #
            >     def __init__(
            >         self,
            >         model_path: Optional[str | Path] = None,
            >         training_required: bool = False,
            >     ) -> None:
            >         self.model_path = Path(model_path) if model_path else Path(MODEL_FILENAME)
            >         self.model: Optional[keras.Model] = None
            >         self._model_input_size = MODEL_INPUT_SHAPE[:2]
            >
            >         if not training_required and self.model_path.exists():
            >             try:
            >                 # When loading custom objects like custom activation or layers (if any were used),
            >                 # you might need custom_objects={'CustomLayer': CustomLayer}
            >                 self.model = keras.models.load_model(self.model_path)
            >                 if self.model.input_shape[1:3] != self._model_input_size:
            >                     print(f"[Warning] Stored model input size {self.model.input_shape[1:3]} "
            >                           f"differs from expected {self._model_input_size}")
            >                 print(f"Digit-classifier model loaded from {self.model_path}")
            >             except Exception as e:
            >                 print(f"[Error] Failed to load model from {self.model_path} – will train from scratch ({e})")
            >                 self.model = None # Ensure model is None if loading failed
            >
            >         # If training is required, or loading failed, ensure model is None
            >         if training_required and self.model is not None:
            >              print("Training required, ignoring loaded model.")
            >              self.model = None
            >         elif training_required and self.model is None:
            >              print("Training required, model will be built.")
            >         elif not training_required and self.model is None:
            >              print("Model not found or failed to load, and training not required. Classifier will not work.")
            >
            >
            >     # -------------------------------------------------------------- #
            >     # ResNet-style building block
            >     # -------------------------------------------------------------- #
            >     def _residual_block(self, x, filters, strides=1, activation="relu"):
            >         """Basic residual block."""
            >         shortcut = x
            >         # Downsample shortcut if needed (stride > 1 or different number of filters)
            >         if strides > 1 or shortcut.shape[-1] != filters:
            >             shortcut = layers.Conv2D(
            >                 filters, 1, strides=strides, use_bias=False, kernel_initializer="he_normal"
            >             )(shortcut)
            >             shortcut = layers.BatchNormalization()(shortcut)
            >
            >         # First convolution
            >         y = layers.Conv2D(
            >             filters, 3, strides=strides, padding="same", use_bias=False, kernel_initializer="he_normal"
            >         )(x)
            >         y = layers.BatchNormalization()(y)
            >         y = layers.Activation(activation)(y)
            >
            >         # Second convolution
            >         y = layers.Conv2D(
            >             filters, 3, padding="same", use_bias=False, kernel_initializer="he_normal"
            >         )(y)
            >         y = layers.BatchNormalization()(y)
            >
            >         # Add shortcut
            >         y = layers.Add()([shortcut, y])
            >         y = layers.Activation(activation)(y)
            >         return y
            >
            >     # -------------------------------------------------------------- #
            >     # backbone (Improved ResNet-style)
            >     # -------------------------------------------------------------- #
            >     def _build_cnn_model(self) -> keras.Model:
            >         """Builds a small ResNet-style CNN model."""
            >         activation_func = "relu" # Or keep 'gelu' if preferred
            >
            >         x_in = keras.Input(shape=MODEL_INPUT_SHAPE)
            >
            >         # Initial Convolution (Stem) - adjusted for small 28x28 input
            >         # No initial max pooling needed for 28x28
            >         x = layers.Conv2D(32, 3, padding="same", use_bias=False, kernel_initializer="he_normal")(x_in)
            >         x = layers.BatchNormalization()(x)
            >         x = layers.Activation(activation_func)(x)
            >         # x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # Optional: if more aggressive downsampling needed early
            >
            >         # Residual Blocks
            >         # Block 1 (32 filters)
            >         x = self._residual_block(x, 32, activation=activation_func)
            >         x = self._residual_block(x, 32, activation=activation_func)
            >
            >         # Block 2 (64 filters, downsample)
            >         x = self._residual_block(x, 64, strides=2, activation=activation_func) # 28x28 -> 14x14
            >         x = self._residual_block(x, 64, activation=activation_func)
            >
            >         # Block 3 (128 filters, downsample)
            >         x = self._residual_block(x, 128, strides=2, activation=activation_func) # 14x14 -> 7x7
            >         x = self._residual_block(x, 128, activation=activation_func)
            >
            >         # Block 4 (256 filters, downsample) - Optional, maybe too much for 7x7
            >         # x = self._residual_block(x, 256, strides=2, activation=activation_func) # 7x7 -> 4x4
            >         # x = self._residual_block(x, 256, activation=activation_func)
            >
            >         # Classifier Head
            >         x = layers.GlobalAveragePooling2D()(x) # Feature vector
            >         x = layers.Flatten()(x) # Ensure flat vector after GAP
            >
            >         x = layers.Dense(128, kernel_initializer="he_normal")(x)
            >         x = layers.BatchNormalization()(x) # BN before activation in dense layers
            >         x = layers.Activation(activation_func)(x)
            >         x = layers.Dropout(0.5)(x) # Regularization
            >
            >         # Removed the intermediate 64-unit dense layer, maybe not needed
            >         # x = layers.Dense(64, activation=activation_func, kernel_initializer="he_normal")(x)
            >         # x = layers.Dropout(0.5)(x)
            >
            >         y_out = layers.Dense(NUM_CLASSES, activation="softmax")(x) # Output layer
            >
            >         model = models.Model(x_in, y_out, name="resnet_digits")
            >
            >         # Consider AdamW optimizer if available and needed
            >         # optimizer = keras.optimizers.AdamW(learning_rate=3e-4, weight_decay=1e-4)
            >         optimizer = keras.optimizers.Adam(learning_rate=3e-4)
            >
            >         model.compile(
            >             optimizer=optimizer,
            >             loss="sparse_categorical_crossentropy",
            >             metrics=["accuracy"],
            >         )
            >         model.summary()
            >         return model
            >
            >     # -------------------------------------------------------------- #
            >     # preprocessing (fixed – tolerant, slightly adjusted target size)
            >     # -------------------------------------------------------------- #
            >     def _preprocess_cell_for_model(self, cell: np.ndarray) -> Optional[np.ndarray]:
            >         """
            >         Convert raw cell → 28×28 float32 in [0,1].
            >         Never raises; returns None only if `cell` itself is invalid.
            >         """
            >         if cell is None or cell.size < 10: # Basic check for validity
            >             return None
            >
            >         # Ensure input is grayscale uint8
            >         if cell.ndim == 3 and cell.shape[2] == 3:
            >             gray = cv2.cvtColor(cell, cv2.COLOR_BGR2GRAY)
            >         elif cell.ndim == 2:
            >             gray = cell
            >         else: # Unexpected shape
            >              return None # Or try to handle other cases like RGBA
            >
            >         # Ensure uint8 type for thresholding
            >         if gray.dtype != np.uint8:
            >              # Try to safely convert (e.g., scale if it's float)
            >              if np.issubdtype(gray.dtype, np.floating):
            >                  gray = (gray * 255).clip(0, 255).astype(np.uint8)
            >              else:
            >                  gray = gray.astype(np.uint8) # Hope for the best
            >
            >         # --- Thresholding ---
            >         # Apply slight Gaussian blur before thresholding to reduce noise
            >         blurred = cv2.GaussianBlur(gray, (3, 3), 0)
            >
            >         # Adaptive thresholding (robust to varying lighting)
            >         try:
            >             # Block size needs to be odd and > 1. Choose based on image size.
            >             block_size = max(5, min(gray.shape[0], gray.shape[1]) // 4)
            >             if block_size % 2 == 0: block_size += 1 # Ensure odd
            >             thresh = cv2.adaptiveThreshold(
            >                 blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, block_size, 5 # C=5 is a decent starting point
            >             )
            >         except cv2.error:
            >             # Fallback to Otsu's method if adaptive fails (e.g., very small image)
            >             _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            >
            >         # --- Find digit bounding box ---
            >         pts = cv2.findNonZero(thresh)
            >         if pts is None:  # Cell is empty or thresholding failed
            >             return np.zeros(self._model_input_size, dtype="float32") # Return black canvas
            >
            >         x, y, w, h = cv2.boundingRect(pts)
            >         if w <= 0 or h <= 0: # Should not happen if pts is not None, but check anyway
            >             return np.zeros(self._model_input_size, dtype="float32")
            >
            >         roi = thresh[y : y + h, x : x + w]
            >
            >         # --- Resize and Center ---
            >         # Calculate scaling factor to fit ROI into TARGET_CELL_CONTENT_SIZE box
            >         # Use TARGET_CELL_CONTENT_SIZE (e.g., 26)
            >         target_size = TARGET_CELL_CONTENT_SIZE
            >         scale = min(target_size / w, target_size / h)
            >         new_w = max(1, int(round(w * scale)))
            >         new_h = max(1, int(round(h * scale)))
            >
            >         # Resize using INTER_AREA for shrinking
            >         resized = cv2.resize(roi, (new_w, new_h), interpolation=cv2.INTER_AREA)
            >
            >         # Create target canvas (28x28)
            >         canvas = np.zeros(self._model_input_size, dtype=np.uint8)
            >
            >         # Calculate padding to center the resized digit
            >         pad_top = (self._model_input_size[0] - new_h) // 2
            >         pad_left = (self._model_input_size[1] - new_w) // 2
            >
            >         # Place the resized digit onto the canvas
            >         canvas[pad_top : pad_top + new_h, pad_left : pad_left + new_w] = resized
            >
            >         # Normalize to [0, 1] float32
            >         return canvas.astype("float32") / 255.0
            >
            >     # -------------------------------------------------------------- #
            >     # training
            >     # -------------------------------------------------------------- #
            >     def train(
            >         self,
            >         epochs: int = EPOCHS,
            >         steps_per_epoch: int = STEPS_PER_EPOCH,
            >         batch_size: int = BATCH_SIZE,
            >         validation_steps: int = VALIDATION_STEPS,
            >     ) -> None:
            >         print(f"\nTraining: epochs={epochs} steps={steps_per_epoch} batch={batch_size}")
            >         if self.model is None:
            >             self.model = self._build_cnn_model()
            >         elif not isinstance(self.model, keras.Model):
            >              print("[Error] self.model is not a valid Keras model. Cannot train.")
            >              return
            >
            >         try:
            >             test_img_path, test_gt = generate_and_save_test_example()
            >             # Ensure classifier instance is passed correctly
            >             epoch_cb = EpochTestCallback(test_img_path, test_gt, self)
            >             if epoch_cb.preprocessed is None:
            >                  print("[Warning] EpochTestCallback disabled due to preprocessing issues.")
            >                  epoch_cb = None # Disable if setup failed
            >         except Exception as e:
            >             print(f"[Warning] Epoch-callback disabled during setup ({e})")
            >             epoch_cb = None
            >
            >         # Use a fresh renderer instance for each generator if state matters
            >         train_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >         val_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >
            >         # Callbacks
            >         cbs: list[callbacks.Callback] = [
            >             callbacks.EarlyStopping(
            >                 monitor="val_accuracy", # Monitor validation accuracy
            >                 patience=8,          # Increase patience slightly
            >                 restore_best_weights=True,
            >                 verbose=1,
            >                 mode='max' # We want to maximize accuracy
            >             ),
            >             callbacks.ModelCheckpoint(
            >                 filepath=self.model_path,
            >                 monitor="val_accuracy", # Save based on best validation accuracy
            >                 save_best_only=True,
            >                 verbose=1,
            >                 mode='max'
            >             ),
            >             callbacks.ReduceLROnPlateau(
            >                 monitor="val_accuracy", # Reduce LR based on validation accuracy
            >                 factor=0.3,          # More aggressive reduction factor
            >                 patience=4,          # Reduce LR sooner if plateauing
            >                 min_lr=1e-7,
            >                 verbose=1,
            >                 mode='max'
            >             ),
            >             # TensorBoard callback (optional, for visualization)
            >             # callbacks.TensorBoard(log_dir='./logs', histogram_freq=1)
            >         ]
            >         if epoch_cb: # Add epoch test callback only if it was initialized successfully
            >             cbs.append(epoch_cb)
            >
            >         # Start Training
            >         history = self.model.fit(
            >             train_gen,
            >             epochs=epochs,
            >             steps_per_epoch=steps_per_epoch,
            >             validation_data=val_gen,
            >             validation_steps=validation_steps,
            >             callbacks=cbs,
            >             verbose=1,
            >         )
            >
            >         # Load best weights back if EarlyStopping restored them
            >         # (ModelCheckpoint already saved the best one, but loading ensures the instance has them)
            >         if self.model_path.exists():
            >              print(f"Loading best weights from {self.model_path}")
            >              self.model.load_weights(self.model_path) # Use load_weights if only weights were saved, or load_model if entire model
            >
            >         print("\nFinal evaluation using best weights:")
            >         # Use a fresh generator for final evaluation
            >         final_eval_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >         loss, acc = self.model.evaluate(
            >             final_eval_gen,
            >             steps=validation_steps * 2, # Evaluate on more steps
            >             verbose=1,
            >         )
            >         print(f"Final val_loss={loss:.5f}  val_acc={acc:.5f}")
            >
            >         # Explicitly save the final best model (ModelCheckpoint should have done this, but belt-and-suspenders)
            >         print(f"Saving final best model to {self.model_path}")
            >         self.model.save(self.model_path)
            >
            >         del train_gen, val_gen, final_eval_gen
            >         gc.collect()
            >
            >     # -------------------------------------------------------------- #
            >     # inference
            >     # -------------------------------------------------------------- #
            >     @torch.no_grad() # Keep torch decorator if using torch backend
            >     def recognise(
            >         self,
            >         cell: np.ndarray,
            >         confidence_threshold: float = 0.9, # Increased default threshold
            >     ) -> Tuple[int, float]:
            >         """Recognises a single digit cell."""
            >         if self.model is None:
            >             print("[Error] Recognise called but model is not loaded.")
            >             return 0, 0.0
            >
            >         proc = self._preprocess_cell_for_model(cell)
            >         if proc is None:
            >             # This indicates an issue with the input cell itself
            >             # print("[Debug] Preprocessing returned None for a cell.")
            >             return 0, 0.0 # Treat as empty/unrecognizable
            >
            >         # Add batch and channel dimensions: (H, W) -> (1, H, W, 1)
            >         x = proc[np.newaxis, ..., np.newaxis]
            >
            >         # Predict using the Keras model
            >         # The torch.no_grad() context manager is primarily for PyTorch operations.
            >         # Keras with torch backend should handle inference mode correctly via training=False.
            >         # If using pure torch tensors were necessary: x_tensor = torch.from_numpy(x).float()
            >         probs = self.model(x, training=False) # Use training=False for inference
            >
            >         # Ensure probs is a NumPy array
            >         if hasattr(probs, 'numpy'): # TF tensor
            >             probs = probs.cpu().detach().numpy()
            >         elif isinstance(probs, torch.Tensor): # PyTorch tensor
            >             probs = probs.cpu().numpy()
            >         # If it's already numpy, do nothing
            >
            >         probs = probs[0] # Remove batch dimension
            >
            >         idx = int(np.argmax(probs))
            >         conf = float(probs[idx])
            >
            >         # Return 0 (empty) if classified as EMPTY_LABEL or confidence is too low
            >         if idx == EMPTY_LABEL or conf < confidence_threshold:
            >             # Optionally distinguish between low-conf digit and classified-empty
            >             # if idx == EMPTY_LABEL: print(f"Cell classified as empty (conf {conf:.3f})")
            >             # else: print(f"Cell classified as {idx} but low conf ({conf:.3f} < {confidence_threshold})")
            >             return 0, conf # Return 0 for empty/uncertain
            >         else:
            >             # Return the classified digit (1-9)
            >             return idx, conf
            >
            >
            > # ------------------------------------------------------------------ #
            > # 8.  epoch‑end callback (Unchanged conceptually, ensure imports/refs are correct)
            > # ------------------------------------------------------------------ #
            > class EpochTestCallback(callbacks.Callback):
            >     def __init__(
            >         self,
            >         test_img_path: Path | str,
            >         gt_grid: np.ndarray,
            >         classifier: "DigitClassifier", # Pass the classifier instance
            >         frequency: int = 1,
            >     ) -> None:
            >         super().__init__()
            >         self.frequency = max(1, frequency)
            >         self.gt_grid = gt_grid.flatten() # Flatten GT grid for easier comparison
            >         self.classifier = classifier # Store the classifier instance
            >         self.test_img_path = test_img_path
            >         self.preprocessed = None # Initialize as None
            >
            >         # --- Preprocessing moved to on_train_begin ---
            >         # This ensures the classifier's model is built before preprocessing
            >
            >     def on_train_begin(self, logs=None):
            >         # --- Preprocess test image cells here ---
            >         # Ensures the model (and its input size) exists if built dynamically
            >         print("[Callback] Preprocessing test example...")
            >         try:
            >             cells, _, _ = extract_cells_from_image(self.test_img_path, debug=False)
            >             if not cells or len(cells) != GRID_SIZE * GRID_SIZE:
            >                 print(f"[Callback] Failed to extract correct number of cells ({len(cells)}) from {self.test_img_path}")
            >                 self.preprocessed = None
            >                 return
            >
            >             buf = []
            >             model_input_size = self.classifier._model_input_size # Get from classifier
            >             for i, cell in enumerate(cells):
            >                 proc = self.classifier._preprocess_cell_for_model(cell)
            >                 if proc is None:
            >                     print(f"[Callback Warning] Preprocessing failed for cell {i}, using zeros.")
            >                     proc = np.zeros(model_input_size, dtype="float32")
            >                 buf.append(proc)
            >
            >             self.preprocessed = np.asarray(buf, dtype="float32")[..., np.newaxis]
            >             print(f"[Callback] Test example preprocessed successfully ({self.preprocessed.shape}).")
            >
            >         except Exception as e:
            >             print(f"[Callback Error] Failed during test example preprocessing: {e}")
            >             self.preprocessed = None
            >
            >
            >     def on_epoch_end(self, epoch, logs=None):
            >         # Check if preprocessing was successful and if it's the right epoch
            >         if self.preprocessed is None or (epoch + 1) % self.frequency != 0:
            >             return
            >
            >         if not hasattr(self.model, 'predict'):
            >              print("[Callback Error] Model object does not have predict method.")
            >              return
            >
            >         print(f"\n--- Epoch {epoch+1} Test Example Evaluation ---")
            >         try:
            >             # Use the model attached to the callback (which is the one being trained)
            >             probs = self.model.predict(self.preprocessed, verbose=0)
            >             idxs = np.argmax(probs, axis=1)
            >             confs = np.max(probs, axis=1)
            >
            >             # Apply the same logic as `recognise` for final prediction
            >             # Use a reasonable threshold for display purposes
            >             display_threshold = 0.7 # Lower than final recognition, just for display
            >             final = [
            >                 i if (i != EMPTY_LABEL and c >= display_threshold) else 0
            >                 for i, c in zip(idxs, confs)
            >             ]
            >             pred_grid_flat = np.asarray(final)
            >             pred_grid = pred_grid_flat.reshape(GRID_SIZE, GRID_SIZE)
            >             conf_grid = confs.reshape(GRID_SIZE, GRID_SIZE)
            >
            >             print("Ground Truth:")
            >             sudoku_recogniser.print_sudoku_grid(self.gt_grid.reshape(GRID_SIZE, GRID_SIZE)) # Reshape GT back
            >             print("Prediction (Thresholded):")
            >             sudoku_recogniser.print_sudoku_grid(pred_grid, conf_grid, threshold=display_threshold)
            >
            >             # Compare against the flattened ground truth
            >             correct_cells = (pred_grid_flat == self.gt_grid).sum()
            >             total_cells = GRID_SIZE * GRID_SIZE
            >             accuracy = correct_cells / total_cells
            >             print(f"Test Example Accuracy: {correct_cells}/{total_cells} = {accuracy:.4f}")
            >             print("--- End Epoch Test ---\n")
            >
            >         except Exception as e:
            >             print(f"[Callback Error] Failed during prediction or display: {e}")
            >
            >
            > # ------------------------------------------------------------------ #
            > # 9.  CLI helper
            > # ------------------------------------------------------------------ #
            > if __name__ == "__main__":
            >     # Set to True to force retraining even if a model file exists
            >     FORCE_TRAIN = False # Set to True to retrain
            >
            >     model_file = Path(MODEL_FILENAME)
            >     train_needed = FORCE_TRAIN or not model_file.exists()
            >
            >     if FORCE_TRAIN and model_file.exists():
            >         print(f"FORCE_TRAIN is True. Deleting existing model: {model_file}")
            >         try:
            >             model_file.unlink()
            >             train_needed = True # Ensure flag is set
            >         except OSError as e:
            >             print(f"Error deleting existing model: {e}")
            >             # Decide whether to proceed or exit
            >             # exit(1)
            >
            >     # Instantiate the classifier. It will try to load if train_needed is False.
            >     clf = DigitClassifier(model_path=model_file, training_required=train_needed)
            >
            >     # Train if needed (either forced or because loading failed/file missing)
            >     if train_needed:
            >         print("Starting training process...")
            >         clf.train()
            >         # After training, the best model should be saved and loaded by the train method.
            >         # Verify the model is loaded for the sanity check below.
            >         if clf.model is None:
            >              print("[Error] Training finished, but model is still None. Cannot proceed.")
            >              exit(1) # Exit if training failed to produce a model
            >     elif clf.model is None:
            >          print("[Error] Model loading failed, and training was not requested. Cannot proceed.")
            >          exit(1) # Exit if no model is available
            >     else:
            >          print("Model loaded successfully. Skipping training.")
            >
            >
            >     # Perform sanity check only if the model is available
            >     if clf.model:
            >         print("\nQuick sanity check:")
            >
            >         # Test 1: Vertical stroke (should ideally be 1)
            >         dummy1 = np.zeros((50, 50), np.uint8)
            >         cv2.line(dummy1, (25, 10), (25, 40), 255, 4) # Thicker line
            >         d1, c1 = clf.recognise(dummy1, confidence_threshold=0.5) # Use lower threshold for test
            >         print(f"Vertical stroke → {d1}  (conf {c1:.3f})")
            >
            >         # Test 2: Blank cell (should be 0)
            >         blank = np.zeros((50, 50), np.uint8)
            >         d0, c0 = clf.recognise(blank, confidence_threshold=0.5)
            >         print(f"Blank cell      → {d0}  (conf {c0:.3f})")
            >
            >         # Test 3: A simple digit (e.g., '7')
            >         dummy7 = np.zeros((50, 50), np.uint8)
            >         cv2.putText(dummy7, '7', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.5, 255, 3)
            >         d7, c7 = clf.recognise(dummy7, confidence_threshold=0.5)
            >         print(f"Digit '7'       → {d7}  (conf {c7:.3f})")
            >
            >     else:
            >         print("\nSanity check skipped: No model available.")
        digit_extractor.py:
            > """
            > Find and extract Sudoku grid cells from an image.
            > """
            >
            > import os
            > from pathlib import Path
            > from typing import List, Tuple, Optional
            >
            > import cv2
            > import numpy as np
            >
            > GRID_SIZE = 9
            > DEFAULT_RECTIFIED_SIZE = 450
            >
            >
            > def _order_points(pts: np.ndarray) -> np.ndarray:
            >     """Order four points as top-left, top-right, bottom-right, bottom-left."""
            >     pts = pts.reshape(4, 2).astype("float32")
            >     rect = np.zeros((4, 2), dtype="float32")
            >     s = pts.sum(axis=1)
            >     rect[0] = pts[np.argmin(s)]
            >     rect[2] = pts[np.argmax(s)]
            >     diff = pts[:, 1] - pts[:, 0]
            >     rect[1] = pts[np.argmin(diff)]
            >     rect[3] = pts[np.argmax(diff)]
            >     return rect
            >
            >
            > def find_sudoku_grid_contour(
            >     img: np.ndarray,
            >     debug_dir: Optional[Path] = None
            > ) -> np.ndarray:
            >     """
            >     Find the largest 4-point contour approximating the Sudoku grid boundary.
            >     """
            >     gray = (
            >         cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            >         if img.ndim == 3 else img.copy()
            >     )
            >
            >     if debug_dir:
            >         debug_dir.mkdir(parents=True, exist_ok=True)
            >
            >     blur = cv2.GaussianBlur(gray, (7, 7), 0)
            >     thresh = cv2.adaptiveThreshold(
            >         blur, 255,
            >         cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            >         cv2.THRESH_BINARY_INV,
            >         15, 4
            >     )
            >     closed = cv2.morphologyEx(
            >         thresh,
            >         cv2.MORPH_CLOSE,
            >         cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)),
            >         iterations=2
            >     )
            >
            >     contours, _ = cv2.findContours(
            >         closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
            >     )
            >     contours = sorted(contours, key=cv2.contourArea, reverse=True)
            >     min_area = gray.size * 0.1
            >
            >     for cnt in contours:
            >         if cv2.contourArea(cnt) < min_area:
            >             break
            >         peri = cv2.arcLength(cnt, True)
            >         approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)
            >         if len(approx) == 4 and cv2.isContourConvex(approx):
            >             x, y, w, h = cv2.boundingRect(approx)
            >             aspect = w / float(h)
            >             if 0.8 < aspect < 1.2:
            >                 return approx.reshape(4, 2).astype("float32")
            >
            >     raise ValueError("Sudoku grid contour not found.")
            >
            >
            > def rectify_grid(
            >     img: np.ndarray,
            >     contour: np.ndarray,
            >     size: int = DEFAULT_RECTIFIED_SIZE
            > ) -> Optional[np.ndarray]:
            >     """Perspective-correct the Sudoku grid to a square of given size."""
            >     try:
            >         src = _order_points(contour)
            >         dst = np.array([
            >             [0, 0],
            >             [size - 1, 0],
            >             [size - 1, size - 1],
            >             [0, size - 1],
            >         ], dtype="float32")
            >         mat = cv2.getPerspectiveTransform(src, dst)
            >         return cv2.warpPerspective(img, mat, (size, size))
            >     except cv2.error:
            >         return None
            >
            >
            > def split_into_cells(
            >     rectified: np.ndarray
            > ) -> Tuple[List[np.ndarray], np.ndarray]:
            >     """
            >     Split the rectified grid into GRID_SIZE × GRID_SIZE cell images.
            >     Returns (cells, rectified_image).
            >     """
            >     h, w = rectified.shape[:2]
            >     if h != w:
            >         size = max(h, w)
            >         rectified = cv2.resize(rectified, (size, size))
            >         h = w = size
            >
            >     cell_sz = h // GRID_SIZE
            >     margin = int(cell_sz * 0.04)
            >     cells: List[np.ndarray] = []
            >
            >     for row in range(GRID_SIZE):
            >         for col in range(GRID_SIZE):
            >             y0 = row * cell_sz + margin
            >             x0 = col * cell_sz + margin
            >             y1 = (row + 1) * cell_sz - margin
            >             x1 = (col + 1) * cell_sz - margin
            >             if y0 >= y1 or x0 >= x1:
            >                 cell = np.zeros((cell_sz, cell_sz), rectified.dtype)
            >             else:
            >                 cell = rectified[y0:y1, x0:x1]
            >             cells.append(cell)
            >
            >     return cells, rectified
            >
            >
            > def extract_cells_from_image(
            >     img_or_path,
            >     size: int = DEFAULT_RECTIFIED_SIZE,
            >     debug: bool = False
            > ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray], Optional[np.ndarray]]:
            >     """
            >     High-level function: read image, find grid, rectify, and split into cells.
            >     Returns (cells, rectified_image, contour) or (None, None, None) on failure.
            >     """
            >     if isinstance(img_or_path, (str, Path)):
            >         img = cv2.imread(str(img_or_path))
            >         if img is None:
            >             return None, None, None
            >     elif isinstance(img_or_path, np.ndarray):
            >         img = img_or_path.copy()
            >     else:
            >         return None, None, None
            >
            >     try:
            >         debug_dir = Path(f"debug_{os.getpid()}") if debug else None
            >         contour = find_sudoku_grid_contour(img, debug_dir)
            >         rectified = rectify_grid(img, contour, size=size)
            >         if rectified is None:
            >             return None, None, None
            >         cells, rectified = split_into_cells(rectified)
            >         return cells, rectified, contour
            >     except Exception as exc:
            >         print(f"[Extractor] {exc}")
            >         return None, None, None
            >
        sudoku_recogniser.py:
            > """
            > Command-line utility to detect a Sudoku grid in an image and recognise its digits.
            > """
            >
            > from __future__ import annotations
            >
            > import sys
            > import time
            > from pathlib import Path
            > from typing import Tuple, Optional
            >
            > import cv2
            > import numpy as np
            >
            > import digit_classifier
            > from digit_extractor import GRID_SIZE, extract_cells_from_image
            >
            > FINAL_CONFIDENCE_THRESHOLD = 0.80
            >
            >
            > def print_sudoku_grid(
            >     grid: np.ndarray,
            >     conf: Optional[np.ndarray] = None,
            >     threshold: float = FINAL_CONFIDENCE_THRESHOLD
            > ) -> None:
            >     """Nicely print a 9×9 Sudoku grid, marking low‑confidence digits as '?'. """
            >     grid = np.asarray(grid)
            >     if grid.shape != (GRID_SIZE, GRID_SIZE):
            >         print("[print_sudoku_grid] invalid shape")
            >         return
            >
            >     for r in range(GRID_SIZE):
            >         if r > 0 and r % 3 == 0:
            >             print("|-----+-------+-----|")
            >
            >         tokens = []
            >         for c in range(GRID_SIZE):
            >             d = grid[r, c]
            >             if d == 0:
            >                 tok = "."
            >             else:
            >                 tok = str(d)
            >                 if conf is not None and conf[r, c] < threshold:
            >                     tok = "?"
            >             tokens.append(tok)
            >             if (c + 1) % 3 == 0 and c < GRID_SIZE - 1:
            >                 tokens.append("|")
            >         print(" ".join(tokens))
            >     print()
            >
            >
            > def display_results_on_image(
            >     rectified: Optional[np.ndarray],
            >     grid: np.ndarray
            > ) -> Optional[np.ndarray]:
            >     """
            >     Draw recognised digits onto the rectified grid image and return it.
            >     """
            >     if rectified is None:
            >         return None
            >
            >     img = (
            >         cv2.cvtColor(rectified, cv2.COLOR_GRAY2BGR)
            >         if rectified.ndim == 2 else rectified.copy()
            >     )
            >     h, w = img.shape[:2]
            >     cell_h, cell_w = h // GRID_SIZE, w // GRID_SIZE
            >
            >     for r in range(GRID_SIZE):
            >         for c in range(GRID_SIZE):
            >             d = grid[r, c]
            >             if d == 0:
            >                 continue
            >             text = str(d)
            >             (tw, th), _ = cv2.getTextSize(
            >                 text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2
            >             )
            >             x = c * cell_w + (cell_w - tw) // 2
            >             y = r * cell_h + (cell_h + th) // 2
            >             cv2.putText(
            >                 img, text, (x, y),
            >                 cv2.FONT_HERSHEY_SIMPLEX,
            >                 1, (0, 255, 0), 2, cv2.LINE_AA
            >             )
            >     return img
            >
            >
            > def recognise_sudoku(
            >     img_path: Path,
            >     classifier: digit_classifier.DigitClassifier
            > ) -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:
            >     """
            >     Extract cells and run the classifier on each one.
            >     Returns (predicted_grid, confidence_grid, rectified_image).
            >     """
            >     print(f"Processing {img_path} ...")
            >     start = time.time()
            >     cells, rectified, _ = extract_cells_from_image(img_path)
            >     if cells is None or rectified is None:
            >         raise RuntimeError("Extraction failed.")
            >
            >     pred = np.zeros((GRID_SIZE, GRID_SIZE), int)
            >     conf = np.zeros_like(pred, float)
            >
            >     for i, cell in enumerate(cells):
            >         r, c = divmod(i, GRID_SIZE)
            >         d, cf = classifier.recognise(cell, confidence_threshold=0.1)
            >         conf[r, c] = cf
            >         if d != 0 and cf >= FINAL_CONFIDENCE_THRESHOLD:
            >             pred[r, c] = d
            >
            >     elapsed = time.time() - start
            >     print(f"Done in {elapsed:.2f}s")
            >     return pred, conf, rectified
            >
            >
            > def main() -> None:
            >     if len(sys.argv) < 2:
            >         print("Usage: sudoku_recogniser.py <image_path>")
            >         sys.exit(0)
            >
            >     img_path = Path(sys.argv[1])
            >     if not img_path.exists():
            >         print(f"Image not found: {img_path}")
            >         sys.exit(1)
            >
            >     classifier = digit_classifier.DigitClassifier(model_path=digit_classifier.MODEL_FILENAME)
            >     if classifier.model is None:
            >         print("Model missing—training required.")
            >         classifier.train()
            >
            >     grid, conf, rectified = recognise_sudoku(img_path, classifier)
            >     print_sudoku_grid(grid, conf)
            >
            >     result_img = display_results_on_image(rectified, grid)
            >     if result_img is not None:
            >         cv2.imshow("Sudoku Recognition", result_img)
            >         cv2.waitKey(0)
            >         cv2.destroyAllWindows()
            >
            >
            > if __name__ == "__main__":
            >     main()
            >
        sudoku_renderer.py:
            > """
            > Synthetic Sudoku image generator for on‑the‑fly training data.
            > """
            >
            > import random
            > from pathlib import Path
            > from typing import Tuple, Optional
            >
            > import cv2
            > import numpy as np
            > import keras
            >
            > GRID_SIZE = 9
            > BASE_IMAGE_SIZE = 1000
            > CELL_SIZE = BASE_IMAGE_SIZE // GRID_SIZE
            >
            >
            > def _order_points(pts: np.ndarray) -> np.ndarray:
            >     """Order four points as TL, TR, BR, BL."""
            >     pts = pts.reshape(4, 2).astype("float32")
            >     rect = np.zeros((4, 2), dtype="float32")
            >     s = pts.sum(axis=1)
            >     rect[0] = pts[np.argmin(s)]
            >     rect[2] = pts[np.argmax(s)]
            >     diff = pts[:, 1] - pts[:, 0]
            >     rect[1] = pts[np.argmin(diff)]
            >     rect[3] = pts[np.argmax(diff)]
            >     return rect
            >
            >
            > def _load_mnist_digits() -> dict[int, list[np.ndarray]]:
            >     """
            >     Download MNIST once and bucket images by label for rendering.
            >     """
            >     (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
            >     images = np.concatenate([x_train, x_test])
            >     labels = np.concatenate([y_train, y_test])
            >
            >     buckets: dict[int, list[np.ndarray]] = {i: [] for i in range(10)}
            >     for img, lbl in zip(images, labels):
            >         inv = cv2.bitwise_not(img)
            >         padded = cv2.copyMakeBorder(
            >             inv, 4, 4, 4, 4,
            >             cv2.BORDER_CONSTANT, value=255
            >         )
            >         buckets[int(lbl)].append(padded)
            >     return buckets
            >
            >
            > class SudokuRenderer:
            >     """
            >     Render a random (or specified) Sudoku grid to a synthetic image.
            >     """
            >
            >     def __init__(self) -> None:
            >         self.mnist_buckets: Optional[dict[int, list[np.ndarray]]] = None
            >
            >     def _digit_source(self, digit: int) -> Tuple[Optional[np.ndarray], str]:
            >         if self.mnist_buckets is None:
            >             self.mnist_buckets = _load_mnist_digits()
            >
            >         sources = []
            >         if self.mnist_buckets[digit]:
            >             sources.append("mnist")
            >         sources.append("font")
            >         choice = random.choice(sources)
            >
            >         if choice == "mnist":
            >             img = random.choice(self.mnist_buckets[digit])
            >             if img.ndim == 2:
            >                 img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
            >             return img, "mnist"
            >         return None, "font"
            >
            >     def render_sudoku(
            >         self,
            >         grid_spec: Optional[list[list[int | None]]] = None,
            >         *,
            >         allow_empty: bool = True
            >     ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
            >         """
            >         Generate a synthetic Sudoku image.
            >         Returns (image, ground_truth_grid, warped_corners).
            >         """
            >         if grid_spec is None:
            >             gt = np.zeros((GRID_SIZE, GRID_SIZE), int)
            >             for r in range(GRID_SIZE):
            >                 for c in range(GRID_SIZE):
            >                     if allow_empty and random.random() < 0.4:
            >                         continue
            >                     gt[r, c] = random.randint(1, 9)
            >         else:
            >             gt = np.array([[d or 0 for d in row] for row in grid_spec], int)
            >
            >         bg = tuple(random.randint(200, 240) for _ in range(3))
            >         img = np.full((BASE_IMAGE_SIZE, BASE_IMAGE_SIZE, 3), bg, np.uint8)
            >
            >         # draw grid lines
            >         for i in range(GRID_SIZE + 1):
            >             major = (i % 3 == 0)
            >             thickness = random.randint(3 if major else 1, 5 if major else 3)
            >             cv2.line(img, (0, i*CELL_SIZE), (BASE_IMAGE_SIZE, i*CELL_SIZE), (0, 0, 0), thickness)
            >             cv2.line(img, (i*CELL_SIZE, 0), (i*CELL_SIZE, BASE_IMAGE_SIZE), (0, 0, 0), thickness)
            >
            >         # draw digits
            >         for r in range(GRID_SIZE):
            >             for c in range(GRID_SIZE):
            >                 d = gt[r, c]
            >                 if d == 0:
            >                     continue
            >
            >                 src_img, src_type = self._digit_source(d)
            >                 scale = random.uniform(0.5, 0.8)
            >                 tgt = int(CELL_SIZE * scale)
            >                 center_x = c*CELL_SIZE + CELL_SIZE//2
            >                 center_y = r*CELL_SIZE + CELL_SIZE//2
            >                 dx = int(random.uniform(-0.1, 0.1)*CELL_SIZE)
            >                 dy = int(random.uniform(-0.1, 0.1)*CELL_SIZE)
            >                 cx, cy = center_x + dx, center_y + dy
            >
            >                 if src_type == "mnist":
            >                     digit = cv2.resize(src_img, (tgt, tgt))
            >                     angle = random.uniform(-10, 10)
            >                     M = cv2.getRotationMatrix2D((tgt/2, tgt/2), angle, 1)
            >                     digit = cv2.warpAffine(
            >                         digit, M, (tgt, tgt),
            >                         borderMode=cv2.BORDER_CONSTANT, borderValue=(255,255,255)
            >                     )
            >                     mask = cv2.cvtColor(digit, cv2.COLOR_BGR2GRAY)
            >                     _, mask = cv2.threshold(mask, 250, 255, cv2.THRESH_BINARY_INV)
            >
            >                     x0 = max(0, cx - tgt//2)
            >                     y0 = max(0, cy - tgt//2)
            >                     roi = img[y0:y0+tgt, x0:x0+tgt]
            >                     m_inv = cv2.bitwise_not(mask[:roi.shape[0], :roi.shape[1]])
            >                     bg_region = cv2.bitwise_and(roi, roi, mask=m_inv)
            >                     fg_region = cv2.bitwise_and(digit, digit, mask=mask[:roi.shape[0], :roi.shape[1]])
            >                     img[y0:y0+roi.shape[0], x0:x0+roi.shape[1]] = cv2.add(bg_region, fg_region)
            >                 else:
            >                     font = cv2.FONT_HERSHEY_SIMPLEX
            >                     thickness = random.randint(1, 3)
            >                     font_scale = cv2.getFontScaleFromHeight(font, tgt, thickness) * 0.8
            >                     text = str(d)
            >                     tw, th = cv2.getTextSize(text, font, font_scale, thickness)[0]
            >                     x = cx - tw//2
            >                     y = cy + th//2
            >                     cv2.putText(img, text, (x, y),
            >                                 font, font_scale, (0, 0, 0), thickness, cv2.LINE_AA)
            >
            >         # add noise
            >         noise = np.random.normal(0, random.uniform(5,20), img.shape).astype(np.float32)
            >         noisy = np.clip(img.astype(np.float32) + noise, 0, 255).astype(np.uint8)
            >
            >         # random perspective warp
            >         h, w = noisy.shape[:2]
            >         orig = np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]], dtype="float32")
            >         shift = random.uniform(0.05, 0.2)
            >         max_dx, max_dy = w*shift, h*shift
            >         dst = np.array([
            >             [random.uniform(0, max_dx), random.uniform(0, max_dy)],
            >             [w-1-random.uniform(0, max_dx), random.uniform(0, max_dy)],
            >             [w-1-random.uniform(-max_dx*0.2, max_dx), h-1-random.uniform(0, max_dy)],
            >             [random.uniform(-max_dx*0.2, max_dx), h-1-random.uniform(0, max_dy)],
            >         ], dtype="float32")
            >         M = cv2.getPerspectiveTransform(orig, dst)
            >         out_w = int(dst[:,0].max()) + 1
            >         out_h = int(dst[:,1].max()) + 1
            >         warped = cv2.warpPerspective(
            >             noisy, M, (out_w, out_h), borderMode=cv2.BORDER_REPLICATE
            >         )
            >
            >         return warped, gt, dst
            >
            >
            > def generate_and_save_test_example(
            >     prefix: str = "epoch_test_sudoku",
            >     force: bool = False
            > ) -> Tuple[str, np.ndarray]:
            >     """
            >     Generate or load a fixed Sudoku test example for epoch callbacks.
            >     Returns (image_path, ground_truth_grid).
            >     """
            >     img_path = Path(f"{prefix}.png")
            >     gt_path = Path(f"{prefix}_gt.npy")
            >
            >     if not force and img_path.exists() and gt_path.exists():
            >         return str(img_path), np.load(gt_path)
            >
            >     renderer = SudokuRenderer()
            >     grid_spec = [
            >         [None, None, 3,    None, None, 6,    None, 8,    None],
            >         [8,    None, 1,    None, 3,    None, 5,    None, 4   ],
            >         [None, 4,    None, 8,    None, 7,    None, 1,    None],
            >         [1,    None, None, 4,    None, 5,    None, None, 9   ],
            >         [None, 7,    None, None, 2,    None, None, 4,    None],
            >         [5,    None, None, 7,    None, 1,    None, None, 3   ],
            >         [None, 8,    None, 5,    None, 3,    None, 9,    None],
            >         [7,    None, 4,    None, 9,    None, 1,    None, 8   ],
            >         [None, 1,    None, 6,    None, None, 4,    None, None],
            >     ]
            >     img, gt, _ = renderer.render_sudoku(grid_spec=grid_spec)
            >     cv2.imwrite(str(img_path), img)
            >     np.save(gt_path, gt)
            >     return str(img_path), gt
            >
    prev_file_contents:
        digit_classifier.py:
            > """
            > SudokuBot – digit classifier
            > Improved version 2025‑04‑21
            >
            > Major fixes
            > • data generator now really yields balanced batches
            > • preprocessing is tolerant – almost never rejects a cell
            > • **Improved CNN architecture (ResNet-style) for higher accuracy**
            > """
            >
            > # ------------------------------------------------------------------ #
            > # 1.  choose backend BEFORE importing keras
            > # ------------------------------------------------------------------ #
            > import os
            >
            > os.environ["KERAS_BACKEND"] = "torch"  # must be first – do NOT move
            >
            > # ------------------------------------------------------------------ #
            > # 2.  std‑lib & 3rd‑party imports
            > # ------------------------------------------------------------------ #
            > import gc
            > import random
            > from pathlib import Path
            > from typing import Callable, Generator, Optional, Tuple
            >
            > import cv2
            > import numpy as np
            > import torch
            > import keras
            > from keras import callbacks, layers, models, activations, regularizers
            >
            > # ------------------------------------------------------------------ #
            > # 3.  project‑local imports
            > # ------------------------------------------------------------------ #
            > # Assume these exist in the same directory or are installable
            > try:
            >     from sudoku_renderer import SudokuRenderer, generate_and_save_test_example
            >     from digit_extractor import (
            >         GRID_SIZE,
            >         extract_cells_from_image,
            >         rectify_grid,
            >         split_into_cells,
            >     )
            >     import sudoku_recogniser
            > except ImportError as e:
            >     print(f"Error importing local modules: {e}")
            >     print("Please ensure sudoku_renderer.py, digit_extractor.py, and sudoku_recogniser.py are available.")
            >     # Provide dummy implementations or raise error if essential
            >     GRID_SIZE = 9
            >     class SudokuRenderer:
            >         def render_sudoku(self, allow_empty=True): return None, None, None
            >     def generate_and_save_test_example(): return Path("dummy_test.png"), np.zeros((9,9), dtype=int)
            >     def extract_cells_from_image(path, debug=False): return [], None, None
            >     class sudoku_recogniser:
            >         FINAL_CONFIDENCE_THRESHOLD = 0.9
            >         @staticmethod
            >         def print_sudoku_grid(grid, confs=None, threshold=0.0): pass
            >
            >
            > # ------------------------------------------------------------------ #
            > # 4.  constants
            > # ------------------------------------------------------------------ #
            > MODEL_FILENAME = "sudoku_digit_classifier_resnet.keras" # Changed filename
            >
            > MODEL_INPUT_SHAPE = (28, 28, 1)
            > NUM_CLASSES = 11  # digits 0‑9 + “empty”
            > EMPTY_LABEL = 10
            >
            > TARGET_CELL_CONTENT_SIZE = 26          # preprocessing (Increased slightly)
            > TARGET_DIGIT_RATIO = 1.5               # 60 % digits / 40 % empty
            >
            > EPOCHS = 15 # Increased epochs slightly, EarlyStopping will handle it
            > STEPS_PER_EPOCH = 150 # Increased steps slightly
            > BATCH_SIZE = 256
            > VALIDATION_STEPS = 50
            >
            > DataBatch = Tuple[np.ndarray, np.ndarray]
            >
            > # ------------------------------------------------------------------ #
            > # 5.  balanced data generator (fixed) - unchanged
            > # ------------------------------------------------------------------ #
            > def sudoku_data_generator(
            >     renderer: SudokuRenderer,
            >     batch_size: int,
            >     preprocess_func: Callable[[np.ndarray], Optional[np.ndarray]],
            >     input_size: Tuple[int, int, int],
            >     target_digit_ratio: float = TARGET_DIGIT_RATIO,
            > ) -> Generator[DataBatch, None, None]:
            >     """
            >     Yield *balanced* batches of (cell, label).
            >
            >     The function never gives up early – it keeps sampling Sudokus until the
            >     required number of digit and empty cells has been collected.
            >     """
            >     total_cells = GRID_SIZE * GRID_SIZE
            >     # Calculate exact numbers needed for balance
            >     num_digits_float = batch_size * target_digit_ratio / (1 + target_digit_ratio)
            >     want_digits = int(round(num_digits_float))
            >     want_empty = batch_size - want_digits
            >
            >     # Ensure the sum is exactly batch_size after rounding
            >     if want_digits + want_empty != batch_size:
            >          # Adjust the one closer to its float representation's rounding direction
            >          if num_digits_float - int(num_digits_float) >= 0.5: # Rounded up
            >              want_digits = batch_size - want_empty
            >          else: # Rounded down
            >              want_empty = batch_size - want_digits
            >
            >     in_h, in_w = input_size[:2]
            >
            >     batch_counter = 0
            >     while True:
            >         xs, ys = [], []
            >         n_dig = n_emp = 0
            >
            >         needed_digits = want_digits
            >         needed_empty = want_empty
            >
            >         while needed_digits > 0 or needed_empty > 0:
            >             img, gt_grid, corners = renderer.render_sudoku(allow_empty=True)
            >             if img is None or corners is None:
            >                 continue
            >             rectified = rectify_grid(img, corners)
            >             if rectified is None:
            >                 continue
            >             cells, _ = split_into_cells(rectified)
            >             if len(cells) != total_cells:
            >                 continue
            >
            >             # iterate shuffled cell indices
            >             idxs = list(range(total_cells))
            >             random.shuffle(idxs)
            >
            >             for idx in idxs:
            >                 if needed_digits <= 0 and needed_empty <= 0:
            >                     break # Batch full
            >
            >                 cell = cells[idx]
            >                 # Handle potential None from gt_grid (though unlikely with allow_empty=True)
            >                 gt_val = gt_grid.flat[idx] if gt_grid is not None else 0
            >                 label = EMPTY_LABEL if gt_val == 0 else gt_val
            >
            >                 # Check if we still need this type of label
            >                 is_empty = (label == EMPTY_LABEL)
            >                 if is_empty and needed_empty <= 0:
            >                     continue
            >                 if not is_empty and needed_digits <= 0:
            >                     continue
            >
            >                 proc = preprocess_func(cell)
            >                 if proc is None:                       # should be rare now
            >                     continue
            >
            >                 # Add to batch and decrement needed count
            >                 xs.append(proc)
            >                 ys.append(label)
            >                 if is_empty:
            >                     needed_empty -= 1
            >                 else:
            >                     needed_digits -= 1
            >
            >
            >         # at this point we have a perfectly balanced batch
            >         x_arr = np.asarray(xs, dtype="float32")[..., np.newaxis]
            >         y_arr = np.asarray(ys, dtype="int64")
            >
            >         # Sanity check batch size and balance (optional)
            >         # assert len(xs) == batch_size, f"Batch size mismatch: expected {batch_size}, got {len(xs)}"
            >         # counts = np.bincount(y_arr, minlength=NUM_CLASSES)
            >         # assert counts[EMPTY_LABEL] == want_empty, f"Empty count mismatch: expected {want_empty}, got {counts[EMPTY_LABEL]}"
            >         # assert np.sum(counts[:EMPTY_LABEL]) == want_digits, f"Digit count mismatch: expected {want_digits}, got {np.sum(counts[:EMPTY_LABEL])}"
            >
            >
            >         p = np.random.permutation(batch_size) # Shuffle within the batch
            >         batch_counter += 1
            >
            >         # optional histo print for debugging
            >         if (
            >             os.environ.get("SUDOKU_DEBUG_GENERATOR", "0") == "1"
            >             and batch_counter % 500 == 0
            >         ):
            >             print(f"Batch {batch_counter} label histogram:", np.bincount(y_arr, minlength=NUM_CLASSES))
            >
            >         yield x_arr[p], y_arr[p]
            >         del xs, ys, x_arr, y_arr
            >         gc.collect()
            >
            >
            > # ------------------------------------------------------------------ #
            > # 6.  layer helpers (Removed _norm, using BN directly)
            > # ------------------------------------------------------------------ #
            > # Using ReLU directly in layers or via layers.Activation('relu')
            >
            > # ------------------------------------------------------------------ #
            > # 7.  classifier object
            > # ------------------------------------------------------------------ #
            > class DigitClassifier:
            >     """
            >     Handles loading, training and inference of the CNN digit classifier.
            >     Uses an improved ResNet-style architecture.
            >     """
            >
            >     # -------------------------------------------------------------- #
            >     # constructor
            >     # -------------------------------------------------------------- #
            >     def __init__(
            >         self,
            >         model_path: Optional[str | Path] = None,
            >         training_required: bool = False,
            >     ) -> None:
            >         self.model_path = Path(model_path) if model_path else Path(MODEL_FILENAME)
            >         self.model: Optional[keras.Model] = None
            >         self._model_input_size = MODEL_INPUT_SHAPE[:2]
            >
            >         if not training_required and self.model_path.exists():
            >             try:
            >                 # When loading custom objects like custom activation or layers (if any were used),
            >                 # you might need custom_objects={'CustomLayer': CustomLayer}
            >                 self.model = keras.models.load_model(self.model_path)
            >                 if self.model.input_shape[1:3] != self._model_input_size:
            >                     print(f"[Warning] Stored model input size {self.model.input_shape[1:3]} "
            >                           f"differs from expected {self._model_input_size}")
            >                 print(f"Digit-classifier model loaded from {self.model_path}")
            >             except Exception as e:
            >                 print(f"[Error] Failed to load model from {self.model_path} – will train from scratch ({e})")
            >                 self.model = None # Ensure model is None if loading failed
            >
            >         # If training is required, or loading failed, ensure model is None
            >         if training_required and self.model is not None:
            >              print("Training required, ignoring loaded model.")
            >              self.model = None
            >         elif training_required and self.model is None:
            >              print("Training required, model will be built.")
            >         elif not training_required and self.model is None:
            >              print("Model not found or failed to load, and training not required. Classifier will not work.")
            >
            >
            >     # -------------------------------------------------------------- #
            >     # ResNet-style building block
            >     # -------------------------------------------------------------- #
            >     def _residual_block(self, x, filters, strides=1, activation="relu"):
            >         """Basic residual block."""
            >         shortcut = x
            >         # Downsample shortcut if needed (stride > 1 or different number of filters)
            >         if strides > 1 or shortcut.shape[-1] != filters:
            >             shortcut = layers.Conv2D(
            >                 filters, 1, strides=strides, use_bias=False, kernel_initializer="he_normal"
            >             )(shortcut)
            >             shortcut = layers.BatchNormalization()(shortcut)
            >
            >         # First convolution
            >         y = layers.Conv2D(
            >             filters, 3, strides=strides, padding="same", use_bias=False, kernel_initializer="he_normal"
            >         )(x)
            >         y = layers.BatchNormalization()(y)
            >         y = layers.Activation(activation)(y)
            >
            >         # Second convolution
            >         y = layers.Conv2D(
            >             filters, 3, padding="same", use_bias=False, kernel_initializer="he_normal"
            >         )(y)
            >         y = layers.BatchNormalization()(y)
            >
            >         # Add shortcut
            >         y = layers.Add()([shortcut, y])
            >         y = layers.Activation(activation)(y)
            >         return y
            >
            >     # -------------------------------------------------------------- #
            >     # backbone (Improved ResNet-style)
            >     # -------------------------------------------------------------- #
            >     def _build_cnn_model(self) -> keras.Model:
            >         """Builds a small ResNet-style CNN model."""
            >         activation_func = "relu" # Or keep 'gelu' if preferred
            >
            >         x_in = keras.Input(shape=MODEL_INPUT_SHAPE)
            >
            >         # Initial Convolution (Stem) - adjusted for small 28x28 input
            >         # No initial max pooling needed for 28x28
            >         x = layers.Conv2D(32, 3, padding="same", use_bias=False, kernel_initializer="he_normal")(x_in)
            >         x = layers.BatchNormalization()(x)
            >         x = layers.Activation(activation_func)(x)
            >         # x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # Optional: if more aggressive downsampling needed early
            >
            >         # Residual Blocks
            >         # Block 1 (32 filters)
            >         x = self._residual_block(x, 32, activation=activation_func)
            >         x = self._residual_block(x, 32, activation=activation_func)
            >
            >         # Block 2 (64 filters, downsample)
            >         x = self._residual_block(x, 64, strides=2, activation=activation_func) # 28x28 -> 14x14
            >         x = self._residual_block(x, 64, activation=activation_func)
            >
            >         # Block 3 (128 filters, downsample)
            >         x = self._residual_block(x, 128, strides=2, activation=activation_func) # 14x14 -> 7x7
            >         x = self._residual_block(x, 128, activation=activation_func)
            >
            >         # Block 4 (256 filters, downsample) - Optional, maybe too much for 7x7
            >         # x = self._residual_block(x, 256, strides=2, activation=activation_func) # 7x7 -> 4x4
            >         # x = self._residual_block(x, 256, activation=activation_func)
            >
            >         # Classifier Head
            >         x = layers.GlobalAveragePooling2D()(x) # Feature vector
            >         x = layers.Flatten()(x) # Ensure flat vector after GAP
            >
            >         x = layers.Dense(128, kernel_initializer="he_normal")(x)
            >         x = layers.BatchNormalization()(x) # BN before activation in dense layers
            >         x = layers.Activation(activation_func)(x)
            >         x = layers.Dropout(0.5)(x) # Regularization
            >
            >         # Removed the intermediate 64-unit dense layer, maybe not needed
            >         # x = layers.Dense(64, activation=activation_func, kernel_initializer="he_normal")(x)
            >         # x = layers.Dropout(0.5)(x)
            >
            >         y_out = layers.Dense(NUM_CLASSES, activation="softmax")(x) # Output layer
            >
            >         model = models.Model(x_in, y_out, name="resnet_digits")
            >
            >         # Consider AdamW optimizer if available and needed
            >         # optimizer = keras.optimizers.AdamW(learning_rate=3e-4, weight_decay=1e-4)
            >         optimizer = keras.optimizers.Adam(learning_rate=3e-4)
            >
            >         model.compile(
            >             optimizer=optimizer,
            >             loss="sparse_categorical_crossentropy",
            >             metrics=["accuracy"],
            >         )
            >         model.summary()
            >         return model
            >
            >     # -------------------------------------------------------------- #
            >     # preprocessing (fixed – tolerant, slightly adjusted target size)
            >     # -------------------------------------------------------------- #
            >     def _preprocess_cell_for_model(self, cell: np.ndarray) -> Optional[np.ndarray]:
            >         """
            >         Convert raw cell → 28×28 float32 in [0,1].
            >         Never raises; returns None only if `cell` itself is invalid.
            >         """
            >         if cell is None or cell.size < 10: # Basic check for validity
            >             return None
            >
            >         # Ensure input is grayscale uint8
            >         if cell.ndim == 3 and cell.shape[2] == 3:
            >             gray = cv2.cvtColor(cell, cv2.COLOR_BGR2GRAY)
            >         elif cell.ndim == 2:
            >             gray = cell
            >         else: # Unexpected shape
            >              return None # Or try to handle other cases like RGBA
            >
            >         # Ensure uint8 type for thresholding
            >         if gray.dtype != np.uint8:
            >              # Try to safely convert (e.g., scale if it's float)
            >              if np.issubdtype(gray.dtype, np.floating):
            >                  gray = (gray * 255).clip(0, 255).astype(np.uint8)
            >              else:
            >                  gray = gray.astype(np.uint8) # Hope for the best
            >
            >         # --- Thresholding ---
            >         # Apply slight Gaussian blur before thresholding to reduce noise
            >         blurred = cv2.GaussianBlur(gray, (3, 3), 0)
            >
            >         # Adaptive thresholding (robust to varying lighting)
            >         try:
            >             # Block size needs to be odd and > 1. Choose based on image size.
            >             block_size = max(5, min(gray.shape[0], gray.shape[1]) // 4)
            >             if block_size % 2 == 0: block_size += 1 # Ensure odd
            >             thresh = cv2.adaptiveThreshold(
            >                 blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, block_size, 5 # C=5 is a decent starting point
            >             )
            >         except cv2.error:
            >             # Fallback to Otsu's method if adaptive fails (e.g., very small image)
            >             _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            >
            >         # --- Find digit bounding box ---
            >         pts = cv2.findNonZero(thresh)
            >         if pts is None:  # Cell is empty or thresholding failed
            >             return np.zeros(self._model_input_size, dtype="float32") # Return black canvas
            >
            >         x, y, w, h = cv2.boundingRect(pts)
            >         if w <= 0 or h <= 0: # Should not happen if pts is not None, but check anyway
            >             return np.zeros(self._model_input_size, dtype="float32")
            >
            >         roi = thresh[y : y + h, x : x + w]
            >
            >         # --- Resize and Center ---
            >         # Calculate scaling factor to fit ROI into TARGET_CELL_CONTENT_SIZE box
            >         # Use TARGET_CELL_CONTENT_SIZE (e.g., 26)
            >         target_size = TARGET_CELL_CONTENT_SIZE
            >         scale = min(target_size / w, target_size / h)
            >         new_w = max(1, int(round(w * scale)))
            >         new_h = max(1, int(round(h * scale)))
            >
            >         # Resize using INTER_AREA for shrinking
            >         resized = cv2.resize(roi, (new_w, new_h), interpolation=cv2.INTER_AREA)
            >
            >         # Create target canvas (28x28)
            >         canvas = np.zeros(self._model_input_size, dtype=np.uint8)
            >
            >         # Calculate padding to center the resized digit
            >         pad_top = (self._model_input_size[0] - new_h) // 2
            >         pad_left = (self._model_input_size[1] - new_w) // 2
            >
            >         # Place the resized digit onto the canvas
            >         canvas[pad_top : pad_top + new_h, pad_left : pad_left + new_w] = resized
            >
            >         # Normalize to [0, 1] float32
            >         return canvas.astype("float32") / 255.0
            >
            >     # -------------------------------------------------------------- #
            >     # training
            >     # -------------------------------------------------------------- #
            >     def train(
            >         self,
            >         epochs: int = EPOCHS,
            >         steps_per_epoch: int = STEPS_PER_EPOCH,
            >         batch_size: int = BATCH_SIZE,
            >         validation_steps: int = VALIDATION_STEPS,
            >     ) -> None:
            >         print(f"\nTraining: epochs={epochs} steps={steps_per_epoch} batch={batch_size}")
            >         if self.model is None:
            >             self.model = self._build_cnn_model()
            >         elif not isinstance(self.model, keras.Model):
            >              print("[Error] self.model is not a valid Keras model. Cannot train.")
            >              return
            >
            >         try:
            >             test_img_path, test_gt = generate_and_save_test_example()
            >             # Ensure classifier instance is passed correctly
            >             epoch_cb = EpochTestCallback(test_img_path, test_gt, self)
            >             if epoch_cb.preprocessed is None:
            >                  print("[Warning] EpochTestCallback disabled due to preprocessing issues.")
            >                  epoch_cb = None # Disable if setup failed
            >         except Exception as e:
            >             print(f"[Warning] Epoch-callback disabled during setup ({e})")
            >             epoch_cb = None
            >
            >         # Use a fresh renderer instance for each generator if state matters
            >         train_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >         val_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >
            >         # Callbacks
            >         cbs: list[callbacks.Callback] = [
            >             callbacks.EarlyStopping(
            >                 monitor="val_accuracy", # Monitor validation accuracy
            >                 patience=8,          # Increase patience slightly
            >                 restore_best_weights=True,
            >                 verbose=1,
            >                 mode='max' # We want to maximize accuracy
            >             ),
            >             callbacks.ModelCheckpoint(
            >                 filepath=self.model_path,
            >                 monitor="val_accuracy", # Save based on best validation accuracy
            >                 save_best_only=True,
            >                 verbose=1,
            >                 mode='max'
            >             ),
            >             callbacks.ReduceLROnPlateau(
            >                 monitor="val_accuracy", # Reduce LR based on validation accuracy
            >                 factor=0.3,          # More aggressive reduction factor
            >                 patience=4,          # Reduce LR sooner if plateauing
            >                 min_lr=1e-7,
            >                 verbose=1,
            >                 mode='max'
            >             ),
            >             # TensorBoard callback (optional, for visualization)
            >             # callbacks.TensorBoard(log_dir='./logs', histogram_freq=1)
            >         ]
            >         if epoch_cb: # Add epoch test callback only if it was initialized successfully
            >             cbs.append(epoch_cb)
            >
            >         # Start Training
            >         history = self.model.fit(
            >             train_gen,
            >             epochs=epochs,
            >             steps_per_epoch=steps_per_epoch,
            >             validation_data=val_gen,
            >             validation_steps=validation_steps,
            >             callbacks=cbs,
            >             verbose=1,
            >         )
            >
            >         # Load best weights back if EarlyStopping restored them
            >         # (ModelCheckpoint already saved the best one, but loading ensures the instance has them)
            >         if self.model_path.exists():
            >              print(f"Loading best weights from {self.model_path}")
            >              self.model.load_weights(self.model_path) # Use load_weights if only weights were saved, or load_model if entire model
            >
            >         print("\nFinal evaluation using best weights:")
            >         # Use a fresh generator for final evaluation
            >         final_eval_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >         loss, acc = self.model.evaluate(
            >             final_eval_gen,
            >             steps=validation_steps * 2, # Evaluate on more steps
            >             verbose=1,
            >         )
            >         print(f"Final val_loss={loss:.5f}  val_acc={acc:.5f}")
            >
            >         # Explicitly save the final best model (ModelCheckpoint should have done this, but belt-and-suspenders)
            >         print(f"Saving final best model to {self.model_path}")
            >         self.model.save(self.model_path)
            >
            >         del train_gen, val_gen, final_eval_gen
            >         gc.collect()
            >
            >     # -------------------------------------------------------------- #
            >     # inference
            >     # -------------------------------------------------------------- #
            >     @torch.no_grad() # Keep torch decorator if using torch backend
            >     def recognise(
            >         self,
            >         cell: np.ndarray,
            >         confidence_threshold: float = 0.9, # Increased default threshold
            >     ) -> Tuple[int, float]:
            >         """Recognises a single digit cell."""
            >         if self.model is None:
            >             print("[Error] Recognise called but model is not loaded.")
            >             return 0, 0.0
            >
            >         proc = self._preprocess_cell_for_model(cell)
            >         if proc is None:
            >             # This indicates an issue with the input cell itself
            >             # print("[Debug] Preprocessing returned None for a cell.")
            >             return 0, 0.0 # Treat as empty/unrecognizable
            >
            >         # Add batch and channel dimensions: (H, W) -> (1, H, W, 1)
            >         x = proc[np.newaxis, ..., np.newaxis]
            >
            >         # Predict using the Keras model
            >         # The torch.no_grad() context manager is primarily for PyTorch operations.
            >         # Keras with torch backend should handle inference mode correctly via training=False.
            >         # If using pure torch tensors were necessary: x_tensor = torch.from_numpy(x).float()
            >         probs = self.model(x, training=False) # Use training=False for inference
            >
            >         # Ensure probs is a NumPy array
            >         if hasattr(probs, 'numpy'): # TF tensor
            >             probs = probs.cpu().detach().numpy()
            >         elif isinstance(probs, torch.Tensor): # PyTorch tensor
            >             probs = probs.cpu().numpy()
            >         # If it's already numpy, do nothing
            >
            >         probs = probs[0] # Remove batch dimension
            >
            >         idx = int(np.argmax(probs))
            >         conf = float(probs[idx])
            >
            >         # Return 0 (empty) if classified as EMPTY_LABEL or confidence is too low
            >         if idx == EMPTY_LABEL or conf < confidence_threshold:
            >             # Optionally distinguish between low-conf digit and classified-empty
            >             # if idx == EMPTY_LABEL: print(f"Cell classified as empty (conf {conf:.3f})")
            >             # else: print(f"Cell classified as {idx} but low conf ({conf:.3f} < {confidence_threshold})")
            >             return 0, conf # Return 0 for empty/uncertain
            >         else:
            >             # Return the classified digit (1-9)
            >             return idx, conf
            >
            >
            > # ------------------------------------------------------------------ #
            > # 8.  epoch‑end callback (Unchanged conceptually, ensure imports/refs are correct)
            > # ------------------------------------------------------------------ #
            > class EpochTestCallback(callbacks.Callback):
            >     def __init__(
            >         self,
            >         test_img_path: Path | str,
            >         gt_grid: np.ndarray,
            >         classifier: "DigitClassifier", # Pass the classifier instance
            >         frequency: int = 1,
            >     ) -> None:
            >         super().__init__()
            >         self.frequency = max(1, frequency)
            >         self.gt_grid = gt_grid.flatten() # Flatten GT grid for easier comparison
            >         self.classifier = classifier # Store the classifier instance
            >         self.test_img_path = test_img_path
            >         self.preprocessed = None # Initialize as None
            >
            >         # --- Preprocessing moved to on_train_begin ---
            >         # This ensures the classifier's model is built before preprocessing
            >
            >     def on_train_begin(self, logs=None):
            >         # --- Preprocess test image cells here ---
            >         # Ensures the model (and its input size) exists if built dynamically
            >         print("[Callback] Preprocessing test example...")
            >         try:
            >             cells, _, _ = extract_cells_from_image(self.test_img_path, debug=False)
            >             if not cells or len(cells) != GRID_SIZE * GRID_SIZE:
            >                 print(f"[Callback] Failed to extract correct number of cells ({len(cells)}) from {self.test_img_path}")
            >                 self.preprocessed = None
            >                 return
            >
            >             buf = []
            >             model_input_size = self.classifier._model_input_size # Get from classifier
            >             for i, cell in enumerate(cells):
            >                 proc = self.classifier._preprocess_cell_for_model(cell)
            >                 if proc is None:
            >                     print(f"[Callback Warning] Preprocessing failed for cell {i}, using zeros.")
            >                     proc = np.zeros(model_input_size, dtype="float32")
            >                 buf.append(proc)
            >
            >             self.preprocessed = np.asarray(buf, dtype="float32")[..., np.newaxis]
            >             print(f"[Callback] Test example preprocessed successfully ({self.preprocessed.shape}).")
            >
            >         except Exception as e:
            >             print(f"[Callback Error] Failed during test example preprocessing: {e}")
            >             self.preprocessed = None
            >
            >
            >     def on_epoch_end(self, epoch, logs=None):
            >         # Check if preprocessing was successful and if it's the right epoch
            >         if self.preprocessed is None or (epoch + 1) % self.frequency != 0:
            >             return
            >
            >         if not hasattr(self.model, 'predict'):
            >              print("[Callback Error] Model object does not have predict method.")
            >              return
            >
            >         print(f"\n--- Epoch {epoch+1} Test Example Evaluation ---")
            >         try:
            >             # Use the model attached to the callback (which is the one being trained)
            >             probs = self.model.predict(self.preprocessed, verbose=0)
            >             idxs = np.argmax(probs, axis=1)
            >             confs = np.max(probs, axis=1)
            >
            >             # Apply the same logic as `recognise` for final prediction
            >             # Use a reasonable threshold for display purposes
            >             display_threshold = 0.7 # Lower than final recognition, just for display
            >             final = [
            >                 i if (i != EMPTY_LABEL and c >= display_threshold) else 0
            >                 for i, c in zip(idxs, confs)
            >             ]
            >             pred_grid_flat = np.asarray(final)
            >             pred_grid = pred_grid_flat.reshape(GRID_SIZE, GRID_SIZE)
            >             conf_grid = confs.reshape(GRID_SIZE, GRID_SIZE)
            >
            >             print("Ground Truth:")
            >             sudoku_recogniser.print_sudoku_grid(self.gt_grid.reshape(GRID_SIZE, GRID_SIZE)) # Reshape GT back
            >             print("Prediction (Thresholded):")
            >             sudoku_recogniser.print_sudoku_grid(pred_grid, conf_grid, threshold=display_threshold)
            >
            >             # Compare against the flattened ground truth
            >             correct_cells = (pred_grid_flat == self.gt_grid).sum()
            >             total_cells = GRID_SIZE * GRID_SIZE
            >             accuracy = correct_cells / total_cells
            >             print(f"Test Example Accuracy: {correct_cells}/{total_cells} = {accuracy:.4f}")
            >             print("--- End Epoch Test ---\n")
            >
            >         except Exception as e:
            >             print(f"[Callback Error] Failed during prediction or display: {e}")
            >
            >
            > # ------------------------------------------------------------------ #
            > # 9.  CLI helper
            > # ------------------------------------------------------------------ #
            > if __name__ == "__main__":
            >     # Set to True to force retraining even if a model file exists
            >     FORCE_TRAIN = False # Set to True to retrain
            >
            >     model_file = Path(MODEL_FILENAME)
            >     train_needed = FORCE_TRAIN or not model_file.exists()
            >
            >     if FORCE_TRAIN and model_file.exists():
            >         print(f"FORCE_TRAIN is True. Deleting existing model: {model_file}")
            >         try:
            >             model_file.unlink()
            >             train_needed = True # Ensure flag is set
            >         except OSError as e:
            >             print(f"Error deleting existing model: {e}")
            >             # Decide whether to proceed or exit
            >             # exit(1)
            >
            >     # Instantiate the classifier. It will try to load if train_needed is False.
            >     clf = DigitClassifier(model_path=model_file, training_required=train_needed)
            >
            >     # Train if needed (either forced or because loading failed/file missing)
            >     if train_needed:
            >         print("Starting training process...")
            >         clf.train()
            >         # After training, the best model should be saved and loaded by the train method.
            >         # Verify the model is loaded for the sanity check below.
            >         if clf.model is None:
            >              print("[Error] Training finished, but model is still None. Cannot proceed.")
            >              exit(1) # Exit if training failed to produce a model
            >     elif clf.model is None:
            >          print("[Error] Model loading failed, and training was not requested. Cannot proceed.")
            >          exit(1) # Exit if no model is available
            >     else:
            >          print("Model loaded successfully. Skipping training.")
            >
            >
            >     # Perform sanity check only if the model is available
            >     if clf.model:
            >         print("\nQuick sanity check:")
            >
            >         # Test 1: Vertical stroke (should ideally be 1)
            >         dummy1 = np.zeros((50, 50), np.uint8)
            >         cv2.line(dummy1, (25, 10), (25, 40), 255, 4) # Thicker line
            >         d1, c1 = clf.recognise(dummy1, confidence_threshold=0.5) # Use lower threshold for test
            >         print(f"Vertical stroke → {d1}  (conf {c1:.3f})")
            >
            >         # Test 2: Blank cell (should be 0)
            >         blank = np.zeros((50, 50), np.uint8)
            >         d0, c0 = clf.recognise(blank, confidence_threshold=0.5)
            >         print(f"Blank cell      → {d0}  (conf {c0:.3f})")
            >
            >         # Test 3: A simple digit (e.g., '7')
            >         dummy7 = np.zeros((50, 50), np.uint8)
            >         cv2.putText(dummy7, '7', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.5, 255, 3)
            >         d7, c7 = clf.recognise(dummy7, confidence_threshold=0.5)
            >         print(f"Digit '7'       → {d7}  (conf {c7:.3f})")
            >
            >     else:
            >         print("\nSanity check skipped: No model available.")
        digit_extractor.py:
            > """
            > Find and extract Sudoku grid cells from an image.
            > """
            >
            > import os
            > from pathlib import Path
            > from typing import List, Tuple, Optional
            >
            > import cv2
            > import numpy as np
            >
            > GRID_SIZE = 9
            > DEFAULT_RECTIFIED_SIZE = 450
            >
            >
            > def _order_points(pts: np.ndarray) -> np.ndarray:
            >     """Order four points as top-left, top-right, bottom-right, bottom-left."""
            >     pts = pts.reshape(4, 2).astype("float32")
            >     rect = np.zeros((4, 2), dtype="float32")
            >     s = pts.sum(axis=1)
            >     rect[0] = pts[np.argmin(s)]
            >     rect[2] = pts[np.argmax(s)]
            >     diff = pts[:, 1] - pts[:, 0]
            >     rect[1] = pts[np.argmin(diff)]
            >     rect[3] = pts[np.argmax(diff)]
            >     return rect
            >
            >
            > def find_sudoku_grid_contour(
            >     img: np.ndarray,
            >     debug_dir: Optional[Path] = None
            > ) -> np.ndarray:
            >     """
            >     Find the largest 4-point contour approximating the Sudoku grid boundary.
            >     """
            >     gray = (
            >         cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            >         if img.ndim == 3 else img.copy()
            >     )
            >
            >     if debug_dir:
            >         debug_dir.mkdir(parents=True, exist_ok=True)
            >
            >     blur = cv2.GaussianBlur(gray, (7, 7), 0)
            >     thresh = cv2.adaptiveThreshold(
            >         blur, 255,
            >         cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            >         cv2.THRESH_BINARY_INV,
            >         15, 4
            >     )
            >     closed = cv2.morphologyEx(
            >         thresh,
            >         cv2.MORPH_CLOSE,
            >         cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)),
            >         iterations=2
            >     )
            >
            >     contours, _ = cv2.findContours(
            >         closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
            >     )
            >     contours = sorted(contours, key=cv2.contourArea, reverse=True)
            >     min_area = gray.size * 0.1
            >
            >     for cnt in contours:
            >         if cv2.contourArea(cnt) < min_area:
            >             break
            >         peri = cv2.arcLength(cnt, True)
            >         approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)
            >         if len(approx) == 4 and cv2.isContourConvex(approx):
            >             x, y, w, h = cv2.boundingRect(approx)
            >             aspect = w / float(h)
            >             if 0.8 < aspect < 1.2:
            >                 return approx.reshape(4, 2).astype("float32")
            >
            >     raise ValueError("Sudoku grid contour not found.")
            >
            >
            > def rectify_grid(
            >     img: np.ndarray,
            >     contour: np.ndarray,
            >     size: int = DEFAULT_RECTIFIED_SIZE
            > ) -> Optional[np.ndarray]:
            >     """Perspective-correct the Sudoku grid to a square of given size."""
            >     try:
            >         src = _order_points(contour)
            >         dst = np.array([
            >             [0, 0],
            >             [size - 1, 0],
            >             [size - 1, size - 1],
            >             [0, size - 1],
            >         ], dtype="float32")
            >         mat = cv2.getPerspectiveTransform(src, dst)
            >         return cv2.warpPerspective(img, mat, (size, size))
            >     except cv2.error:
            >         return None
            >
            >
            > def split_into_cells(
            >     rectified: np.ndarray
            > ) -> Tuple[List[np.ndarray], np.ndarray]:
            >     """
            >     Split the rectified grid into GRID_SIZE × GRID_SIZE cell images.
            >     Returns (cells, rectified_image).
            >     """
            >     h, w = rectified.shape[:2]
            >     if h != w:
            >         size = max(h, w)
            >         rectified = cv2.resize(rectified, (size, size))
            >         h = w = size
            >
            >     cell_sz = h // GRID_SIZE
            >     margin = int(cell_sz * 0.04)
            >     cells: List[np.ndarray] = []
            >
            >     for row in range(GRID_SIZE):
            >         for col in range(GRID_SIZE):
            >             y0 = row * cell_sz + margin
            >             x0 = col * cell_sz + margin
            >             y1 = (row + 1) * cell_sz - margin
            >             x1 = (col + 1) * cell_sz - margin
            >             if y0 >= y1 or x0 >= x1:
            >                 cell = np.zeros((cell_sz, cell_sz), rectified.dtype)
            >             else:
            >                 cell = rectified[y0:y1, x0:x1]
            >             cells.append(cell)
            >
            >     return cells, rectified
            >
            >
            > def extract_cells_from_image(
            >     img_or_path,
            >     size: int = DEFAULT_RECTIFIED_SIZE,
            >     debug: bool = False
            > ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray], Optional[np.ndarray]]:
            >     """
            >     High-level function: read image, find grid, rectify, and split into cells.
            >     Returns (cells, rectified_image, contour) or (None, None, None) on failure.
            >     """
            >     if isinstance(img_or_path, (str, Path)):
            >         img = cv2.imread(str(img_or_path))
            >         if img is None:
            >             return None, None, None
            >     elif isinstance(img_or_path, np.ndarray):
            >         img = img_or_path.copy()
            >     else:
            >         return None, None, None
            >
            >     try:
            >         debug_dir = Path(f"debug_{os.getpid()}") if debug else None
            >         contour = find_sudoku_grid_contour(img, debug_dir)
            >         rectified = rectify_grid(img, contour, size=size)
            >         if rectified is None:
            >             return None, None, None
            >         cells, rectified = split_into_cells(rectified)
            >         return cells, rectified, contour
            >     except Exception as exc:
            >         print(f"[Extractor] {exc}")
            >         return None, None, None
            >
        sudoku_recogniser.py:
            > """
            > Command-line utility to detect a Sudoku grid in an image and recognise its digits.
            > """
            >
            > from __future__ import annotations
            >
            > import sys
            > import time
            > from pathlib import Path
            > from typing import Tuple, Optional
            >
            > import cv2
            > import numpy as np
            >
            > import digit_classifier
            > from digit_extractor import GRID_SIZE, extract_cells_from_image
            >
            > FINAL_CONFIDENCE_THRESHOLD = 0.80
            >
            >
            > def print_sudoku_grid(
            >     grid: np.ndarray,
            >     conf: Optional[np.ndarray] = None,
            >     threshold: float = FINAL_CONFIDENCE_THRESHOLD
            > ) -> None:
            >     """Nicely print a 9×9 Sudoku grid, marking low‑confidence digits as '?'. """
            >     grid = np.asarray(grid)
            >     if grid.shape != (GRID_SIZE, GRID_SIZE):
            >         print("[print_sudoku_grid] invalid shape")
            >         return
            >
            >     for r in range(GRID_SIZE):
            >         if r > 0 and r % 3 == 0:
            >             print("|-----+-------+-----|")
            >
            >         tokens = []
            >         for c in range(GRID_SIZE):
            >             d = grid[r, c]
            >             if d == 0:
            >                 tok = "."
            >             else:
            >                 tok = str(d)
            >                 if conf is not None and conf[r, c] < threshold:
            >                     tok = "?"
            >             tokens.append(tok)
            >             if (c + 1) % 3 == 0 and c < GRID_SIZE - 1:
            >                 tokens.append("|")
            >         print(" ".join(tokens))
            >     print()
            >
            >
            > def display_results_on_image(
            >     rectified: Optional[np.ndarray],
            >     grid: np.ndarray
            > ) -> Optional[np.ndarray]:
            >     """
            >     Draw recognised digits onto the rectified grid image and return it.
            >     """
            >     if rectified is None:
            >         return None
            >
            >     img = (
            >         cv2.cvtColor(rectified, cv2.COLOR_GRAY2BGR)
            >         if rectified.ndim == 2 else rectified.copy()
            >     )
            >     h, w = img.shape[:2]
            >     cell_h, cell_w = h // GRID_SIZE, w // GRID_SIZE
            >
            >     for r in range(GRID_SIZE):
            >         for c in range(GRID_SIZE):
            >             d = grid[r, c]
            >             if d == 0:
            >                 continue
            >             text = str(d)
            >             (tw, th), _ = cv2.getTextSize(
            >                 text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2
            >             )
            >             x = c * cell_w + (cell_w - tw) // 2
            >             y = r * cell_h + (cell_h + th) // 2
            >             cv2.putText(
            >                 img, text, (x, y),
            >                 cv2.FONT_HERSHEY_SIMPLEX,
            >                 1, (0, 255, 0), 2, cv2.LINE_AA
            >             )
            >     return img
            >
            >
            > def recognise_sudoku(
            >     img_path: Path,
            >     classifier: digit_classifier.DigitClassifier
            > ) -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:
            >     """
            >     Extract cells and run the classifier on each one.
            >     Returns (predicted_grid, confidence_grid, rectified_image).
            >     """
            >     print(f"Processing {img_path} ...")
            >     start = time.time()
            >     cells, rectified, _ = extract_cells_from_image(img_path)
            >     if cells is None or rectified is None:
            >         raise RuntimeError("Extraction failed.")
            >
            >     pred = np.zeros((GRID_SIZE, GRID_SIZE), int)
            >     conf = np.zeros_like(pred, float)
            >
            >     for i, cell in enumerate(cells):
            >         r, c = divmod(i, GRID_SIZE)
            >         d, cf = classifier.recognise(cell, confidence_threshold=0.1)
            >         conf[r, c] = cf
            >         if d != 0 and cf >= FINAL_CONFIDENCE_THRESHOLD:
            >             pred[r, c] = d
            >
            >     elapsed = time.time() - start
            >     print(f"Done in {elapsed:.2f}s")
            >     return pred, conf, rectified
            >
            >
            > def main() -> None:
            >     if len(sys.argv) < 2:
            >         print("Usage: sudoku_recogniser.py <image_path>")
            >         sys.exit(0)
            >
            >     img_path = Path(sys.argv[1])
            >     if not img_path.exists():
            >         print(f"Image not found: {img_path}")
            >         sys.exit(1)
            >
            >     classifier = digit_classifier.DigitClassifier(model_path=digit_classifier.MODEL_FILENAME)
            >     if classifier.model is None:
            >         print("Model missing—training required.")
            >         classifier.train()
            >
            >     grid, conf, rectified = recognise_sudoku(img_path, classifier)
            >     print_sudoku_grid(grid, conf)
            >
            >     result_img = display_results_on_image(rectified, grid)
            >     if result_img is not None:
            >         cv2.imshow("Sudoku Recognition", result_img)
            >         cv2.waitKey(0)
            >         cv2.destroyAllWindows()
            >
            >
            > if __name__ == "__main__":
            >     main()
            >
        sudoku_renderer.py:
            > """
            > Synthetic Sudoku image generator for on‑the‑fly training data.
            > """
            >
            > import random
            > from pathlib import Path
            > from typing import Tuple, Optional
            >
            > import cv2
            > import numpy as np
            > import keras
            >
            > GRID_SIZE = 9
            > BASE_IMAGE_SIZE = 1000
            > CELL_SIZE = BASE_IMAGE_SIZE // GRID_SIZE
            >
            >
            > def _order_points(pts: np.ndarray) -> np.ndarray:
            >     """Order four points as TL, TR, BR, BL."""
            >     pts = pts.reshape(4, 2).astype("float32")
            >     rect = np.zeros((4, 2), dtype="float32")
            >     s = pts.sum(axis=1)
            >     rect[0] = pts[np.argmin(s)]
            >     rect[2] = pts[np.argmax(s)]
            >     diff = pts[:, 1] - pts[:, 0]
            >     rect[1] = pts[np.argmin(diff)]
            >     rect[3] = pts[np.argmax(diff)]
            >     return rect
            >
            >
            > def _load_mnist_digits() -> dict[int, list[np.ndarray]]:
            >     """
            >     Download MNIST once and bucket images by label for rendering.
            >     """
            >     (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
            >     images = np.concatenate([x_train, x_test])
            >     labels = np.concatenate([y_train, y_test])
            >
            >     buckets: dict[int, list[np.ndarray]] = {i: [] for i in range(10)}
            >     for img, lbl in zip(images, labels):
            >         inv = cv2.bitwise_not(img)
            >         padded = cv2.copyMakeBorder(
            >             inv, 4, 4, 4, 4,
            >             cv2.BORDER_CONSTANT, value=255
            >         )
            >         buckets[int(lbl)].append(padded)
            >     return buckets
            >
            >
            > class SudokuRenderer:
            >     """
            >     Render a random (or specified) Sudoku grid to a synthetic image.
            >     """
            >
            >     def __init__(self) -> None:
            >         self.mnist_buckets: Optional[dict[int, list[np.ndarray]]] = None
            >
            >     def _digit_source(self, digit: int) -> Tuple[Optional[np.ndarray], str]:
            >         if self.mnist_buckets is None:
            >             self.mnist_buckets = _load_mnist_digits()
            >
            >         sources = []
            >         if self.mnist_buckets[digit]:
            >             sources.append("mnist")
            >         sources.append("font")
            >         choice = random.choice(sources)
            >
            >         if choice == "mnist":
            >             img = random.choice(self.mnist_buckets[digit])
            >             if img.ndim == 2:
            >                 img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
            >             return img, "mnist"
            >         return None, "font"
            >
            >     def render_sudoku(
            >         self,
            >         grid_spec: Optional[list[list[int | None]]] = None,
            >         *,
            >         allow_empty: bool = True
            >     ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
            >         """
            >         Generate a synthetic Sudoku image.
            >         Returns (image, ground_truth_grid, warped_corners).
            >         """
            >         if grid_spec is None:
            >             gt = np.zeros((GRID_SIZE, GRID_SIZE), int)
            >             for r in range(GRID_SIZE):
            >                 for c in range(GRID_SIZE):
            >                     if allow_empty and random.random() < 0.4:
            >                         continue
            >                     gt[r, c] = random.randint(1, 9)
            >         else:
            >             gt = np.array([[d or 0 for d in row] for row in grid_spec], int)
            >
            >         bg = tuple(random.randint(200, 240) for _ in range(3))
            >         img = np.full((BASE_IMAGE_SIZE, BASE_IMAGE_SIZE, 3), bg, np.uint8)
            >
            >         # draw grid lines
            >         for i in range(GRID_SIZE + 1):
            >             major = (i % 3 == 0)
            >             thickness = random.randint(3 if major else 1, 5 if major else 3)
            >             cv2.line(img, (0, i*CELL_SIZE), (BASE_IMAGE_SIZE, i*CELL_SIZE), (0, 0, 0), thickness)
            >             cv2.line(img, (i*CELL_SIZE, 0), (i*CELL_SIZE, BASE_IMAGE_SIZE), (0, 0, 0), thickness)
            >
            >         # draw digits
            >         for r in range(GRID_SIZE):
            >             for c in range(GRID_SIZE):
            >                 d = gt[r, c]
            >                 if d == 0:
            >                     continue
            >
            >                 src_img, src_type = self._digit_source(d)
            >                 scale = random.uniform(0.5, 0.8)
            >                 tgt = int(CELL_SIZE * scale)
            >                 center_x = c*CELL_SIZE + CELL_SIZE//2
            >                 center_y = r*CELL_SIZE + CELL_SIZE//2
            >                 dx = int(random.uniform(-0.1, 0.1)*CELL_SIZE)
            >                 dy = int(random.uniform(-0.1, 0.1)*CELL_SIZE)
            >                 cx, cy = center_x + dx, center_y + dy
            >
            >                 if src_type == "mnist":
            >                     digit = cv2.resize(src_img, (tgt, tgt))
            >                     angle = random.uniform(-10, 10)
            >                     M = cv2.getRotationMatrix2D((tgt/2, tgt/2), angle, 1)
            >                     digit = cv2.warpAffine(
            >                         digit, M, (tgt, tgt),
            >                         borderMode=cv2.BORDER_CONSTANT, borderValue=(255,255,255)
            >                     )
            >                     mask = cv2.cvtColor(digit, cv2.COLOR_BGR2GRAY)
            >                     _, mask = cv2.threshold(mask, 250, 255, cv2.THRESH_BINARY_INV)
            >
            >                     x0 = max(0, cx - tgt//2)
            >                     y0 = max(0, cy - tgt//2)
            >                     roi = img[y0:y0+tgt, x0:x0+tgt]
            >                     m_inv = cv2.bitwise_not(mask[:roi.shape[0], :roi.shape[1]])
            >                     bg_region = cv2.bitwise_and(roi, roi, mask=m_inv)
            >                     fg_region = cv2.bitwise_and(digit, digit, mask=mask[:roi.shape[0], :roi.shape[1]])
            >                     img[y0:y0+roi.shape[0], x0:x0+roi.shape[1]] = cv2.add(bg_region, fg_region)
            >                 else:
            >                     font = cv2.FONT_HERSHEY_SIMPLEX
            >                     thickness = random.randint(1, 3)
            >                     font_scale = cv2.getFontScaleFromHeight(font, tgt, thickness) * 0.8
            >                     text = str(d)
            >                     tw, th = cv2.getTextSize(text, font, font_scale, thickness)[0]
            >                     x = cx - tw//2
            >                     y = cy + th//2
            >                     cv2.putText(img, text, (x, y),
            >                                 font, font_scale, (0, 0, 0), thickness, cv2.LINE_AA)
            >
            >         # add noise
            >         noise = np.random.normal(0, random.uniform(5,20), img.shape).astype(np.float32)
            >         noisy = np.clip(img.astype(np.float32) + noise, 0, 255).astype(np.uint8)
            >
            >         # random perspective warp
            >         h, w = noisy.shape[:2]
            >         orig = np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]], dtype="float32")
            >         shift = random.uniform(0.05, 0.2)
            >         max_dx, max_dy = w*shift, h*shift
            >         dst = np.array([
            >             [random.uniform(0, max_dx), random.uniform(0, max_dy)],
            >             [w-1-random.uniform(0, max_dx), random.uniform(0, max_dy)],
            >             [w-1-random.uniform(-max_dx*0.2, max_dx), h-1-random.uniform(0, max_dy)],
            >             [random.uniform(-max_dx*0.2, max_dx), h-1-random.uniform(0, max_dy)],
            >         ], dtype="float32")
            >         M = cv2.getPerspectiveTransform(orig, dst)
            >         out_w = int(dst[:,0].max()) + 1
            >         out_h = int(dst[:,1].max()) + 1
            >         warped = cv2.warpPerspective(
            >             noisy, M, (out_w, out_h), borderMode=cv2.BORDER_REPLICATE
            >         )
            >
            >         return warped, gt, dst
            >
            >
            > def generate_and_save_test_example(
            >     prefix: str = "epoch_test_sudoku",
            >     force: bool = False
            > ) -> Tuple[str, np.ndarray]:
            >     """
            >     Generate or load a fixed Sudoku test example for epoch callbacks.
            >     Returns (image_path, ground_truth_grid).
            >     """
            >     img_path = Path(f"{prefix}.png")
            >     gt_path = Path(f"{prefix}_gt.npy")
            >
            >     if not force and img_path.exists() and gt_path.exists():
            >         return str(img_path), np.load(gt_path)
            >
            >     renderer = SudokuRenderer()
            >     grid_spec = [
            >         [None, None, 3,    None, None, 6,    None, 8,    None],
            >         [8,    None, 1,    None, 3,    None, 5,    None, 4   ],
            >         [None, 4,    None, 8,    None, 7,    None, 1,    None],
            >         [1,    None, None, 4,    None, 5,    None, None, 9   ],
            >         [None, 7,    None, None, 2,    None, None, 4,    None],
            >         [5,    None, None, 7,    None, 1,    None, None, 3   ],
            >         [None, 8,    None, 5,    None, 3,    None, 9,    None],
            >         [7,    None, 4,    None, 9,    None, 1,    None, 8   ],
            >         [None, 1,    None, 6,    None, None, 4,    None, None],
            >     ]
            >     img, gt, _ = renderer.render_sudoku(grid_spec=grid_spec)
            >     cv2.imwrite(str(img_path), img)
            >     np.save(gt_path, gt)
            >     return str(img_path), gt
            >
    diffs_applied_this_send: True
system:
    message:
        >
        > You are a helpful assistant.
        > Respond in markdown format.
        > Respond with a git diff patch for any modified or added files. Use the ```diff markdown code block.
        > Avoid asking the user to clear their caches or do local configuration related stuff. That's rarely the cause of errors.
        > If you ask them, and they reply with a compilation error, assume they've already done everything you suggested and move on.
        > But try to avoid such suggestions. It's a cop out. It's like when tech support says 'Have you tried turning it off and on again?'.
        > Try to actually fix the error instead.
        >
    model:
        - o4-mini
    code_completion_model:
        - gemini/gemini-2.0-flash-thinking-exp-01-21
    commit_message_model:
        - gemini/gemini-2.0-flash-thinking-exp-01-21
    max_completion_tokens:
    temperature: 0.0
    apply_mode: git
messages:
    -
        user:
            > ```python 'digit_classifier.py'
            > """
            > SudokuBot – digit classifier
            > Improved version 2025‑04‑21
            >
            > Major fixes
            > • data generator now really yields balanced batches
            > • preprocessing is tolerant – almost never rejects a cell
            > • **Improved CNN architecture (ResNet-style) for higher accuracy**
            > """
            >
            > # ------------------------------------------------------------------ #
            > # 1.  choose backend BEFORE importing keras
            > # ------------------------------------------------------------------ #
            > import os
            >
            > os.environ["KERAS_BACKEND"] = "torch"  # must be first – do NOT move
            >
            > # ------------------------------------------------------------------ #
            > # 2.  std‑lib & 3rd‑party imports
            > # ------------------------------------------------------------------ #
            > import gc
            > import random
            > from pathlib import Path
            > from typing import Callable, Generator, Optional, Tuple
            >
            > import cv2
            > import numpy as np
            > import torch
            > import keras
            > from keras import callbacks, layers, models, activations, regularizers
            >
            > # ------------------------------------------------------------------ #
            > # 3.  project‑local imports
            > # ------------------------------------------------------------------ #
            > # Assume these exist in the same directory or are installable
            > try:
            >     from sudoku_renderer import SudokuRenderer, generate_and_save_test_example
            >     from digit_extractor import (
            >         GRID_SIZE,
            >         extract_cells_from_image,
            >         rectify_grid,
            >         split_into_cells,
            >     )
            >     import sudoku_recogniser
            > except ImportError as e:
            >     print(f"Error importing local modules: {e}")
            >     print("Please ensure sudoku_renderer.py, digit_extractor.py, and sudoku_recogniser.py are available.")
            >     # Provide dummy implementations or raise error if essential
            >     GRID_SIZE = 9
            >     class SudokuRenderer:
            >         def render_sudoku(self, allow_empty=True): return None, None, None
            >     def generate_and_save_test_example(): return Path("dummy_test.png"), np.zeros((9,9), dtype=int)
            >     def extract_cells_from_image(path, debug=False): return [], None, None
            >     class sudoku_recogniser:
            >         FINAL_CONFIDENCE_THRESHOLD = 0.9
            >         @staticmethod
            >         def print_sudoku_grid(grid, confs=None, threshold=0.0): pass
            >
            >
            > # ------------------------------------------------------------------ #
            > # 4.  constants
            > # ------------------------------------------------------------------ #
            > MODEL_FILENAME = "sudoku_digit_classifier_resnet.keras" # Changed filename
            >
            > MODEL_INPUT_SHAPE = (28, 28, 1)
            > NUM_CLASSES = 11  # digits 0‑9 + “empty”
            > EMPTY_LABEL = 10
            >
            > TARGET_CELL_CONTENT_SIZE = 26          # preprocessing (Increased slightly)
            > TARGET_DIGIT_RATIO = 1.5               # 60 % digits / 40 % empty
            >
            > EPOCHS = 15 # Increased epochs slightly, EarlyStopping will handle it
            > STEPS_PER_EPOCH = 150 # Increased steps slightly
            > BATCH_SIZE = 256
            > VALIDATION_STEPS = 50
            >
            > DataBatch = Tuple[np.ndarray, np.ndarray]
            >
            > # ------------------------------------------------------------------ #
            > # 5.  balanced data generator (fixed) - unchanged
            > # ------------------------------------------------------------------ #
            > def sudoku_data_generator(
            >     renderer: SudokuRenderer,
            >     batch_size: int,
            >     preprocess_func: Callable[[np.ndarray], Optional[np.ndarray]],
            >     input_size: Tuple[int, int, int],
            >     target_digit_ratio: float = TARGET_DIGIT_RATIO,
            > ) -> Generator[DataBatch, None, None]:
            >     """
            >     Yield *balanced* batches of (cell, label).
            >
            >     The function never gives up early – it keeps sampling Sudokus until the
            >     required number of digit and empty cells has been collected.
            >     """
            >     total_cells = GRID_SIZE * GRID_SIZE
            >     # Calculate exact numbers needed for balance
            >     num_digits_float = batch_size * target_digit_ratio / (1 + target_digit_ratio)
            >     want_digits = int(round(num_digits_float))
            >     want_empty = batch_size - want_digits
            >
            >     # Ensure the sum is exactly batch_size after rounding
            >     if want_digits + want_empty != batch_size:
            >          # Adjust the one closer to its float representation's rounding direction
            >          if num_digits_float - int(num_digits_float) >= 0.5: # Rounded up
            >              want_digits = batch_size - want_empty
            >          else: # Rounded down
            >              want_empty = batch_size - want_digits
            >
            >     in_h, in_w = input_size[:2]
            >
            >     batch_counter = 0
            >     while True:
            >         xs, ys = [], []
            >         n_dig = n_emp = 0
            >
            >         needed_digits = want_digits
            >         needed_empty = want_empty
            >
            >         while needed_digits > 0 or needed_empty > 0:
            >             img, gt_grid, corners = renderer.render_sudoku(allow_empty=True)
            >             if img is None or corners is None:
            >                 continue
            >             rectified = rectify_grid(img, corners)
            >             if rectified is None:
            >                 continue
            >             cells, _ = split_into_cells(rectified)
            >             if len(cells) != total_cells:
            >                 continue
            >
            >             # iterate shuffled cell indices
            >             idxs = list(range(total_cells))
            >             random.shuffle(idxs)
            >
            >             for idx in idxs:
            >                 if needed_digits <= 0 and needed_empty <= 0:
            >                     break # Batch full
            >
            >                 cell = cells[idx]
            >                 # Handle potential None from gt_grid (though unlikely with allow_empty=True)
            >                 gt_val = gt_grid.flat[idx] if gt_grid is not None else 0
            >                 label = EMPTY_LABEL if gt_val == 0 else gt_val
            >
            >                 # Check if we still need this type of label
            >                 is_empty = (label == EMPTY_LABEL)
            >                 if is_empty and needed_empty <= 0:
            >                     continue
            >                 if not is_empty and needed_digits <= 0:
            >                     continue
            >
            >                 proc = preprocess_func(cell)
            >                 if proc is None:                       # should be rare now
            >                     continue
            >
            >                 # Add to batch and decrement needed count
            >                 xs.append(proc)
            >                 ys.append(label)
            >                 if is_empty:
            >                     needed_empty -= 1
            >                 else:
            >                     needed_digits -= 1
            >
            >
            >         # at this point we have a perfectly balanced batch
            >         x_arr = np.asarray(xs, dtype="float32")[..., np.newaxis]
            >         y_arr = np.asarray(ys, dtype="int64")
            >
            >         # Sanity check batch size and balance (optional)
            >         # assert len(xs) == batch_size, f"Batch size mismatch: expected {batch_size}, got {len(xs)}"
            >         # counts = np.bincount(y_arr, minlength=NUM_CLASSES)
            >         # assert counts[EMPTY_LABEL] == want_empty, f"Empty count mismatch: expected {want_empty}, got {counts[EMPTY_LABEL]}"
            >         # assert np.sum(counts[:EMPTY_LABEL]) == want_digits, f"Digit count mismatch: expected {want_digits}, got {np.sum(counts[:EMPTY_LABEL])}"
            >
            >
            >         p = np.random.permutation(batch_size) # Shuffle within the batch
            >         batch_counter += 1
            >
            >         # optional histo print for debugging
            >         if (
            >             os.environ.get("SUDOKU_DEBUG_GENERATOR", "0") == "1"
            >             and batch_counter % 500 == 0
            >         ):
            >             print(f"Batch {batch_counter} label histogram:", np.bincount(y_arr, minlength=NUM_CLASSES))
            >
            >         yield x_arr[p], y_arr[p]
            >         del xs, ys, x_arr, y_arr
            >         gc.collect()
            >
            >
            > # ------------------------------------------------------------------ #
            > # 6.  layer helpers (Removed _norm, using BN directly)
            > # ------------------------------------------------------------------ #
            > # Using ReLU directly in layers or via layers.Activation('relu')
            >
            > # ------------------------------------------------------------------ #
            > # 7.  classifier object
            > # ------------------------------------------------------------------ #
            > class DigitClassifier:
            >     """
            >     Handles loading, training and inference of the CNN digit classifier.
            >     Uses an improved ResNet-style architecture.
            >     """
            >
            >     # -------------------------------------------------------------- #
            >     # constructor
            >     # -------------------------------------------------------------- #
            >     def __init__(
            >         self,
            >         model_path: Optional[str | Path] = None,
            >         training_required: bool = False,
            >     ) -> None:
            >         self.model_path = Path(model_path) if model_path else Path(MODEL_FILENAME)
            >         self.model: Optional[keras.Model] = None
            >         self._model_input_size = MODEL_INPUT_SHAPE[:2]
            >
            >         if not training_required and self.model_path.exists():
            >             try:
            >                 # When loading custom objects like custom activation or layers (if any were used),
            >                 # you might need custom_objects={'CustomLayer': CustomLayer}
            >                 self.model = keras.models.load_model(self.model_path)
            >                 if self.model.input_shape[1:3] != self._model_input_size:
            >                     print(f"[Warning] Stored model input size {self.model.input_shape[1:3]} "
            >                           f"differs from expected {self._model_input_size}")
            >                 print(f"Digit-classifier model loaded from {self.model_path}")
            >             except Exception as e:
            >                 print(f"[Error] Failed to load model from {self.model_path} – will train from scratch ({e})")
            >                 self.model = None # Ensure model is None if loading failed
            >
            >         # If training is required, or loading failed, ensure model is None
            >         if training_required and self.model is not None:
            >              print("Training required, ignoring loaded model.")
            >              self.model = None
            >         elif training_required and self.model is None:
            >              print("Training required, model will be built.")
            >         elif not training_required and self.model is None:
            >              print("Model not found or failed to load, and training not required. Classifier will not work.")
            >
            >
            >     # -------------------------------------------------------------- #
            >     # ResNet-style building block
            >     # -------------------------------------------------------------- #
            >     def _residual_block(self, x, filters, strides=1, activation="relu"):
            >         """Basic residual block."""
            >         shortcut = x
            >         # Downsample shortcut if needed (stride > 1 or different number of filters)
            >         if strides > 1 or shortcut.shape[-1] != filters:
            >             shortcut = layers.Conv2D(
            >                 filters, 1, strides=strides, use_bias=False, kernel_initializer="he_normal"
            >             )(shortcut)
            >             shortcut = layers.BatchNormalization()(shortcut)
            >
            >         # First convolution
            >         y = layers.Conv2D(
            >             filters, 3, strides=strides, padding="same", use_bias=False, kernel_initializer="he_normal"
            >         )(x)
            >         y = layers.BatchNormalization()(y)
            >         y = layers.Activation(activation)(y)
            >
            >         # Second convolution
            >         y = layers.Conv2D(
            >             filters, 3, padding="same", use_bias=False, kernel_initializer="he_normal"
            >         )(y)
            >         y = layers.BatchNormalization()(y)
            >
            >         # Add shortcut
            >         y = layers.Add()([shortcut, y])
            >         y = layers.Activation(activation)(y)
            >         return y
            >
            >     # -------------------------------------------------------------- #
            >     # backbone (Improved ResNet-style)
            >     # -------------------------------------------------------------- #
            >     def _build_cnn_model(self) -> keras.Model:
            >         """Builds a small ResNet-style CNN model."""
            >         activation_func = "relu" # Or keep 'gelu' if preferred
            >
            >         x_in = keras.Input(shape=MODEL_INPUT_SHAPE)
            >
            >         # Initial Convolution (Stem) - adjusted for small 28x28 input
            >         # No initial max pooling needed for 28x28
            >         x = layers.Conv2D(32, 3, padding="same", use_bias=False, kernel_initializer="he_normal")(x_in)
            >         x = layers.BatchNormalization()(x)
            >         x = layers.Activation(activation_func)(x)
            >         # x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # Optional: if more aggressive downsampling needed early
            >
            >         # Residual Blocks
            >         # Block 1 (32 filters)
            >         x = self._residual_block(x, 32, activation=activation_func)
            >         x = self._residual_block(x, 32, activation=activation_func)
            >
            >         # Block 2 (64 filters, downsample)
            >         x = self._residual_block(x, 64, strides=2, activation=activation_func) # 28x28 -> 14x14
            >         x = self._residual_block(x, 64, activation=activation_func)
            >
            >         # Block 3 (128 filters, downsample)
            >         x = self._residual_block(x, 128, strides=2, activation=activation_func) # 14x14 -> 7x7
            >         x = self._residual_block(x, 128, activation=activation_func)
            >
            >         # Block 4 (256 filters, downsample) - Optional, maybe too much for 7x7
            >         # x = self._residual_block(x, 256, strides=2, activation=activation_func) # 7x7 -> 4x4
            >         # x = self._residual_block(x, 256, activation=activation_func)
            >
            >         # Classifier Head
            >         x = layers.GlobalAveragePooling2D()(x) # Feature vector
            >         x = layers.Flatten()(x) # Ensure flat vector after GAP
            >
            >         x = layers.Dense(128, kernel_initializer="he_normal")(x)
            >         x = layers.BatchNormalization()(x) # BN before activation in dense layers
            >         x = layers.Activation(activation_func)(x)
            >         x = layers.Dropout(0.5)(x) # Regularization
            >
            >         # Removed the intermediate 64-unit dense layer, maybe not needed
            >         # x = layers.Dense(64, activation=activation_func, kernel_initializer="he_normal")(x)
            >         # x = layers.Dropout(0.5)(x)
            >
            >         y_out = layers.Dense(NUM_CLASSES, activation="softmax")(x) # Output layer
            >
            >         model = models.Model(x_in, y_out, name="resnet_digits")
            >
            >         # Consider AdamW optimizer if available and needed
            >         # optimizer = keras.optimizers.AdamW(learning_rate=3e-4, weight_decay=1e-4)
            >         optimizer = keras.optimizers.Adam(learning_rate=3e-4)
            >
            >         model.compile(
            >             optimizer=optimizer,
            >             loss="sparse_categorical_crossentropy",
            >             metrics=["accuracy"],
            >         )
            >         model.summary()
            >         return model
            >
            >     # -------------------------------------------------------------- #
            >     # preprocessing (fixed – tolerant, slightly adjusted target size)
            >     # -------------------------------------------------------------- #
            >     def _preprocess_cell_for_model(self, cell: np.ndarray) -> Optional[np.ndarray]:
            >         """
            >         Convert raw cell → 28×28 float32 in [0,1].
            >         Never raises; returns None only if `cell` itself is invalid.
            >         """
            >         if cell is None or cell.size < 10: # Basic check for validity
            >             return None
            >
            >         # Ensure input is grayscale uint8
            >         if cell.ndim == 3 and cell.shape[2] == 3:
            >             gray = cv2.cvtColor(cell, cv2.COLOR_BGR2GRAY)
            >         elif cell.ndim == 2:
            >             gray = cell
            >         else: # Unexpected shape
            >              return None # Or try to handle other cases like RGBA
            >
            >         # Ensure uint8 type for thresholding
            >         if gray.dtype != np.uint8:
            >              # Try to safely convert (e.g., scale if it's float)
            >              if np.issubdtype(gray.dtype, np.floating):
            >                  gray = (gray * 255).clip(0, 255).astype(np.uint8)
            >              else:
            >                  gray = gray.astype(np.uint8) # Hope for the best
            >
            >         # --- Thresholding ---
            >         # Apply slight Gaussian blur before thresholding to reduce noise
            >         blurred = cv2.GaussianBlur(gray, (3, 3), 0)
            >
            >         # Adaptive thresholding (robust to varying lighting)
            >         try:
            >             # Block size needs to be odd and > 1. Choose based on image size.
            >             block_size = max(5, min(gray.shape[0], gray.shape[1]) // 4)
            >             if block_size % 2 == 0: block_size += 1 # Ensure odd
            >             thresh = cv2.adaptiveThreshold(
            >                 blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, block_size, 5 # C=5 is a decent starting point
            >             )
            >         except cv2.error:
            >             # Fallback to Otsu's method if adaptive fails (e.g., very small image)
            >             _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            >
            >         # --- Find digit bounding box ---
            >         pts = cv2.findNonZero(thresh)
            >         if pts is None:  # Cell is empty or thresholding failed
            >             return np.zeros(self._model_input_size, dtype="float32") # Return black canvas
            >
            >         x, y, w, h = cv2.boundingRect(pts)
            >         if w <= 0 or h <= 0: # Should not happen if pts is not None, but check anyway
            >             return np.zeros(self._model_input_size, dtype="float32")
            >
            >         roi = thresh[y : y + h, x : x + w]
            >
            >         # --- Resize and Center ---
            >         # Calculate scaling factor to fit ROI into TARGET_CELL_CONTENT_SIZE box
            >         # Use TARGET_CELL_CONTENT_SIZE (e.g., 26)
            >         target_size = TARGET_CELL_CONTENT_SIZE
            >         scale = min(target_size / w, target_size / h)
            >         new_w = max(1, int(round(w * scale)))
            >         new_h = max(1, int(round(h * scale)))
            >
            >         # Resize using INTER_AREA for shrinking
            >         resized = cv2.resize(roi, (new_w, new_h), interpolation=cv2.INTER_AREA)
            >
            >         # Create target canvas (28x28)
            >         canvas = np.zeros(self._model_input_size, dtype=np.uint8)
            >
            >         # Calculate padding to center the resized digit
            >         pad_top = (self._model_input_size[0] - new_h) // 2
            >         pad_left = (self._model_input_size[1] - new_w) // 2
            >
            >         # Place the resized digit onto the canvas
            >         canvas[pad_top : pad_top + new_h, pad_left : pad_left + new_w] = resized
            >
            >         # Normalize to [0, 1] float32
            >         return canvas.astype("float32") / 255.0
            >
            >     # -------------------------------------------------------------- #
            >     # training
            >     # -------------------------------------------------------------- #
            >     def train(
            >         self,
            >         epochs: int = EPOCHS,
            >         steps_per_epoch: int = STEPS_PER_EPOCH,
            >         batch_size: int = BATCH_SIZE,
            >         validation_steps: int = VALIDATION_STEPS,
            >     ) -> None:
            >         print(f"\nTraining: epochs={epochs} steps={steps_per_epoch} batch={batch_size}")
            >         if self.model is None:
            >             self.model = self._build_cnn_model()
            >         elif not isinstance(self.model, keras.Model):
            >              print("[Error] self.model is not a valid Keras model. Cannot train.")
            >              return
            >
            >         try:
            >             test_img_path, test_gt = generate_and_save_test_example()
            >             # Ensure classifier instance is passed correctly
            >             epoch_cb = EpochTestCallback(test_img_path, test_gt, self)
            >             if epoch_cb.preprocessed is None:
            >                  print("[Warning] EpochTestCallback disabled due to preprocessing issues.")
            >                  epoch_cb = None # Disable if setup failed
            >         except Exception as e:
            >             print(f"[Warning] Epoch-callback disabled during setup ({e})")
            >             epoch_cb = None
            >
            >         # Use a fresh renderer instance for each generator if state matters
            >         train_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >         val_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >
            >         # Callbacks
            >         cbs: list[callbacks.Callback] = [
            >             callbacks.EarlyStopping(
            >                 monitor="val_accuracy", # Monitor validation accuracy
            >                 patience=8,          # Increase patience slightly
            >                 restore_best_weights=True,
            >                 verbose=1,
            >                 mode='max' # We want to maximize accuracy
            >             ),
            >             callbacks.ModelCheckpoint(
            >                 filepath=self.model_path,
            >                 monitor="val_accuracy", # Save based on best validation accuracy
            >                 save_best_only=True,
            >                 verbose=1,
            >                 mode='max'
            >             ),
            >             callbacks.ReduceLROnPlateau(
            >                 monitor="val_accuracy", # Reduce LR based on validation accuracy
            >                 factor=0.3,          # More aggressive reduction factor
            >                 patience=4,          # Reduce LR sooner if plateauing
            >                 min_lr=1e-7,
            >                 verbose=1,
            >                 mode='max'
            >             ),
            >             # TensorBoard callback (optional, for visualization)
            >             # callbacks.TensorBoard(log_dir='./logs', histogram_freq=1)
            >         ]
            >         if epoch_cb: # Add epoch test callback only if it was initialized successfully
            >             cbs.append(epoch_cb)
            >
            >         # Start Training
            >         history = self.model.fit(
            >             train_gen,
            >             epochs=epochs,
            >             steps_per_epoch=steps_per_epoch,
            >             validation_data=val_gen,
            >             validation_steps=validation_steps,
            >             callbacks=cbs,
            >             verbose=1,
            >         )
            >
            >         # Load best weights back if EarlyStopping restored them
            >         # (ModelCheckpoint already saved the best one, but loading ensures the instance has them)
            >         if self.model_path.exists():
            >              print(f"Loading best weights from {self.model_path}")
            >              self.model.load_weights(self.model_path) # Use load_weights if only weights were saved, or load_model if entire model
            >
            >         print("\nFinal evaluation using best weights:")
            >         # Use a fresh generator for final evaluation
            >         final_eval_gen = sudoku_data_generator(
            >             SudokuRenderer(),
            >             batch_size,
            >             self._preprocess_cell_for_model,
            >             MODEL_INPUT_SHAPE,
            >         )
            >         loss, acc = self.model.evaluate(
            >             final_eval_gen,
            >             steps=validation_steps * 2, # Evaluate on more steps
            >             verbose=1,
            >         )
            >         print(f"Final val_loss={loss:.5f}  val_acc={acc:.5f}")
            >
            >         # Explicitly save the final best model (ModelCheckpoint should have done this, but belt-and-suspenders)
            >         print(f"Saving final best model to {self.model_path}")
            >         self.model.save(self.model_path)
            >
            >         del train_gen, val_gen, final_eval_gen
            >         gc.collect()
            >
            >     # -------------------------------------------------------------- #
            >     # inference
            >     # -------------------------------------------------------------- #
            >     @torch.no_grad() # Keep torch decorator if using torch backend
            >     def recognise(
            >         self,
            >         cell: np.ndarray,
            >         confidence_threshold: float = 0.9, # Increased default threshold
            >     ) -> Tuple[int, float]:
            >         """Recognises a single digit cell."""
            >         if self.model is None:
            >             print("[Error] Recognise called but model is not loaded.")
            >             return 0, 0.0
            >
            >         proc = self._preprocess_cell_for_model(cell)
            >         if proc is None:
            >             # This indicates an issue with the input cell itself
            >             # print("[Debug] Preprocessing returned None for a cell.")
            >             return 0, 0.0 # Treat as empty/unrecognizable
            >
            >         # Add batch and channel dimensions: (H, W) -> (1, H, W, 1)
            >         x = proc[np.newaxis, ..., np.newaxis]
            >
            >         # Predict using the Keras model
            >         # The torch.no_grad() context manager is primarily for PyTorch operations.
            >         # Keras with torch backend should handle inference mode correctly via training=False.
            >         # If using pure torch tensors were necessary: x_tensor = torch.from_numpy(x).float()
            >         probs = self.model(x, training=False) # Use training=False for inference
            >
            >         # Ensure probs is a NumPy array
            >         if hasattr(probs, 'numpy'): # TF tensor
            >             probs = probs.cpu().detach().numpy()
            >         elif isinstance(probs, torch.Tensor): # PyTorch tensor
            >             probs = probs.cpu().numpy()
            >         # If it's already numpy, do nothing
            >
            >         probs = probs[0] # Remove batch dimension
            >
            >         idx = int(np.argmax(probs))
            >         conf = float(probs[idx])
            >
            >         # Return 0 (empty) if classified as EMPTY_LABEL or confidence is too low
            >         if idx == EMPTY_LABEL or conf < confidence_threshold:
            >             # Optionally distinguish between low-conf digit and classified-empty
            >             # if idx == EMPTY_LABEL: print(f"Cell classified as empty (conf {conf:.3f})")
            >             # else: print(f"Cell classified as {idx} but low conf ({conf:.3f} < {confidence_threshold})")
            >             return 0, conf # Return 0 for empty/uncertain
            >         else:
            >             # Return the classified digit (1-9)
            >             return idx, conf
            >
            >
            > # ------------------------------------------------------------------ #
            > # 8.  epoch‑end callback (Unchanged conceptually, ensure imports/refs are correct)
            > # ------------------------------------------------------------------ #
            > class EpochTestCallback(callbacks.Callback):
            >     def __init__(
            >         self,
            >         test_img_path: Path | str,
            >         gt_grid: np.ndarray,
            >         classifier: "DigitClassifier", # Pass the classifier instance
            >         frequency: int = 1,
            >     ) -> None:
            >         super().__init__()
            >         self.frequency = max(1, frequency)
            >         self.gt_grid = gt_grid.flatten() # Flatten GT grid for easier comparison
            >         self.classifier = classifier # Store the classifier instance
            >         self.test_img_path = test_img_path
            >         self.preprocessed = None # Initialize as None
            >
            >         # --- Preprocessing moved to on_train_begin ---
            >         # This ensures the classifier's model is built before preprocessing
            >
            >     def on_train_begin(self, logs=None):
            >         # --- Preprocess test image cells here ---
            >         # Ensures the model (and its input size) exists if built dynamically
            >         print("[Callback] Preprocessing test example...")
            >         try:
            >             cells, _, _ = extract_cells_from_image(self.test_img_path, debug=False)
            >             if not cells or len(cells) != GRID_SIZE * GRID_SIZE:
            >                 print(f"[Callback] Failed to extract correct number of cells ({len(cells)}) from {self.test_img_path}")
            >                 self.preprocessed = None
            >                 return
            >
            >             buf = []
            >             model_input_size = self.classifier._model_input_size # Get from classifier
            >             for i, cell in enumerate(cells):
            >                 proc = self.classifier._preprocess_cell_for_model(cell)
            >                 if proc is None:
            >                     print(f"[Callback Warning] Preprocessing failed for cell {i}, using zeros.")
            >                     proc = np.zeros(model_input_size, dtype="float32")
            >                 buf.append(proc)
            >
            >             self.preprocessed = np.asarray(buf, dtype="float32")[..., np.newaxis]
            >             print(f"[Callback] Test example preprocessed successfully ({self.preprocessed.shape}).")
            >
            >         except Exception as e:
            >             print(f"[Callback Error] Failed during test example preprocessing: {e}")
            >             self.preprocessed = None
            >
            >
            >     def on_epoch_end(self, epoch, logs=None):
            >         # Check if preprocessing was successful and if it's the right epoch
            >         if self.preprocessed is None or (epoch + 1) % self.frequency != 0:
            >             return
            >
            >         if not hasattr(self.model, 'predict'):
            >              print("[Callback Error] Model object does not have predict method.")
            >              return
            >
            >         print(f"\n--- Epoch {epoch+1} Test Example Evaluation ---")
            >         try:
            >             # Use the model attached to the callback (which is the one being trained)
            >             probs = self.model.predict(self.preprocessed, verbose=0)
            >             idxs = np.argmax(probs, axis=1)
            >             confs = np.max(probs, axis=1)
            >
            >             # Apply the same logic as `recognise` for final prediction
            >             # Use a reasonable threshold for display purposes
            >             display_threshold = 0.7 # Lower than final recognition, just for display
            >             final = [
            >                 i if (i != EMPTY_LABEL and c >= display_threshold) else 0
            >                 for i, c in zip(idxs, confs)
            >             ]
            >             pred_grid_flat = np.asarray(final)
            >             pred_grid = pred_grid_flat.reshape(GRID_SIZE, GRID_SIZE)
            >             conf_grid = confs.reshape(GRID_SIZE, GRID_SIZE)
            >
            >             print("Ground Truth:")
            >             sudoku_recogniser.print_sudoku_grid(self.gt_grid.reshape(GRID_SIZE, GRID_SIZE)) # Reshape GT back
            >             print("Prediction (Thresholded):")
            >             sudoku_recogniser.print_sudoku_grid(pred_grid, conf_grid, threshold=display_threshold)
            >
            >             # Compare against the flattened ground truth
            >             correct_cells = (pred_grid_flat == self.gt_grid).sum()
            >             total_cells = GRID_SIZE * GRID_SIZE
            >             accuracy = correct_cells / total_cells
            >             print(f"Test Example Accuracy: {correct_cells}/{total_cells} = {accuracy:.4f}")
            >             print("--- End Epoch Test ---\n")
            >
            >         except Exception as e:
            >             print(f"[Callback Error] Failed during prediction or display: {e}")
            >
            >
            > # ------------------------------------------------------------------ #
            > # 9.  CLI helper
            > # ------------------------------------------------------------------ #
            > if __name__ == "__main__":
            >     # Set to True to force retraining even if a model file exists
            >     FORCE_TRAIN = False # Set to True to retrain
            >
            >     model_file = Path(MODEL_FILENAME)
            >     train_needed = FORCE_TRAIN or not model_file.exists()
            >
            >     if FORCE_TRAIN and model_file.exists():
            >         print(f"FORCE_TRAIN is True. Deleting existing model: {model_file}")
            >         try:
            >             model_file.unlink()
            >             train_needed = True # Ensure flag is set
            >         except OSError as e:
            >             print(f"Error deleting existing model: {e}")
            >             # Decide whether to proceed or exit
            >             # exit(1)
            >
            >     # Instantiate the classifier. It will try to load if train_needed is False.
            >     clf = DigitClassifier(model_path=model_file, training_required=train_needed)
            >
            >     # Train if needed (either forced or because loading failed/file missing)
            >     if train_needed:
            >         print("Starting training process...")
            >         clf.train()
            >         # After training, the best model should be saved and loaded by the train method.
            >         # Verify the model is loaded for the sanity check below.
            >         if clf.model is None:
            >              print("[Error] Training finished, but model is still None. Cannot proceed.")
            >              exit(1) # Exit if training failed to produce a model
            >     elif clf.model is None:
            >          print("[Error] Model loading failed, and training was not requested. Cannot proceed.")
            >          exit(1) # Exit if no model is available
            >     else:
            >          print("Model loaded successfully. Skipping training.")
            >
            >
            >     # Perform sanity check only if the model is available
            >     if clf.model:
            >         print("\nQuick sanity check:")
            >
            >         # Test 1: Vertical stroke (should ideally be 1)
            >         dummy1 = np.zeros((50, 50), np.uint8)
            >         cv2.line(dummy1, (25, 10), (25, 40), 255, 4) # Thicker line
            >         d1, c1 = clf.recognise(dummy1, confidence_threshold=0.5) # Use lower threshold for test
            >         print(f"Vertical stroke → {d1}  (conf {c1:.3f})")
            >
            >         # Test 2: Blank cell (should be 0)
            >         blank = np.zeros((50, 50), np.uint8)
            >         d0, c0 = clf.recognise(blank, confidence_threshold=0.5)
            >         print(f"Blank cell      → {d0}  (conf {c0:.3f})")
            >
            >         # Test 3: A simple digit (e.g., '7')
            >         dummy7 = np.zeros((50, 50), np.uint8)
            >         cv2.putText(dummy7, '7', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.5, 255, 3)
            >         d7, c7 = clf.recognise(dummy7, confidence_threshold=0.5)
            >         print(f"Digit '7'       → {d7}  (conf {c7:.3f})")
            >
            >     else:
            >         print("\nSanity check skipped: No model available.")
            > ```
        metadata:
            filename: digit_classifier.py
    -
        user:
            > ```python 'digit_extractor.py'
            > """
            > Find and extract Sudoku grid cells from an image.
            > """
            >
            > import os
            > from pathlib import Path
            > from typing import List, Tuple, Optional
            >
            > import cv2
            > import numpy as np
            >
            > GRID_SIZE = 9
            > DEFAULT_RECTIFIED_SIZE = 450
            >
            >
            > def _order_points(pts: np.ndarray) -> np.ndarray:
            >     """Order four points as top-left, top-right, bottom-right, bottom-left."""
            >     pts = pts.reshape(4, 2).astype("float32")
            >     rect = np.zeros((4, 2), dtype="float32")
            >     s = pts.sum(axis=1)
            >     rect[0] = pts[np.argmin(s)]
            >     rect[2] = pts[np.argmax(s)]
            >     diff = pts[:, 1] - pts[:, 0]
            >     rect[1] = pts[np.argmin(diff)]
            >     rect[3] = pts[np.argmax(diff)]
            >     return rect
            >
            >
            > def find_sudoku_grid_contour(
            >     img: np.ndarray,
            >     debug_dir: Optional[Path] = None
            > ) -> np.ndarray:
            >     """
            >     Find the largest 4-point contour approximating the Sudoku grid boundary.
            >     """
            >     gray = (
            >         cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            >         if img.ndim == 3 else img.copy()
            >     )
            >
            >     if debug_dir:
            >         debug_dir.mkdir(parents=True, exist_ok=True)
            >
            >     blur = cv2.GaussianBlur(gray, (7, 7), 0)
            >     thresh = cv2.adaptiveThreshold(
            >         blur, 255,
            >         cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            >         cv2.THRESH_BINARY_INV,
            >         15, 4
            >     )
            >     closed = cv2.morphologyEx(
            >         thresh,
            >         cv2.MORPH_CLOSE,
            >         cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)),
            >         iterations=2
            >     )
            >
            >     contours, _ = cv2.findContours(
            >         closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
            >     )
            >     contours = sorted(contours, key=cv2.contourArea, reverse=True)
            >     min_area = gray.size * 0.1
            >
            >     for cnt in contours:
            >         if cv2.contourArea(cnt) < min_area:
            >             break
            >         peri = cv2.arcLength(cnt, True)
            >         approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)
            >         if len(approx) == 4 and cv2.isContourConvex(approx):
            >             x, y, w, h = cv2.boundingRect(approx)
            >             aspect = w / float(h)
            >             if 0.8 < aspect < 1.2:
            >                 return approx.reshape(4, 2).astype("float32")
            >
            >     raise ValueError("Sudoku grid contour not found.")
            >
            >
            > def rectify_grid(
            >     img: np.ndarray,
            >     contour: np.ndarray,
            >     size: int = DEFAULT_RECTIFIED_SIZE
            > ) -> Optional[np.ndarray]:
            >     """Perspective-correct the Sudoku grid to a square of given size."""
            >     try:
            >         src = _order_points(contour)
            >         dst = np.array([
            >             [0, 0],
            >             [size - 1, 0],
            >             [size - 1, size - 1],
            >             [0, size - 1],
            >         ], dtype="float32")
            >         mat = cv2.getPerspectiveTransform(src, dst)
            >         return cv2.warpPerspective(img, mat, (size, size))
            >     except cv2.error:
            >         return None
            >
            >
            > def split_into_cells(
            >     rectified: np.ndarray
            > ) -> Tuple[List[np.ndarray], np.ndarray]:
            >     """
            >     Split the rectified grid into GRID_SIZE × GRID_SIZE cell images.
            >     Returns (cells, rectified_image).
            >     """
            >     h, w = rectified.shape[:2]
            >     if h != w:
            >         size = max(h, w)
            >         rectified = cv2.resize(rectified, (size, size))
            >         h = w = size
            >
            >     cell_sz = h // GRID_SIZE
            >     margin = int(cell_sz * 0.04)
            >     cells: List[np.ndarray] = []
            >
            >     for row in range(GRID_SIZE):
            >         for col in range(GRID_SIZE):
            >             y0 = row * cell_sz + margin
            >             x0 = col * cell_sz + margin
            >             y1 = (row + 1) * cell_sz - margin
            >             x1 = (col + 1) * cell_sz - margin
            >             if y0 >= y1 or x0 >= x1:
            >                 cell = np.zeros((cell_sz, cell_sz), rectified.dtype)
            >             else:
            >                 cell = rectified[y0:y1, x0:x1]
            >             cells.append(cell)
            >
            >     return cells, rectified
            >
            >
            > def extract_cells_from_image(
            >     img_or_path,
            >     size: int = DEFAULT_RECTIFIED_SIZE,
            >     debug: bool = False
            > ) -> Tuple[Optional[List[np.ndarray]], Optional[np.ndarray], Optional[np.ndarray]]:
            >     """
            >     High-level function: read image, find grid, rectify, and split into cells.
            >     Returns (cells, rectified_image, contour) or (None, None, None) on failure.
            >     """
            >     if isinstance(img_or_path, (str, Path)):
            >         img = cv2.imread(str(img_or_path))
            >         if img is None:
            >             return None, None, None
            >     elif isinstance(img_or_path, np.ndarray):
            >         img = img_or_path.copy()
            >     else:
            >         return None, None, None
            >
            >     try:
            >         debug_dir = Path(f"debug_{os.getpid()}") if debug else None
            >         contour = find_sudoku_grid_contour(img, debug_dir)
            >         rectified = rectify_grid(img, contour, size=size)
            >         if rectified is None:
            >             return None, None, None
            >         cells, rectified = split_into_cells(rectified)
            >         return cells, rectified, contour
            >     except Exception as exc:
            >         print(f"[Extractor] {exc}")
            >         return None, None, None
            >
            > ```
        metadata:
            filename: digit_extractor.py
    -
        user:
            > ```python 'sudoku_recogniser.py'
            > """
            > Command-line utility to detect a Sudoku grid in an image and recognise its digits.
            > """
            >
            > from __future__ import annotations
            >
            > import sys
            > import time
            > from pathlib import Path
            > from typing import Tuple, Optional
            >
            > import cv2
            > import numpy as np
            >
            > import digit_classifier
            > from digit_extractor import GRID_SIZE, extract_cells_from_image
            >
            > FINAL_CONFIDENCE_THRESHOLD = 0.80
            >
            >
            > def print_sudoku_grid(
            >     grid: np.ndarray,
            >     conf: Optional[np.ndarray] = None,
            >     threshold: float = FINAL_CONFIDENCE_THRESHOLD
            > ) -> None:
            >     """Nicely print a 9×9 Sudoku grid, marking low‑confidence digits as '?'. """
            >     grid = np.asarray(grid)
            >     if grid.shape != (GRID_SIZE, GRID_SIZE):
            >         print("[print_sudoku_grid] invalid shape")
            >         return
            >
            >     for r in range(GRID_SIZE):
            >         if r > 0 and r % 3 == 0:
            >             print("|-----+-------+-----|")
            >
            >         tokens = []
            >         for c in range(GRID_SIZE):
            >             d = grid[r, c]
            >             if d == 0:
            >                 tok = "."
            >             else:
            >                 tok = str(d)
            >                 if conf is not None and conf[r, c] < threshold:
            >                     tok = "?"
            >             tokens.append(tok)
            >             if (c + 1) % 3 == 0 and c < GRID_SIZE - 1:
            >                 tokens.append("|")
            >         print(" ".join(tokens))
            >     print()
            >
            >
            > def display_results_on_image(
            >     rectified: Optional[np.ndarray],
            >     grid: np.ndarray
            > ) -> Optional[np.ndarray]:
            >     """
            >     Draw recognised digits onto the rectified grid image and return it.
            >     """
            >     if rectified is None:
            >         return None
            >
            >     img = (
            >         cv2.cvtColor(rectified, cv2.COLOR_GRAY2BGR)
            >         if rectified.ndim == 2 else rectified.copy()
            >     )
            >     h, w = img.shape[:2]
            >     cell_h, cell_w = h // GRID_SIZE, w // GRID_SIZE
            >
            >     for r in range(GRID_SIZE):
            >         for c in range(GRID_SIZE):
            >             d = grid[r, c]
            >             if d == 0:
            >                 continue
            >             text = str(d)
            >             (tw, th), _ = cv2.getTextSize(
            >                 text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2
            >             )
            >             x = c * cell_w + (cell_w - tw) // 2
            >             y = r * cell_h + (cell_h + th) // 2
            >             cv2.putText(
            >                 img, text, (x, y),
            >                 cv2.FONT_HERSHEY_SIMPLEX,
            >                 1, (0, 255, 0), 2, cv2.LINE_AA
            >             )
            >     return img
            >
            >
            > def recognise_sudoku(
            >     img_path: Path,
            >     classifier: digit_classifier.DigitClassifier
            > ) -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:
            >     """
            >     Extract cells and run the classifier on each one.
            >     Returns (predicted_grid, confidence_grid, rectified_image).
            >     """
            >     print(f"Processing {img_path} ...")
            >     start = time.time()
            >     cells, rectified, _ = extract_cells_from_image(img_path)
            >     if cells is None or rectified is None:
            >         raise RuntimeError("Extraction failed.")
            >
            >     pred = np.zeros((GRID_SIZE, GRID_SIZE), int)
            >     conf = np.zeros_like(pred, float)
            >
            >     for i, cell in enumerate(cells):
            >         r, c = divmod(i, GRID_SIZE)
            >         d, cf = classifier.recognise(cell, confidence_threshold=0.1)
            >         conf[r, c] = cf
            >         if d != 0 and cf >= FINAL_CONFIDENCE_THRESHOLD:
            >             pred[r, c] = d
            >
            >     elapsed = time.time() - start
            >     print(f"Done in {elapsed:.2f}s")
            >     return pred, conf, rectified
            >
            >
            > def main() -> None:
            >     if len(sys.argv) < 2:
            >         print("Usage: sudoku_recogniser.py <image_path>")
            >         sys.exit(0)
            >
            >     img_path = Path(sys.argv[1])
            >     if not img_path.exists():
            >         print(f"Image not found: {img_path}")
            >         sys.exit(1)
            >
            >     classifier = digit_classifier.DigitClassifier(model_path=digit_classifier.MODEL_FILENAME)
            >     if classifier.model is None:
            >         print("Model missing—training required.")
            >         classifier.train()
            >
            >     grid, conf, rectified = recognise_sudoku(img_path, classifier)
            >     print_sudoku_grid(grid, conf)
            >
            >     result_img = display_results_on_image(rectified, grid)
            >     if result_img is not None:
            >         cv2.imshow("Sudoku Recognition", result_img)
            >         cv2.waitKey(0)
            >         cv2.destroyAllWindows()
            >
            >
            > if __name__ == "__main__":
            >     main()
            >
            > ```
        metadata:
            filename: sudoku_recogniser.py
    -
        user:
            > ```python 'sudoku_renderer.py'
            > """
            > Synthetic Sudoku image generator for on‑the‑fly training data.
            > """
            >
            > import random
            > from pathlib import Path
            > from typing import Tuple, Optional
            >
            > import cv2
            > import numpy as np
            > import keras
            >
            > GRID_SIZE = 9
            > BASE_IMAGE_SIZE = 1000
            > CELL_SIZE = BASE_IMAGE_SIZE // GRID_SIZE
            >
            >
            > def _order_points(pts: np.ndarray) -> np.ndarray:
            >     """Order four points as TL, TR, BR, BL."""
            >     pts = pts.reshape(4, 2).astype("float32")
            >     rect = np.zeros((4, 2), dtype="float32")
            >     s = pts.sum(axis=1)
            >     rect[0] = pts[np.argmin(s)]
            >     rect[2] = pts[np.argmax(s)]
            >     diff = pts[:, 1] - pts[:, 0]
            >     rect[1] = pts[np.argmin(diff)]
            >     rect[3] = pts[np.argmax(diff)]
            >     return rect
            >
            >
            > def _load_mnist_digits() -> dict[int, list[np.ndarray]]:
            >     """
            >     Download MNIST once and bucket images by label for rendering.
            >     """
            >     (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
            >     images = np.concatenate([x_train, x_test])
            >     labels = np.concatenate([y_train, y_test])
            >
            >     buckets: dict[int, list[np.ndarray]] = {i: [] for i in range(10)}
            >     for img, lbl in zip(images, labels):
            >         inv = cv2.bitwise_not(img)
            >         padded = cv2.copyMakeBorder(
            >             inv, 4, 4, 4, 4,
            >             cv2.BORDER_CONSTANT, value=255
            >         )
            >         buckets[int(lbl)].append(padded)
            >     return buckets
            >
            >
            > class SudokuRenderer:
            >     """
            >     Render a random (or specified) Sudoku grid to a synthetic image.
            >     """
            >
            >     def __init__(self) -> None:
            >         self.mnist_buckets: Optional[dict[int, list[np.ndarray]]] = None
            >
            >     def _digit_source(self, digit: int) -> Tuple[Optional[np.ndarray], str]:
            >         if self.mnist_buckets is None:
            >             self.mnist_buckets = _load_mnist_digits()
            >
            >         sources = []
            >         if self.mnist_buckets[digit]:
            >             sources.append("mnist")
            >         sources.append("font")
            >         choice = random.choice(sources)
            >
            >         if choice == "mnist":
            >             img = random.choice(self.mnist_buckets[digit])
            >             if img.ndim == 2:
            >                 img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
            >             return img, "mnist"
            >         return None, "font"
            >
            >     def render_sudoku(
            >         self,
            >         grid_spec: Optional[list[list[int | None]]] = None,
            >         *,
            >         allow_empty: bool = True
            >     ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
            >         """
            >         Generate a synthetic Sudoku image.
            >         Returns (image, ground_truth_grid, warped_corners).
            >         """
            >         if grid_spec is None:
            >             gt = np.zeros((GRID_SIZE, GRID_SIZE), int)
            >             for r in range(GRID_SIZE):
            >                 for c in range(GRID_SIZE):
            >                     if allow_empty and random.random() < 0.4:
            >                         continue
            >                     gt[r, c] = random.randint(1, 9)
            >         else:
            >             gt = np.array([[d or 0 for d in row] for row in grid_spec], int)
            >
            >         bg = tuple(random.randint(200, 240) for _ in range(3))
            >         img = np.full((BASE_IMAGE_SIZE, BASE_IMAGE_SIZE, 3), bg, np.uint8)
            >
            >         # draw grid lines
            >         for i in range(GRID_SIZE + 1):
            >             major = (i % 3 == 0)
            >             thickness = random.randint(3 if major else 1, 5 if major else 3)
            >             cv2.line(img, (0, i*CELL_SIZE), (BASE_IMAGE_SIZE, i*CELL_SIZE), (0, 0, 0), thickness)
            >             cv2.line(img, (i*CELL_SIZE, 0), (i*CELL_SIZE, BASE_IMAGE_SIZE), (0, 0, 0), thickness)
            >
            >         # draw digits
            >         for r in range(GRID_SIZE):
            >             for c in range(GRID_SIZE):
            >                 d = gt[r, c]
            >                 if d == 0:
            >                     continue
            >
            >                 src_img, src_type = self._digit_source(d)
            >                 scale = random.uniform(0.5, 0.8)
            >                 tgt = int(CELL_SIZE * scale)
            >                 center_x = c*CELL_SIZE + CELL_SIZE//2
            >                 center_y = r*CELL_SIZE + CELL_SIZE//2
            >                 dx = int(random.uniform(-0.1, 0.1)*CELL_SIZE)
            >                 dy = int(random.uniform(-0.1, 0.1)*CELL_SIZE)
            >                 cx, cy = center_x + dx, center_y + dy
            >
            >                 if src_type == "mnist":
            >                     digit = cv2.resize(src_img, (tgt, tgt))
            >                     angle = random.uniform(-10, 10)
            >                     M = cv2.getRotationMatrix2D((tgt/2, tgt/2), angle, 1)
            >                     digit = cv2.warpAffine(
            >                         digit, M, (tgt, tgt),
            >                         borderMode=cv2.BORDER_CONSTANT, borderValue=(255,255,255)
            >                     )
            >                     mask = cv2.cvtColor(digit, cv2.COLOR_BGR2GRAY)
            >                     _, mask = cv2.threshold(mask, 250, 255, cv2.THRESH_BINARY_INV)
            >
            >                     x0 = max(0, cx - tgt//2)
            >                     y0 = max(0, cy - tgt//2)
            >                     roi = img[y0:y0+tgt, x0:x0+tgt]
            >                     m_inv = cv2.bitwise_not(mask[:roi.shape[0], :roi.shape[1]])
            >                     bg_region = cv2.bitwise_and(roi, roi, mask=m_inv)
            >                     fg_region = cv2.bitwise_and(digit, digit, mask=mask[:roi.shape[0], :roi.shape[1]])
            >                     img[y0:y0+roi.shape[0], x0:x0+roi.shape[1]] = cv2.add(bg_region, fg_region)
            >                 else:
            >                     font = cv2.FONT_HERSHEY_SIMPLEX
            >                     thickness = random.randint(1, 3)
            >                     font_scale = cv2.getFontScaleFromHeight(font, tgt, thickness) * 0.8
            >                     text = str(d)
            >                     tw, th = cv2.getTextSize(text, font, font_scale, thickness)[0]
            >                     x = cx - tw//2
            >                     y = cy + th//2
            >                     cv2.putText(img, text, (x, y),
            >                                 font, font_scale, (0, 0, 0), thickness, cv2.LINE_AA)
            >
            >         # add noise
            >         noise = np.random.normal(0, random.uniform(5,20), img.shape).astype(np.float32)
            >         noisy = np.clip(img.astype(np.float32) + noise, 0, 255).astype(np.uint8)
            >
            >         # random perspective warp
            >         h, w = noisy.shape[:2]
            >         orig = np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]], dtype="float32")
            >         shift = random.uniform(0.05, 0.2)
            >         max_dx, max_dy = w*shift, h*shift
            >         dst = np.array([
            >             [random.uniform(0, max_dx), random.uniform(0, max_dy)],
            >             [w-1-random.uniform(0, max_dx), random.uniform(0, max_dy)],
            >             [w-1-random.uniform(-max_dx*0.2, max_dx), h-1-random.uniform(0, max_dy)],
            >             [random.uniform(-max_dx*0.2, max_dx), h-1-random.uniform(0, max_dy)],
            >         ], dtype="float32")
            >         M = cv2.getPerspectiveTransform(orig, dst)
            >         out_w = int(dst[:,0].max()) + 1
            >         out_h = int(dst[:,1].max()) + 1
            >         warped = cv2.warpPerspective(
            >             noisy, M, (out_w, out_h), borderMode=cv2.BORDER_REPLICATE
            >         )
            >
            >         return warped, gt, dst
            >
            >
            > def generate_and_save_test_example(
            >     prefix: str = "epoch_test_sudoku",
            >     force: bool = False
            > ) -> Tuple[str, np.ndarray]:
            >     """
            >     Generate or load a fixed Sudoku test example for epoch callbacks.
            >     Returns (image_path, ground_truth_grid).
            >     """
            >     img_path = Path(f"{prefix}.png")
            >     gt_path = Path(f"{prefix}_gt.npy")
            >
            >     if not force and img_path.exists() and gt_path.exists():
            >         return str(img_path), np.load(gt_path)
            >
            >     renderer = SudokuRenderer()
            >     grid_spec = [
            >         [None, None, 3,    None, None, 6,    None, 8,    None],
            >         [8,    None, 1,    None, 3,    None, 5,    None, 4   ],
            >         [None, 4,    None, 8,    None, 7,    None, 1,    None],
            >         [1,    None, None, 4,    None, 5,    None, None, 9   ],
            >         [None, 7,    None, None, 2,    None, None, 4,    None],
            >         [5,    None, None, 7,    None, 1,    None, None, 3   ],
            >         [None, 8,    None, 5,    None, 3,    None, 9,    None],
            >         [7,    None, 4,    None, 9,    None, 1,    None, 8   ],
            >         [None, 1,    None, 6,    None, None, 4,    None, None],
            >     ]
            >     img, gt, _ = renderer.render_sudoku(grid_spec=grid_spec)
            >     cv2.imwrite(str(img_path), img)
            >     np.save(gt_path, gt)
            >     return str(img_path), gt
            >
            > ```
        metadata:
            filename: sudoku_renderer.py
    -
        user: This model reaches about 94% accuracy. We need much high accuracy. Improve it. Perhaps on the data side?
        metadata:
    -
        assistant:
            > ```diff
            > diff --git a/digit_classifier.py b/digit_classifier.py
            > index abcdef0..1234567 100644
            > --- a/digit_classifier.py
            > +++ b/digit_classifier.py
            > @@ def _preprocess_cell_for_model(self, cell: np.ndarray) -> Optional[np.ndarray]:
            >          # Normalize to [0, 1] float32
            >          return canvas.astype("float32") / 255.0
            > +
            > +    # ------------------------------------------------------------------ #
            > +    # 7.1  augmentation for training
            > +    # ------------------------------------------------------------------ #
            > +    def _augment_cell(self, proc: np.ndarray) -> np.ndarray:
            > +        """Apply random small rotations, translations and brightness/contrast jitter."""
            > +        h, w = proc.shape
            > +        # 1) random rotation
            > +        angle = random.uniform(-15, 15)
            > +        M_rot = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)
            > +        proc = cv2.warpAffine(proc, M_rot, (w, h),
            > +                              borderMode=cv2.BORDER_CONSTANT, borderValue=0)
            > +        # 2) random translation
            > +        tx, ty = random.uniform(-2, 2), random.uniform(-2, 2)
            > +        M_trans = np.float32([[1, 0, tx], [0, 1, ty]])
            > +        proc = cv2.warpAffine(proc, M_trans, (w, h),
            > +                              borderMode=cv2.BORDER_CONSTANT, borderValue=0)
            > +        # 3) photometric jitter (contrast & brightness)
            > +        alpha = random.uniform(0.8, 1.2)
            > +        beta  = random.uniform(-0.1, 0.1)
            > +        proc = np.clip(proc * alpha + beta, 0.0, 1.0).astype("float32")
            > +        return proc
            > @@ def train(
            > -        # Use a fresh renderer instance for each generator if state matters
            > -        train_gen = sudoku_data_generator(
            > -            SudokuRenderer(),
            > -            batch_size,
            > -            self._preprocess_cell_for_model,
            > -            MODEL_INPUT_SHAPE,
            > -        )
            > +        # Wrap preprocessing with augmentation for training
            > +        def train_preproc(cell):
            > +            proc = self._preprocess_cell_for_model(cell)
            > +            if proc is None:
            > +                return None
            > +            return self._augment_cell(proc)
            > +
            > +        # Use a fresh renderer instance for each generator if state matters
            > +        train_gen = sudoku_data_generator(
            > +            SudokuRenderer(),
            > +            batch_size,
            > +            train_preproc,
            > +            MODEL_INPUT_SHAPE,
            > +        )
            > ```
        metadata:
    -
        user:
            > Git apply result:
            > Found 1 diff block(s) to process using custom patcher.
            >
            > --- Processing Diff Block 1 ---
            > Identified target file: digit_classifier.py
            > Applying patch to 'digit_classifier.py' using custom patcher...
            > Successfully applied patch and wrote to digit_classifier.py.
            >
        metadata: